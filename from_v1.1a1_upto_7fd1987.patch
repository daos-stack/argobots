From 87e9d52d515abd59d6b906498656ac55124c517c Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Thu, 15 Oct 2020 17:21:32 -0500
Subject: [PATCH 01/40] barrier: fix ABT_barrier_free

ABT_barrier might be freed right after ABT_barrier_wait().  A lock is taken in
ABT_barrier_free() in order not to free ABT_barrier() that is being used.  The
number of waiters, however, is checked before this lock, which causes an error
if assert() is enabled; before taking the lock, there might exist some waiters.
This patch fixes it.
---
 src/barrier.c | 5 +++--
 1 file changed, 3 insertions(+), 2 deletions(-)

diff --git a/src/barrier.c b/src/barrier.c
index 99686f6..5199393 100644
--- a/src/barrier.c
+++ b/src/barrier.c
@@ -118,13 +118,14 @@ int ABT_barrier_free(ABT_barrier *barrier)
     ABTI_barrier *p_barrier = ABTI_barrier_get_ptr(h_barrier);
     ABTI_CHECK_NULL_BARRIER_PTR(p_barrier);
 
-    ABTI_ASSERT(p_barrier->counter == 0);
-
     /* The lock needs to be acquired to safely free the barrier structure.
      * However, we do not have to unlock it because the entire structure is
      * freed here. */
     ABTI_spinlock_acquire(&p_barrier->lock);
 
+    /* p_barrier->counter must be checked after taking a lock. */
+    ABTI_ASSERT(p_barrier->counter == 0);
+
     ABTU_free(p_barrier->waiters);
     ABTU_free(p_barrier->waiter_type);
     ABTU_free(p_barrier);
-- 
2.21.0 (Apple Git-122.2)


From 0663a6bae4cf32d7ac1e64aaa6ab90c4ce5b95a7 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Wed, 21 Oct 2020 22:20:37 -0500
Subject: [PATCH 02/40] cond: declare static functions at the bottom of the
 code file

Internal static functions should be declared after public ABT_ functions.  This
patch fixes it.
---
 src/cond.c | 89 +++++++++++++++++++++++++++++-------------------------
 1 file changed, 48 insertions(+), 41 deletions(-)

diff --git a/src/cond.c b/src/cond.c
index 8a0af51..3cee63b 100644
--- a/src/cond.c
+++ b/src/cond.c
@@ -6,6 +6,9 @@
 #include "abti.h"
 #include <sys/time.h>
 
+static inline double convert_timespec_to_sec(const struct timespec *p_ts);
+static inline void remove_thread(ABTI_cond *p_cond, ABTI_thread *p_thread);
+
 /** @defgroup COND Condition Variable
  * This group is for Condition Variable.
  */
@@ -91,47 +94,6 @@ int ABT_cond_wait(ABT_cond cond, ABT_mutex mutex)
     return ABT_SUCCESS;
 }
 
-static inline double convert_timespec_to_sec(const struct timespec *p_ts)
-{
-    double secs;
-    secs = ((double)p_ts->tv_sec) + 1.0e-9 * ((double)p_ts->tv_nsec);
-    return secs;
-}
-
-static inline void remove_thread(ABTI_cond *p_cond, ABTI_thread *p_thread)
-{
-    if (p_thread->p_next == NULL)
-        return;
-
-    ABTI_spinlock_acquire(&p_cond->lock);
-
-    if (p_thread->p_next == NULL) {
-        ABTI_spinlock_release(&p_cond->lock);
-        return;
-    }
-
-    /* If p_thread is still in the queue, we have to remove it. */
-    p_cond->num_waiters--;
-    if (p_cond->num_waiters == 0) {
-        p_cond->p_waiter_mutex = NULL;
-        p_cond->p_head = NULL;
-        p_cond->p_tail = NULL;
-    } else {
-        p_thread->p_prev->p_next = p_thread->p_next;
-        p_thread->p_next->p_prev = p_thread->p_prev;
-        if (p_thread == p_cond->p_head) {
-            p_cond->p_head = p_thread->p_next;
-        } else if (p_thread == p_cond->p_tail) {
-            p_cond->p_tail = p_thread->p_prev;
-        }
-    }
-
-    ABTI_spinlock_release(&p_cond->lock);
-
-    p_thread->p_prev = NULL;
-    p_thread->p_next = NULL;
-}
-
 /**
  * @ingroup COND
  * @brief   Wait on the condition.
@@ -304,3 +266,48 @@ int ABT_cond_broadcast(ABT_cond cond)
     ABTI_cond_broadcast(p_local, p_cond);
     return ABT_SUCCESS;
 }
+
+/*****************************************************************************/
+/* Internal static functions                                                 */
+/*****************************************************************************/
+
+static inline double convert_timespec_to_sec(const struct timespec *p_ts)
+{
+    double secs;
+    secs = ((double)p_ts->tv_sec) + 1.0e-9 * ((double)p_ts->tv_nsec);
+    return secs;
+}
+
+static inline void remove_thread(ABTI_cond *p_cond, ABTI_thread *p_thread)
+{
+    if (p_thread->p_next == NULL)
+        return;
+
+    ABTI_spinlock_acquire(&p_cond->lock);
+
+    if (p_thread->p_next == NULL) {
+        ABTI_spinlock_release(&p_cond->lock);
+        return;
+    }
+
+    /* If p_thread is still in the queue, we have to remove it. */
+    p_cond->num_waiters--;
+    if (p_cond->num_waiters == 0) {
+        p_cond->p_waiter_mutex = NULL;
+        p_cond->p_head = NULL;
+        p_cond->p_tail = NULL;
+    } else {
+        p_thread->p_prev->p_next = p_thread->p_next;
+        p_thread->p_next->p_prev = p_thread->p_prev;
+        if (p_thread == p_cond->p_head) {
+            p_cond->p_head = p_thread->p_next;
+        } else if (p_thread == p_cond->p_tail) {
+            p_cond->p_tail = p_thread->p_prev;
+        }
+    }
+
+    ABTI_spinlock_release(&p_cond->lock);
+
+    p_thread->p_prev = NULL;
+    p_thread->p_next = NULL;
+}
-- 
2.21.0 (Apple Git-122.2)


From 264b38e4d5007bbdbad363b62abc3ebe1bf8dcff Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Tue, 3 Nov 2020 12:34:59 -0600
Subject: [PATCH 03/40] error: add new error code, ABT_ERR_INV_ARG

ABT_ERR_INV_ARG will be returned if the user gives an invalid argument.
---
 src/include/abt.h.in | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/src/include/abt.h.in b/src/include/abt.h.in
index 7a9880c..6cd03b6 100644
--- a/src/include/abt.h.in
+++ b/src/include/abt.h.in
@@ -91,6 +91,7 @@ extern "C" {
 #define ABT_ERR_INV_TIMER          27  /* Invalid timer */
 #define ABT_ERR_INV_QUERY_KIND     28  /* Invalid query kind */
 #define ABT_ERR_INV_TOOL_CONTEXT   52  /* Invalid tool context */
+#define ABT_ERR_INV_ARG            53  /* Invalid argument */
 #define ABT_ERR_XSTREAM            29  /* ES-related error */
 #define ABT_ERR_XSTREAM_STATE      30  /* ES state error */
 #define ABT_ERR_XSTREAM_BARRIER    31  /* ES barrier-related error */
@@ -115,7 +116,6 @@ extern "C" {
 #define ABT_ERR_MISSING_JOIN       50  /* An ES or more did not join */
 #define ABT_ERR_FEATURE_NA         51  /* Feature not available */
 
-
 /* Constants */
 enum ABT_xstream_state {
     ABT_XSTREAM_STATE_RUNNING,
-- 
2.21.0 (Apple Git-122.2)


From 3ecea82c33e4dcaffe527669a070c095e717adbe Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Tue, 3 Nov 2020 12:37:02 -0600
Subject: [PATCH 04/40] error: fix ABT_error_get_str

ABT_error_get_str() got outdated.  This patch fixes it.
---
 src/error.c | 16 ++++++++++------
 1 file changed, 10 insertions(+), 6 deletions(-)

diff --git a/src/error.c b/src/error.c
index 5793382..ee8495b 100644
--- a/src/error.c
+++ b/src/error.c
@@ -44,7 +44,7 @@ int ABT_error_get_str(int err, char *str, size_t *len)
                                      "ABT_ERR_INV_UNIT",
                                      "ABT_ERR_INV_THREAD",
                                      "ABT_ERR_INV_THREAD_ATTR",
-                                     "ABT_ERR_INV_TASK",
+                                     NULL, /* 18 */
                                      "ABT_ERR_INV_KEY",
                                      "ABT_ERR_INV_MUTEX",
                                      "ABT_ERR_INV_MUTEX_ATTR",
@@ -63,7 +63,7 @@ int ABT_error_get_str(int err, char *str, size_t *len)
                                      "ABT_ERR_POOL",
                                      "ABT_ERR_UNIT",
                                      "ABT_ERR_THREAD",
-                                     "ABT_ERR_TASK",
+                                     NULL, /* 37 */
                                      "ABT_ERR_KEY",
                                      "ABT_ERR_MUTEX",
                                      "ABT_ERR_MUTEX_LOCKED",
@@ -74,14 +74,18 @@ int ABT_error_get_str(int err, char *str, size_t *len)
                                      "ABT_ERR_FUTURE",
                                      "ABT_ERR_BARRIER",
                                      "ABT_ERR_TIMER",
-                                     "ABT_ERR_EVENT",
                                      "ABT_ERR_MIGRATION_TARGET",
                                      "ABT_ERR_MIGRATION_NA",
                                      "ABT_ERR_MISSING_JOIN",
-                                     "ABT_ERR_FEATURE_NA" };
+                                     "ABT_ERR_FEATURE_NA",
+                                     "ABT_ERR_INV_TOOL_CONTEXT",
+                                     "ABT_ERR_INV_ARG" };
 
-    ABTI_CHECK_TRUE(err >= ABT_SUCCESS && err <= ABT_ERR_FEATURE_NA,
-                    ABT_ERR_OTHER);
+    ABTI_CHECK_TRUE(err >= ABT_SUCCESS &&
+                        err < sizeof(err_str) / sizeof(err_str[0]),
+                    ABT_ERR_INV_ARG);
+    /* This entry does not exist. */
+    ABTI_CHECK_TRUE(err_str[err], ABT_ERR_INV_ARG);
     if (str)
         strcpy(str, err_str[err]);
     if (len)
-- 
2.21.0 (Apple Git-122.2)


From f34f8fac18cde2d598dee676a6be36d8b209bdf1 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Tue, 3 Nov 2020 13:26:38 -0600
Subject: [PATCH 05/40] test/basic: add a new test to check ABT_error_get_str

---
 test/.gitignore        |  1 +
 test/basic/Makefile.am |  5 ++-
 test/basic/error.c     | 86 ++++++++++++++++++++++++++++++++++++++++++
 3 files changed, 91 insertions(+), 1 deletion(-)
 create mode 100644 test/basic/error.c

diff --git a/test/.gitignore b/test/.gitignore
index 00c8d96..94f74b3 100644
--- a/test/.gitignore
+++ b/test/.gitignore
@@ -59,6 +59,7 @@ basic/timer
 basic/info_print
 basic/info_stackdump
 basic/info_stackdump2
+basic/error
 
 # benchmark
 benchmark/init_finalize
diff --git a/test/basic/Makefile.am b/test/basic/Makefile.am
index fe9204b..5500424 100644
--- a/test/basic/Makefile.am
+++ b/test/basic/Makefile.am
@@ -63,7 +63,8 @@ TESTS = \
 	timer \
 	info_print \
 	info_stackdump \
-	info_stackdump2
+	info_stackdump2 \
+	error
 
 XFAIL_TESTS =
 if ABT_CONFIG_DISABLE_EXT_THREAD
@@ -138,6 +139,7 @@ timer_SOURCES = timer.c
 info_print_SOURCES = info_print.c
 info_stackdump_SOURCES = info_stackdump.c
 info_stackdump2_SOURCES = info_stackdump2.c
+error_SOURCES = error.c
 
 testing:
 	./init_finalize
@@ -200,3 +202,4 @@ testing:
 	./info_print
 	./info_stackdump
 	./info_stackdump2
+	./error
diff --git a/test/basic/error.c b/test/basic/error.c
new file mode 100644
index 0000000..8689a82
--- /dev/null
+++ b/test/basic/error.c
@@ -0,0 +1,86 @@
+/* -*- Mode: C; c-basic-offset:4 ; indent-tabs-mode:nil ; -*- */
+/*
+ * See COPYRIGHT in top-level directory.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include "abt.h"
+#include "abttest.h"
+
+typedef struct {
+    const char *str;
+    int code;
+} error_pair_t;
+
+int main(int argc, char *argv[])
+{
+    int ret;
+
+    /* init and thread creation */
+    ATS_read_args(argc, argv);
+
+    error_pair_t error_pairs[] = {
+        { "ABT_SUCCESS", ABT_SUCCESS },
+        { "ABT_ERR_UNINITIALIZED", ABT_ERR_UNINITIALIZED },
+        { "ABT_ERR_MEM", ABT_ERR_MEM },
+        { "ABT_ERR_OTHER", ABT_ERR_OTHER },
+        { "ABT_ERR_INV_XSTREAM", ABT_ERR_INV_XSTREAM },
+        { "ABT_ERR_INV_XSTREAM_RANK", ABT_ERR_INV_XSTREAM_RANK },
+        { "ABT_ERR_INV_XSTREAM_BARRIER", ABT_ERR_INV_XSTREAM_BARRIER },
+        { "ABT_ERR_INV_SCHED", ABT_ERR_INV_SCHED },
+        { "ABT_ERR_INV_SCHED_KIND", ABT_ERR_INV_SCHED_KIND },
+        { "ABT_ERR_INV_SCHED_PREDEF", ABT_ERR_INV_SCHED_PREDEF },
+        { "ABT_ERR_INV_SCHED_TYPE", ABT_ERR_INV_SCHED_TYPE },
+        { "ABT_ERR_INV_SCHED_CONFIG", ABT_ERR_INV_SCHED_CONFIG },
+        { "ABT_ERR_INV_POOL", ABT_ERR_INV_POOL },
+        { "ABT_ERR_INV_POOL_KIND", ABT_ERR_INV_POOL_KIND },
+        { "ABT_ERR_INV_POOL_ACCESS", ABT_ERR_INV_POOL_ACCESS },
+        { "ABT_ERR_INV_UNIT", ABT_ERR_INV_UNIT },
+        { "ABT_ERR_INV_THREAD", ABT_ERR_INV_THREAD },
+        { "ABT_ERR_INV_THREAD_ATTR", ABT_ERR_INV_THREAD_ATTR },
+        { "ABT_ERR_INV_KEY", ABT_ERR_INV_KEY },
+        { "ABT_ERR_INV_MUTEX", ABT_ERR_INV_MUTEX },
+        { "ABT_ERR_INV_MUTEX_ATTR", ABT_ERR_INV_MUTEX_ATTR },
+        { "ABT_ERR_INV_COND", ABT_ERR_INV_COND },
+        { "ABT_ERR_INV_RWLOCK", ABT_ERR_INV_RWLOCK },
+        { "ABT_ERR_INV_EVENTUAL", ABT_ERR_INV_EVENTUAL },
+        { "ABT_ERR_INV_FUTURE", ABT_ERR_INV_FUTURE },
+        { "ABT_ERR_INV_BARRIER", ABT_ERR_INV_BARRIER },
+        { "ABT_ERR_INV_TIMER", ABT_ERR_INV_TIMER },
+        { "ABT_ERR_INV_QUERY_KIND", ABT_ERR_INV_QUERY_KIND },
+        { "ABT_ERR_XSTREAM", ABT_ERR_XSTREAM },
+        { "ABT_ERR_XSTREAM_STATE", ABT_ERR_XSTREAM_STATE },
+        { "ABT_ERR_XSTREAM_BARRIER", ABT_ERR_XSTREAM_BARRIER },
+        { "ABT_ERR_SCHED", ABT_ERR_SCHED },
+        { "ABT_ERR_SCHED_CONFIG", ABT_ERR_SCHED_CONFIG },
+        { "ABT_ERR_POOL", ABT_ERR_POOL },
+        { "ABT_ERR_UNIT", ABT_ERR_UNIT },
+        { "ABT_ERR_THREAD", ABT_ERR_THREAD },
+        { "ABT_ERR_KEY", ABT_ERR_KEY },
+        { "ABT_ERR_MUTEX", ABT_ERR_MUTEX },
+        { "ABT_ERR_MUTEX_LOCKED", ABT_ERR_MUTEX_LOCKED },
+        { "ABT_ERR_COND", ABT_ERR_COND },
+        { "ABT_ERR_COND_TIMEDOUT", ABT_ERR_COND_TIMEDOUT },
+        { "ABT_ERR_RWLOCK", ABT_ERR_RWLOCK },
+        { "ABT_ERR_EVENTUAL", ABT_ERR_EVENTUAL },
+        { "ABT_ERR_FUTURE", ABT_ERR_FUTURE },
+        { "ABT_ERR_BARRIER", ABT_ERR_BARRIER },
+        { "ABT_ERR_TIMER", ABT_ERR_TIMER },
+        { "ABT_ERR_MIGRATION_TARGET", ABT_ERR_MIGRATION_TARGET },
+        { "ABT_ERR_MIGRATION_NA", ABT_ERR_MIGRATION_NA },
+        { "ABT_ERR_MISSING_JOIN", ABT_ERR_MISSING_JOIN },
+        { "ABT_ERR_FEATURE_NA", ABT_ERR_FEATURE_NA },
+        { "ABT_ERR_INV_TOOL_CONTEXT", ABT_ERR_INV_TOOL_CONTEXT },
+        { "ABT_ERR_INV_ARG", ABT_ERR_INV_ARG },
+    };
+
+    for (int i = 0; i < sizeof(error_pairs) / sizeof(error_pairs[0]); i++) {
+        char str[256];
+        ret = ABT_error_get_str(error_pairs[i].code, str, NULL);
+        ATS_ERROR(ret, "ABT_error_get_str");
+        assert(strcmp(error_pairs[i].str, str) == 0);
+    }
+    return ret;
+}
-- 
2.21.0 (Apple Git-122.2)


From d149ee3e24bc57848ea7763871fa3db97a4538b1 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Wed, 11 Nov 2020 17:04:22 -0600
Subject: [PATCH 06/40] util: implement basic math functions

min, max, and roundup can be easily implemented, so they are embedded into the
Argobots code, but it significantly lowers the readability.  This patch
introduces basic math functions to fix this issue.
---
 src/include/abtu.h | 91 ++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 91 insertions(+)

diff --git a/src/include/abtu.h b/src/include/abtu.h
index 96131b6..0a3c296 100644
--- a/src/include/abtu.h
+++ b/src/include/abtu.h
@@ -11,6 +11,97 @@
 #include <assert.h>
 #include "abt_config.h"
 
+/* Basic math functions */
+static inline int ABTU_max_int(int a, int b)
+{
+    return a > b ? a : b;
+}
+
+static inline int32_t ABTU_max_int32(int32_t a, int32_t b)
+{
+    return a > b ? a : b;
+}
+
+static inline uint32_t ABTU_max_uint32(uint32_t a, uint32_t b)
+{
+    return a > b ? a : b;
+}
+
+static inline int64_t ABTU_max_int64(int64_t a, int64_t b)
+{
+    return a > b ? a : b;
+}
+
+static inline uint64_t ABTU_max_uint64(uint64_t a, uint64_t b)
+{
+    return a > b ? a : b;
+}
+
+static inline size_t ABTU_max_size(size_t a, size_t b)
+{
+    return a > b ? a : b;
+}
+
+static inline int ABTU_min_int(int a, int b)
+{
+    return a < b ? a : b;
+}
+
+static inline int32_t ABTU_min_int32(int32_t a, int32_t b)
+{
+    return a < b ? a : b;
+}
+
+static inline uint32_t ABTU_min_uint32(uint32_t a, uint32_t b)
+{
+    return a < b ? a : b;
+}
+
+static inline int64_t ABTU_min_int64(int64_t a, int64_t b)
+{
+    return a < b ? a : b;
+}
+
+static inline uint64_t ABTU_min_uint64(uint64_t a, uint64_t b)
+{
+    return a < b ? a : b;
+}
+
+static inline size_t ABTU_min_size(size_t a, size_t b)
+{
+    return a < b ? a : b;
+}
+
+static inline uint32_t ABTU_roundup_uint32(uint32_t val, uint32_t multiple)
+{
+    if ((multiple & (multiple - 1)) == 0) {
+        /* If multiple is a power of two. */
+        return (val + multiple - 1) & (~(multiple - 1));
+    } else {
+        return ((val + multiple - 1) / multiple) * multiple;
+    }
+}
+
+static inline uint64_t ABTU_roundup_uint64(uint64_t val, uint64_t multiple)
+{
+    if ((multiple & (multiple - 1)) == 0) {
+        /* If multiple is a power of two. */
+        return (val + multiple - 1) & (~(multiple - 1));
+    } else {
+        return ((val + multiple - 1) / multiple) * multiple;
+    }
+}
+
+static inline size_t ABTU_roundup_size(size_t val, size_t multiple)
+{
+    if ((multiple & (multiple - 1)) == 0) {
+        /* If multiple is a power of two. */
+        return (val + multiple - 1) & (~(multiple - 1));
+    } else {
+        return ((val + multiple - 1) / multiple) * multiple;
+    }
+}
+
 /* Utility feature */
 
 #ifdef HAVE___BUILTIN_EXPECT
-- 
2.21.0 (Apple Git-122.2)


From 408262cf57e31efe56122ba821522ecc241bf471 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Wed, 11 Nov 2020 17:07:55 -0600
Subject: [PATCH 07/40] util: use min/max/roundup for better readability

---
 src/arch/abtd_env.c    | 29 ++++++++++++-----------------
 src/include/abti_key.h |  6 +++---
 src/include/abti_mem.h |  6 ++----
 src/include/abtu.h     |  9 +++------
 src/mem/malloc.c       |  6 +++---
 src/stream.c           |  4 ++--
 6 files changed, 25 insertions(+), 35 deletions(-)

diff --git a/src/arch/abtd_env.c b/src/arch/abtd_env.c
index f8c6dff..96f32fa 100644
--- a/src/arch/abtd_env.c
+++ b/src/arch/abtd_env.c
@@ -116,8 +116,8 @@ void ABTD_env_init(ABTI_global *p_global)
     }
     /* Stack size must be a multiple of cacheline size. */
     p_global->thread_stacksize =
-        (p_global->thread_stacksize + ABT_CONFIG_STATIC_CACHELINE_SIZE - 1) &
-        (~(ABT_CONFIG_STATIC_CACHELINE_SIZE - 1));
+        ABTU_roundup_size(p_global->thread_stacksize,
+                          ABT_CONFIG_STATIC_CACHELINE_SIZE);
 
     /* Default stack size for scheduler */
     env = getenv("ABT_SCHED_STACKSIZE");
@@ -221,21 +221,17 @@ void ABTD_env_init(ABTI_global *p_global)
     if (env != NULL) {
         p_global->mem_max_stacks = (uint32_t)atol(env);
     } else {
-        if (p_global->thread_stacksize * ABTD_MEM_MAX_NUM_STACKS >
-            ABTD_MEM_MAX_TOTAL_STACK_SIZE) {
-            /* Each execution stream caches too many stacks in total. Let's
-             * reduce the max # of stacks. */
-            p_global->mem_max_stacks =
-                ABTD_MEM_MAX_TOTAL_STACK_SIZE / p_global->thread_stacksize;
-        } else {
-            p_global->mem_max_stacks = ABTD_MEM_MAX_NUM_STACKS;
-        }
+        /* Each execution stream caches too many stacks in total. Let's
+         * reduce the max # of stacks. */
+        p_global->mem_max_stacks =
+            ABTU_min_uint32(ABTD_MEM_MAX_TOTAL_STACK_SIZE /
+                                p_global->thread_stacksize,
+                            ABTD_MEM_MAX_NUM_STACKS);
     }
     /* The value must be a multiple of ABT_MEM_POOL_MAX_LOCAL_BUCKETS. */
     p_global->mem_max_stacks =
-        ((p_global->mem_max_stacks + ABT_MEM_POOL_MAX_LOCAL_BUCKETS - 1) /
-         ABT_MEM_POOL_MAX_LOCAL_BUCKETS) *
-        ABT_MEM_POOL_MAX_LOCAL_BUCKETS;
+        ABTU_roundup_uint32(p_global->mem_max_stacks,
+                            ABT_MEM_POOL_MAX_LOCAL_BUCKETS);
 
     /* Maximum number of descriptors that each ES can keep during execution */
     env = getenv("ABT_MEM_MAX_NUM_DESCS");
@@ -248,9 +244,8 @@ void ABTD_env_init(ABTI_global *p_global)
     }
     /* The value must be a multiple of ABT_MEM_POOL_MAX_LOCAL_BUCKETS. */
     p_global->mem_max_descs =
-        ((p_global->mem_max_descs + ABT_MEM_POOL_MAX_LOCAL_BUCKETS - 1) /
-         ABT_MEM_POOL_MAX_LOCAL_BUCKETS) *
-        ABT_MEM_POOL_MAX_LOCAL_BUCKETS;
+        ABTU_roundup_uint32(p_global->mem_max_descs,
+                            ABT_MEM_POOL_MAX_LOCAL_BUCKETS);
 
     /* How to allocate large pages.  The default is to use mmap() for huge
      * pages and then to fall back to allocate regular pages using mmap() when
diff --git a/src/include/abti_key.h b/src/include/abti_key.h
index a4b0640..b174611 100644
--- a/src/include/abti_key.h
+++ b/src/include/abti_key.h
@@ -74,9 +74,9 @@ ABTU_ret_err static inline int ABTI_ktable_create(ABTI_local *p_local,
     /* max alignment must be a power of 2. */
     ABTI_STATIC_ASSERT((ABTU_MAX_ALIGNMENT & (ABTU_MAX_ALIGNMENT - 1)) == 0);
     size_t ktable_size =
-        (offsetof(ABTI_ktable, p_elems) +
-         sizeof(ABTD_atomic_ptr) * key_table_size + ABTU_MAX_ALIGNMENT - 1) &
-        (~(ABTU_MAX_ALIGNMENT - 1));
+        ABTU_roundup_size(offsetof(ABTI_ktable, p_elems) +
+                              sizeof(ABTD_atomic_ptr) * key_table_size,
+                          ABTU_MAX_ALIGNMENT);
     /* Since only one ES can access the memory pool on creation, this uses an
      * unsafe memory pool without taking a lock. */
     if (ABTU_likely(ktable_size <= ABTI_KTABLE_DESC_SIZE)) {
diff --git a/src/include/abti_mem.h b/src/include/abti_mem.h
index 47cffee..407cbec 100644
--- a/src/include/abti_mem.h
+++ b/src/include/abti_mem.h
@@ -12,8 +12,7 @@
  * used to determine whether the descriptor is allocated externally (i.e.,
  * malloc()) or taken from a memory pool. */
 #define ABTI_MEM_POOL_DESC_ELEM_SIZE                                           \
-    ((sizeof(ABTI_thread) + ABT_CONFIG_STATIC_CACHELINE_SIZE - 1) &            \
-     (~(ABT_CONFIG_STATIC_CACHELINE_SIZE - 1)))
+    ABTU_roundup_size(sizeof(ABTI_thread), ABT_CONFIG_STATIC_CACHELINE_SIZE)
 
 enum {
     ABTI_MEM_LP_MALLOC = 0,
@@ -119,8 +118,7 @@ ABTU_ret_err static inline int ABTI_mem_alloc_ythread_malloc_desc_stack_impl(
 {
     /* stacksize must be a multiple of ABT_CONFIG_STATIC_CACHELINE_SIZE. */
     size_t alloc_stacksize =
-        (stacksize + ABT_CONFIG_STATIC_CACHELINE_SIZE - 1) &
-        (~(ABT_CONFIG_STATIC_CACHELINE_SIZE - 1));
+        ABTU_roundup_size(stacksize, ABT_CONFIG_STATIC_CACHELINE_SIZE);
     char *p_stack;
     int abt_errno =
         ABTU_malloc(alloc_stacksize + sizeof(ABTI_ythread), (void **)&p_stack);
diff --git a/src/include/abtu.h b/src/include/abtu.h
index 0a3c296..e7280c1 100644
--- a/src/include/abtu.h
+++ b/src/include/abtu.h
@@ -132,9 +132,7 @@ static inline size_t ABTU_roundup_size(size_t val, size_t multiple)
 #define ABTU_alignof(type) 16 /* 16 bytes would be a good guess. */
 #endif
 #define ABTU_MAX_ALIGNMENT                                                     \
-    (ABTU_alignof(long double) > ABTU_alignof(long long)                       \
-         ? ABTU_alignof(long double)                                           \
-         : ABTU_alignof(long long))
+    ABTU_max_size(ABTU_alignof(long double), ABTU_alignof(long long))
 
 #ifdef HAVE_FUNC_ATTRIBUTE_WARN_UNUSED_RESULT
 #define ABTU_ret_err __attribute__((warn_unused_result))
@@ -222,8 +220,7 @@ ABTU_ret_err static inline int ABTU_malloc(size_t size, void **p_ptr)
     /* Round up to the smallest multiple of ABT_CONFIG_STATIC_CACHELINE_SIZE
      * which is greater than or equal to size in order to avoid any
      * false-sharing. */
-    size = (size + ABT_CONFIG_STATIC_CACHELINE_SIZE - 1) &
-           (~(ABT_CONFIG_STATIC_CACHELINE_SIZE - 1));
+    size = ABTU_roundup_size(size, ABT_CONFIG_STATIC_CACHELINE_SIZE);
     return ABTU_memalign(ABT_CONFIG_STATIC_CACHELINE_SIZE, size, p_ptr);
 }
 
@@ -248,7 +245,7 @@ ABTU_ret_err static inline int ABTU_realloc(size_t old_size, size_t new_size,
     if (ABTI_IS_ERROR_CHECK_ENABLED && ret != ABT_SUCCESS) {
         return ABT_ERR_MEM;
     }
-    memcpy(new_ptr, old_ptr, (old_size < new_size) ? old_size : new_size);
+    memcpy(new_ptr, old_ptr, ABTU_min_size(old_size, new_size));
     ABTU_free(old_ptr);
     *p_ptr = new_ptr;
     return ABT_SUCCESS;
diff --git a/src/mem/malloc.c b/src/mem/malloc.c
index e374356..c113fb0 100644
--- a/src/mem/malloc.c
+++ b/src/mem/malloc.c
@@ -47,9 +47,9 @@ void ABTI_mem_init(ABTI_global *p_global)
     size_t thread_stacksize = p_global->thread_stacksize;
     ABTI_ASSERT((thread_stacksize & (ABT_CONFIG_STATIC_CACHELINE_SIZE - 1)) ==
                 0);
-    size_t stacksize = (thread_stacksize + sizeof(ABTI_ythread) +
-                        ABT_CONFIG_STATIC_CACHELINE_SIZE - 1) &
-                       (~(ABT_CONFIG_STATIC_CACHELINE_SIZE - 1));
+    size_t stacksize =
+        ABTU_roundup_size(thread_stacksize + sizeof(ABTI_ythread),
+                          ABT_CONFIG_STATIC_CACHELINE_SIZE);
     if ((stacksize & (2 * ABT_CONFIG_STATIC_CACHELINE_SIZE - 1)) == 0) {
         /* Avoid a multiple of 2 * cacheline size to avoid cache bank conflict.
          */
diff --git a/src/stream.c b/src/stream.c
index b0ac0eb..db6b6ce 100644
--- a/src/stream.c
+++ b/src/stream.c
@@ -570,7 +570,7 @@ int ABT_xstream_get_main_pools(ABT_xstream xstream, int max_pools,
     ABTI_CHECK_NULL_XSTREAM_PTR(p_xstream);
 
     ABTI_sched *p_sched = p_xstream->p_main_sched;
-    max_pools = p_sched->num_pools > max_pools ? max_pools : p_sched->num_pools;
+    max_pools = ABTU_min_int(p_sched->num_pools, max_pools);
     memcpy(pools, p_sched->pools, sizeof(ABT_pool) * max_pools);
     return ABT_SUCCESS;
 }
@@ -839,7 +839,7 @@ int ABT_xstream_get_affinity(ABT_xstream xstream, int cpuset_size, int *cpuset,
     ABTI_CHECK_ERROR(abt_errno);
 
     int i, n;
-    n = affinity.num_cpuids > cpuset_size ? cpuset_size : affinity.num_cpuids;
+    n = ABTU_min_int(affinity.num_cpuids, cpuset_size);
     *num_cpus = n;
     for (i = 0; i < n; i++) {
         cpuset[i] = affinity.cpuids[i];
-- 
2.21.0 (Apple Git-122.2)


From c35424f5581a96426ae2db3c1b8642d56472be6a Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Thu, 12 Nov 2020 14:28:41 -0600
Subject: [PATCH 08/40] util: implement an improved atoi function

Argobots uses atoi() to read environment variables, but atoi() does not
throw an error properly when the input is not vaild.  This patch implements a
new atoi() function that can detect overflow, underflow, and invalid input.
---
 src/include/abtu.h   |   9 ++
 src/util/Makefile.mk |   1 +
 src/util/atoi.c      | 305 +++++++++++++++++++++++++++++++++++++++++++
 3 files changed, 315 insertions(+)
 create mode 100644 src/util/atoi.c

diff --git a/src/include/abtu.h b/src/include/abtu.h
index e7280c1..afb07c5 100644
--- a/src/include/abtu.h
+++ b/src/include/abtu.h
@@ -305,4 +305,13 @@ ABTU_alloc_largepage(size_t size, size_t alignment_hint,
                      void **p_ptr);
 void ABTU_free_largepage(void *ptr, size_t size, ABTU_MEM_LARGEPAGE_TYPE type);
 
+/* String-to-integer functions. */
+ABTU_ret_err int ABTU_atoi(const char *str, int *p_val, ABT_bool *p_overflow);
+ABTU_ret_err int ABTU_atoui32(const char *str, uint32_t *p_val,
+                              ABT_bool *p_overflow);
+ABTU_ret_err int ABTU_atoui64(const char *str, uint64_t *p_val,
+                              ABT_bool *p_overflow);
+ABTU_ret_err int ABTU_atosz(const char *str, size_t *p_val,
+                            ABT_bool *p_overflow);
+
 #endif /* ABTU_H_INCLUDED */
diff --git a/src/util/Makefile.mk b/src/util/Makefile.mk
index 59a86e3..acdde2c 100644
--- a/src/util/Makefile.mk
+++ b/src/util/Makefile.mk
@@ -4,4 +4,5 @@
 #
 
 abt_sources += \
+	util/atoi.c \
 	util/largepage.c
diff --git a/src/util/atoi.c b/src/util/atoi.c
new file mode 100644
index 0000000..65245a0
--- /dev/null
+++ b/src/util/atoi.c
@@ -0,0 +1,305 @@
+/* -*- Mode: C; c-basic-offset:4 ; indent-tabs-mode:nil ; -*- */
+/*
+ * See COPYRIGHT in top-level directory.
+ */
+
+#include "abti.h"
+
+static ABTU_ret_err int atoi_impl(const char *str, ABT_bool *p_is_signed,
+                                  uint64_t *p_val, ABT_bool *p_overflow);
+
+ABTU_ret_err int ABTU_atoi(const char *str, int *p_val, ABT_bool *p_overflow)
+{
+    uint64_t val;
+    ABT_bool overflow, is_signed;
+    int abt_errno = atoi_impl(str, &is_signed, &val, &overflow);
+    ABTI_CHECK_ERROR(abt_errno);
+    if (is_signed) {
+        if (val > (uint64_t)(-(int64_t)INT_MIN)) {
+            /* Underflow. */
+            overflow = ABT_TRUE;
+            *p_val = INT_MIN;
+        } else {
+            *p_val = (int)(-(int64_t)val);
+        }
+    } else {
+        if (val > (uint64_t)INT_MAX) {
+            /* Overflow. */
+            overflow = ABT_TRUE;
+            *p_val = INT_MAX;
+        } else {
+            *p_val = (int)val;
+        }
+    }
+    if (p_overflow)
+        *p_overflow = overflow;
+    return abt_errno;
+}
+
+ABTU_ret_err int ABTU_atoui32(const char *str, uint32_t *p_val,
+                              ABT_bool *p_overflow)
+{
+    uint64_t val;
+    ABT_bool overflow, is_signed;
+    int abt_errno = atoi_impl(str, &is_signed, &val, &overflow);
+    ABTI_CHECK_ERROR(abt_errno);
+    if (is_signed) {
+        /* Underflow. */
+        if (val != 0)
+            overflow = ABT_TRUE;
+        *p_val = 0;
+    } else {
+        if (val > (uint64_t)UINT32_MAX) {
+            /* Overflow. */
+            overflow = ABT_TRUE;
+            *p_val = UINT32_MAX;
+        } else {
+            *p_val = (uint32_t)val;
+        }
+    }
+    if (p_overflow)
+        *p_overflow = overflow;
+    return abt_errno;
+}
+
+ABTU_ret_err int ABTU_atoui64(const char *str, uint64_t *p_val,
+                              ABT_bool *p_overflow)
+{
+    uint64_t val;
+    ABT_bool overflow, is_signed;
+    int abt_errno = atoi_impl(str, &is_signed, &val, &overflow);
+    ABTI_CHECK_ERROR(abt_errno);
+    if (is_signed) {
+        /* Underflow. */
+        if (val != 0)
+            overflow = ABT_TRUE;
+        *p_val = 0;
+    } else {
+        *p_val = val;
+    }
+    if (p_overflow)
+        *p_overflow = overflow;
+    return abt_errno;
+}
+
+ABTU_ret_err int ABTU_atosz(const char *str, size_t *p_val,
+                            ABT_bool *p_overflow)
+{
+    ABTI_STATIC_ASSERT(sizeof(size_t) == 4 || sizeof(size_t) == 8);
+    if (sizeof(size_t) == 4) {
+        uint32_t val;
+        ABT_bool overflow;
+        int abt_errno = ABTU_atoui32(str, &val, &overflow);
+        ABTI_CHECK_ERROR(abt_errno);
+        *p_val = (size_t)val;
+        if (p_overflow)
+            *p_overflow = overflow;
+        return abt_errno;
+    } else {
+        uint64_t val;
+        ABT_bool overflow;
+        int abt_errno = ABTU_atoui64(str, &val, &overflow);
+        ABTI_CHECK_ERROR(abt_errno);
+        *p_val = (size_t)val;
+        if (p_overflow)
+            *p_overflow = overflow;
+        return abt_errno;
+    }
+}
+
+/*****************************************************************************/
+/* Internal static functions                                                 */
+/*****************************************************************************/
+
+static ABTU_ret_err int atoi_impl(const char *str, ABT_bool *p_is_signed,
+                                  uint64_t *p_val, ABT_bool *p_overflow)
+{
+    uint64_t val = 0;
+    ABT_bool is_signed = ABT_FALSE, read_char = ABT_FALSE,
+             read_digit = ABT_FALSE;
+    while (1) {
+        if ((*str == '\n' || *str == '\t' || *str == ' ' || *str == '\r') &&
+            read_char == ABT_FALSE) {
+            /* Do nothing. */
+        } else if (*str == '+' && read_digit == ABT_FALSE) {
+            read_char = ABT_TRUE;
+        } else if (*str == '-' && read_digit == ABT_FALSE) {
+            /* Flip the digit. */
+            read_char = ABT_TRUE;
+            is_signed = is_signed ? ABT_FALSE : ABT_TRUE;
+        } else if ('0' <= *str && *str <= '9') {
+            read_char = ABT_TRUE;
+            read_digit = ABT_TRUE;
+            /* Will val overflow? */
+            if ((val > UINT64_MAX / 10) ||
+                (val * 10 > UINT64_MAX - (uint64_t)(*str - '0'))) {
+                /* Overflow. */
+                *p_overflow = ABT_TRUE;
+                *p_val = UINT64_MAX;
+                *p_is_signed = is_signed;
+                return ABT_SUCCESS;
+            }
+            val = val * 10 + (uint64_t)(*str - '0');
+            read_digit = ABT_TRUE;
+        } else {
+            /* Stop reading str. */
+            if (read_digit == ABT_FALSE) {
+                /* No integer. */
+                return ABT_ERR_INV_ARG;
+            }
+            *p_overflow = ABT_FALSE;
+            *p_val = val;
+            *p_is_signed = is_signed;
+            return ABT_SUCCESS;
+        }
+        str++;
+    }
+}
+
+#if 0
+
+void test_ABTU_atoi(const char *str, int err, int val, ABT_bool overflow)
+{
+    int ret_val;
+    ABT_bool ret_overflow;
+    int ret_err = ABTU_atoi(str, &ret_val, &ret_overflow);
+    assert(err == ret_err);
+    if (err == ABT_SUCCESS) {
+        assert(val == ret_val);
+        assert(overflow == ret_overflow);
+    }
+}
+
+void test_ABTU_atoui32(const char *str, int err, uint32_t val, ABT_bool overflow)
+{
+    uint32_t ret_val;
+    ABT_bool ret_overflow;
+    int ret_err = ABTU_atoui32(str, &ret_val, &ret_overflow);
+    assert(err == ret_err);
+    if (err == ABT_SUCCESS) {
+        assert(val == ret_val);
+        assert(overflow == ret_overflow);
+    }
+}
+
+void test_ABTU_atoui64(const char *str, int err, uint64_t val, ABT_bool overflow)
+{
+    uint64_t ret_val;
+    ABT_bool ret_overflow;
+    int ret_err = ABTU_atoui64(str, &ret_val, &ret_overflow);
+    assert(err == ret_err);
+    if (err == ABT_SUCCESS) {
+        assert(val == ret_val);
+        assert(overflow == ret_overflow);
+    }
+}
+
+void test_ABTU_atosz(const char *str, int err, size_t val, ABT_bool overflow)
+{
+    size_t ret_val;
+    ABT_bool ret_overflow;
+    int ret_err = ABTU_atosz(str, &ret_val, &ret_overflow);
+    assert(err == ret_err);
+    if (err == ABT_SUCCESS) {
+        assert(val == ret_val);
+        assert(overflow == ret_overflow);
+    }
+}
+
+int main()
+{
+    typedef struct {
+        const char *str;
+        int err;
+        int val;
+    } base_case_t;
+
+    /* Basic cases (no overflow). */
+    base_case_t cases[] = {
+        { "0", ABT_SUCCESS, 0 },
+        { "63", ABT_SUCCESS, 63 },
+        { "+14", ABT_SUCCESS, 14 },
+        { "+0", ABT_SUCCESS, 0 },
+        { "+-+-+---++0", ABT_SUCCESS, 0 },
+        { "+-+-+---+-+8800", ABT_SUCCESS, 8800 },
+        { "----1---", ABT_SUCCESS, 1 },
+        { "abc", ABT_ERR_INV_ARG, 0 },
+        { "13abc", ABT_SUCCESS, 13 },
+        { "000123456", ABT_SUCCESS, 123456 },
+        { "00000000", ABT_SUCCESS, 0 },
+        { "123x456", ABT_SUCCESS, 123 },
+        { "123+456", ABT_SUCCESS, 123 },
+        { "123 456", ABT_SUCCESS, 123 },
+        { "--12-3-45-6", ABT_SUCCESS, 12 },
+        { "", ABT_ERR_INV_ARG, 0 },
+        { "+", ABT_ERR_INV_ARG, 0 },
+        { "-", ABT_ERR_INV_ARG, 0 },
+        { "+ 2", ABT_ERR_INV_ARG, 0 },
+        { "    \n\t\r+-+-", ABT_ERR_INV_ARG, 0 },
+        { "    \n\t\r+-+-123", ABT_SUCCESS, 123 },
+    };
+
+    size_t i;
+    for (i = 0; i < sizeof(cases) / sizeof(cases[0]); i++) {
+        test_ABTU_atoi(cases[i].str, cases[i].err, cases[i].val, ABT_FALSE);
+        test_ABTU_atoui32(cases[i].str, cases[i].err, cases[i].val, ABT_FALSE);
+        test_ABTU_atoui64(cases[i].str, cases[i].err, cases[i].val, ABT_FALSE);
+        test_ABTU_atosz(cases[i].str, cases[i].err, cases[i].val, ABT_FALSE);
+    }
+
+    /* Check negative values. */
+    test_ABTU_atoi("-1", ABT_SUCCESS, -1, ABT_FALSE);
+    test_ABTU_atoi("-9990", ABT_SUCCESS, -9990, ABT_FALSE);
+    test_ABTU_atoi(" --+-1234a-", ABT_SUCCESS, -1234, ABT_FALSE);
+
+    /* Check overflow/underflow */
+    test_ABTU_atoi("2147483646", ABT_SUCCESS, 2147483646, ABT_FALSE);
+    test_ABTU_atoi("2147483647", ABT_SUCCESS, 2147483647, ABT_FALSE);
+    test_ABTU_atoi("2147483648", ABT_SUCCESS, 2147483647, ABT_TRUE);
+    test_ABTU_atoi("11112147483648", ABT_SUCCESS, 2147483647, ABT_TRUE);
+    test_ABTU_atoi("-2147483647", ABT_SUCCESS, -2147483647, ABT_FALSE);
+    test_ABTU_atoi("-2147483648", ABT_SUCCESS, -2147483648, ABT_FALSE);
+    test_ABTU_atoi("-2147483649", ABT_SUCCESS, -2147483648, ABT_TRUE);
+    test_ABTU_atoi("-11112147483648", ABT_SUCCESS, -2147483648, ABT_TRUE);
+
+    test_ABTU_atoui32("4294967294", ABT_SUCCESS, 4294967294, ABT_FALSE);
+    test_ABTU_atoui32("4294967295", ABT_SUCCESS, 4294967295, ABT_FALSE);
+    test_ABTU_atoui32("4294967296", ABT_SUCCESS, 4294967295, ABT_TRUE);
+    test_ABTU_atoui32("11114294967295", ABT_SUCCESS, 4294967295, ABT_TRUE);
+    test_ABTU_atoui32("-1", ABT_SUCCESS, 0, ABT_TRUE);
+    test_ABTU_atoui32("-2147483649", ABT_SUCCESS, 0, ABT_TRUE);
+
+    test_ABTU_atoui64("18446744073709551614", ABT_SUCCESS,
+                      18446744073709551614u, ABT_FALSE);
+    test_ABTU_atoui64("18446744073709551615", ABT_SUCCESS,
+                      18446744073709551615u, ABT_FALSE);
+    test_ABTU_atoui64("18446744073709551616", ABT_SUCCESS,
+                      18446744073709551615u, ABT_TRUE);
+    test_ABTU_atoui64("111118446744073709551615", ABT_SUCCESS,
+                      18446744073709551615u, ABT_TRUE);
+    test_ABTU_atoui64("-1", ABT_SUCCESS, 0, ABT_TRUE);
+    test_ABTU_atoui64("-18446744073709551616", ABT_SUCCESS, 0, ABT_TRUE);
+
+    if (sizeof(size_t) == 4) {
+        test_ABTU_atosz("4294967294", ABT_SUCCESS, 4294967294, ABT_FALSE);
+        test_ABTU_atosz("4294967295", ABT_SUCCESS, 4294967295, ABT_FALSE);
+        test_ABTU_atosz("4294967296", ABT_SUCCESS, 4294967295, ABT_TRUE);
+        test_ABTU_atosz("11114294967295", ABT_SUCCESS, 4294967295, ABT_TRUE);
+        test_ABTU_atosz("-1", ABT_SUCCESS, 0, ABT_TRUE);
+        test_ABTU_atosz("-2147483649", ABT_SUCCESS, 0, ABT_TRUE);
+    } else {
+        assert(sizeof(size_t) == 8);
+        test_ABTU_atosz("18446744073709551614", ABT_SUCCESS,
+                        18446744073709551614u, ABT_FALSE);
+        test_ABTU_atosz("18446744073709551615", ABT_SUCCESS,
+                        18446744073709551615u, ABT_FALSE);
+        test_ABTU_atosz("18446744073709551616", ABT_SUCCESS,
+                        18446744073709551615u, ABT_TRUE);
+        test_ABTU_atosz("111118446744073709551615", ABT_SUCCESS,
+                        18446744073709551615u, ABT_TRUE);
+        test_ABTU_atosz("-1", ABT_SUCCESS, 0, ABT_TRUE);
+        test_ABTU_atosz("-18446744073709551616", ABT_SUCCESS, 0, ABT_TRUE);
+    }
+}
+
+#endif
-- 
2.21.0 (Apple Git-122.2)


From b2b0ab4cdfce91b1d4c86e330a77926beaaf2a17 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Thu, 12 Nov 2020 14:28:53 -0600
Subject: [PATCH 09/40] env: remove os_page_size

os_page_size is not used.  This patch removes it.
---
 src/arch/abtd_env.c | 11 -----------
 src/include/abti.h  |  1 -
 src/info.c          |  1 -
 3 files changed, 13 deletions(-)

diff --git a/src/arch/abtd_env.c b/src/arch/abtd_env.c
index 96f32fa..d2f8bad 100644
--- a/src/arch/abtd_env.c
+++ b/src/arch/abtd_env.c
@@ -13,7 +13,6 @@
 #define ABTD_SCHED_EVENT_FREQ 50
 #define ABTD_SCHED_SLEEP_NSEC 100
 
-#define ABTD_OS_PAGE_SIZE (4 * 1024)
 #define ABTD_HUGE_PAGE_SIZE (2 * 1024 * 1024)
 #define ABTD_MEM_PAGE_SIZE (2 * 1024 * 1024)
 #define ABTD_MEM_STACK_PAGE_SIZE (8 * 1024 * 1024)
@@ -173,16 +172,6 @@ void ABTD_env_init(ABTI_global *p_global)
         p_global->mutex_max_wakeups = 1;
     }
 
-    /* OS page size */
-    env = getenv("ABT_OS_PAGE_SIZE");
-    if (env == NULL)
-        env = getenv("ABT_ENV_OS_PAGE_SIZE");
-    if (env != NULL) {
-        p_global->os_page_size = (uint32_t)atol(env);
-    } else {
-        p_global->os_page_size = ABTD_OS_PAGE_SIZE;
-    }
-
     /* Huge page size */
     env = getenv("ABT_HUGE_PAGE_SIZE");
     if (env == NULL)
diff --git a/src/include/abti.h b/src/include/abti.h
index 803463e..cf010b2 100644
--- a/src/include/abti.h
+++ b/src/include/abti.h
@@ -187,7 +187,6 @@ struct ABTI_global {
 
     uint32_t mutex_max_handovers; /* Default max. # of local handovers */
     uint32_t mutex_max_wakeups;   /* Default max. # of wakeups */
-    uint32_t os_page_size;        /* OS page size */
     uint32_t huge_page_size;      /* Huge page size */
 #ifdef ABT_CONFIG_USE_MEM_POOL
     uint32_t mem_page_size;  /* Page size for memory allocation */
diff --git a/src/info.c b/src/info.c
index cb48385..bab6c97 100644
--- a/src/info.c
+++ b/src/info.c
@@ -593,7 +593,6 @@ void ABTI_info_print_config(FILE *fp)
     fprintf(fp, "Argobots Configuration:\n");
     fprintf(fp, " - # of cores: %d\n", p_global->num_cores);
     fprintf(fp, " - cache line size: %u\n", ABT_CONFIG_STATIC_CACHELINE_SIZE);
-    fprintf(fp, " - OS page size: %u\n", p_global->os_page_size);
     fprintf(fp, " - huge page size: %u\n", p_global->huge_page_size);
     fprintf(fp, " - max. # of ESs: %d\n", p_global->max_xstreams);
     fprintf(fp, " - cur. # of ESs: %d\n", p_global->num_xstreams);
-- 
2.21.0 (Apple Git-122.2)


From 9ca15607ac2ee9a4bbdd04de5114a3b3b17ca415 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Thu, 12 Nov 2020 14:38:32 -0600
Subject: [PATCH 10/40] env: use a larger integer type to store some
 environment variables

Some environmental variables can be potentially large, but they are saved to
32-bit integers (e.g., huge page size, which can be more than 4 GB).  This patch
uses larger integer types for these variables so that we can store those values
without overflow.
---
 src/arch/abtd_env.c    | 10 +++++-----
 src/include/abti.h     | 10 +++++-----
 src/include/abti_key.h |  2 +-
 src/info.c             | 17 +++++++++--------
 4 files changed, 20 insertions(+), 19 deletions(-)

diff --git a/src/arch/abtd_env.c b/src/arch/abtd_env.c
index d2f8bad..22ba247 100644
--- a/src/arch/abtd_env.c
+++ b/src/arch/abtd_env.c
@@ -89,18 +89,18 @@ void ABTD_env_init(ABTI_global *p_global)
     if (env == NULL)
         env = getenv("ABT_ENV_KEY_TABLE_SIZE");
     if (env != NULL) {
-        p_global->key_table_size = (int)atoi(env);
+        p_global->key_table_size = (uint32_t)atoi(env);
     } else {
         p_global->key_table_size = ABTD_KEY_TABLE_DEFAULT_SIZE;
     }
     /* key_table_size must be a power of 2. */
     {
         int i;
-        for (i = 0; i < sizeof(int) * 8; i++) {
+        for (i = 0; i < sizeof(size_t) * 8; i++) {
             if ((p_global->key_table_size - 1) >> i == 0)
                 break;
         }
-        p_global->key_table_size = 1 << i;
+        p_global->key_table_size = ((uint32_t)1) << i;
     }
 
     /* Default stack size for ULT */
@@ -177,7 +177,7 @@ void ABTD_env_init(ABTI_global *p_global)
     if (env == NULL)
         env = getenv("ABT_ENV_HUGE_PAGE_SIZE");
     if (env != NULL) {
-        p_global->huge_page_size = (uint32_t)atol(env);
+        p_global->huge_page_size = (size_t)atol(env);
     } else {
         p_global->huge_page_size = ABTD_HUGE_PAGE_SIZE;
     }
@@ -188,7 +188,7 @@ void ABTD_env_init(ABTI_global *p_global)
     if (env == NULL)
         env = getenv("ABT_ENV_MEM_PAGE_SIZE");
     if (env != NULL) {
-        p_global->mem_page_size = (uint32_t)atol(env);
+        p_global->mem_page_size = (size_t)atol(env);
     } else {
         p_global->mem_page_size = ABTD_MEM_PAGE_SIZE;
     }
diff --git a/src/include/abti.h b/src/include/abti.h
index cf010b2..597d629 100644
--- a/src/include/abti.h
+++ b/src/include/abti.h
@@ -178,19 +178,19 @@ struct ABTI_global {
     ABT_bool set_affinity;        /* Whether CPU affinity is used */
     ABT_bool use_logging;         /* Whether logging is used */
     ABT_bool use_debug;           /* Whether debug output is used */
-    int key_table_size;           /* Default key table size */
+    uint32_t key_table_size;      /* Default key table size */
     size_t thread_stacksize;      /* Default stack size for ULT (in bytes) */
     size_t sched_stacksize;       /* Default stack size for sched (in bytes) */
     uint32_t sched_event_freq;    /* Default check frequency for sched */
-    long sched_sleep_nsec;        /* Default nanoseconds for scheduler sleep */
+    uint64_t sched_sleep_nsec;    /* Default nanoseconds for scheduler sleep */
     ABTI_ythread *p_main_ythread; /* ULT of the main function */
 
     uint32_t mutex_max_handovers; /* Default max. # of local handovers */
     uint32_t mutex_max_wakeups;   /* Default max. # of wakeups */
-    uint32_t huge_page_size;      /* Huge page size */
+    size_t huge_page_size;        /* Huge page size */
 #ifdef ABT_CONFIG_USE_MEM_POOL
-    uint32_t mem_page_size;  /* Page size for memory allocation */
-    uint32_t mem_sp_size;    /* Stack page size */
+    size_t mem_page_size;    /* Page size for memory allocation */
+    size_t mem_sp_size;      /* Stack page size */
     uint32_t mem_max_stacks; /* Max. # of stacks kept in each ES */
     uint32_t mem_max_descs;  /* Max. # of descriptors kept in each ES */
     int mem_lp_alloc;        /* How to allocate large pages */
diff --git a/src/include/abti_key.h b/src/include/abti_key.h
index b174611..b7254aa 100644
--- a/src/include/abti_key.h
+++ b/src/include/abti_key.h
@@ -68,7 +68,7 @@ ABTU_ret_err static inline int ABTI_ktable_create(ABTI_local *p_local,
                                                   ABTI_ktable **pp_ktable)
 {
     ABTI_ktable *p_ktable;
-    int key_table_size = gp_ABTI_global->key_table_size;
+    uint32_t key_table_size = gp_ABTI_global->key_table_size;
     /* size must be a power of 2. */
     ABTI_ASSERT((key_table_size & (key_table_size - 1)) == 0);
     /* max alignment must be a power of 2. */
diff --git a/src/info.c b/src/info.c
index bab6c97..e05f480 100644
--- a/src/info.c
+++ b/src/info.c
@@ -593,7 +593,7 @@ void ABTI_info_print_config(FILE *fp)
     fprintf(fp, "Argobots Configuration:\n");
     fprintf(fp, " - # of cores: %d\n", p_global->num_cores);
     fprintf(fp, " - cache line size: %u\n", ABT_CONFIG_STATIC_CACHELINE_SIZE);
-    fprintf(fp, " - huge page size: %u\n", p_global->huge_page_size);
+    fprintf(fp, " - huge page size: %zu\n", p_global->huge_page_size);
     fprintf(fp, " - max. # of ESs: %d\n", p_global->max_xstreams);
     fprintf(fp, " - cur. # of ESs: %d\n", p_global->num_xstreams);
     fprintf(fp, " - ES affinity: %s\n",
@@ -602,11 +602,12 @@ void ABTI_info_print_config(FILE *fp)
             (p_global->use_logging == ABT_TRUE) ? "on" : "off");
     fprintf(fp, " - debug output: %s\n",
             (p_global->use_debug == ABT_TRUE) ? "on" : "off");
-    fprintf(fp, " - key table entries: %d\n", p_global->key_table_size);
-    fprintf(fp, " - ULT stack size: %u KB\n",
-            (unsigned)(p_global->thread_stacksize / 1024));
-    fprintf(fp, " - scheduler stack size: %u KB\n",
-            (unsigned)(p_global->sched_stacksize / 1024));
+    fprintf(fp, " - key table entries: %" PRIu32 "\n",
+            p_global->key_table_size);
+    fprintf(fp, " - ULT stack size: %zu KB\n",
+            p_global->thread_stacksize / 1024);
+    fprintf(fp, " - scheduler stack size: %zu KB\n",
+            p_global->sched_stacksize / 1024);
     fprintf(fp, " - scheduler event check frequency: %u\n",
             p_global->sched_event_freq);
 
@@ -622,9 +623,9 @@ void ABTI_info_print_config(FILE *fp)
 
 #ifdef ABT_CONFIG_USE_MEM_POOL
     fprintf(fp, "Memory Pool:\n");
-    fprintf(fp, " - page size for allocation: %u KB\n",
+    fprintf(fp, " - page size for allocation: %zu KB\n",
             p_global->mem_page_size / 1024);
-    fprintf(fp, " - stack page size: %u KB\n", p_global->mem_sp_size / 1024);
+    fprintf(fp, " - stack page size: %zu KB\n", p_global->mem_sp_size / 1024);
     fprintf(fp, " - max. # of stacks per ES: %u\n", p_global->mem_max_stacks);
     switch (p_global->mem_lp_alloc) {
         case ABTI_MEM_LP_MALLOC:
-- 
2.21.0 (Apple Git-122.2)


From 15dcbaa8eb0841fdc6d576dff6f923b84be41d5e Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Thu, 12 Nov 2020 14:52:55 -0600
Subject: [PATCH 11/40] env: clean up ABTD_env_init

ABTD_env_init() ignored, asserted, or silently fixed values when Argobots'
environment variables have illegal values.  This patch simplifies the logic by
unifying the behavior; illegal values are silently adjusted.  This patch also
fixes misuses of atoi() and atol() for size_t, uint32_t, and uint64_t.
---
 src/arch/abtd_env.c | 456 +++++++++++++++++++++++++-------------------
 1 file changed, 262 insertions(+), 194 deletions(-)

diff --git a/src/arch/abtd_env.c b/src/arch/abtd_env.c
index 22ba247..70d54a8 100644
--- a/src/arch/abtd_env.c
+++ b/src/arch/abtd_env.c
@@ -20,228 +20,164 @@
 #define ABTD_MEM_MAX_TOTAL_STACK_SIZE (64 * 1024 * 1024)
 #define ABTD_MEM_MAX_NUM_DESCS 4096
 
+/* To avoid potential overflow, we intentionally use a smaller value than the
+ * real limit. */
+#define ABTD_ENV_INT_MAX ((int)(INT_MAX / 2))
+#define ABTD_ENV_UINT32_MAX ((int)(UINT32_MAX / 2))
+#define ABTD_ENV_UINT64_MAX ((int)(UINT64_MAX / 2))
+#define ABTD_ENV_SIZE_MAX ((int)(SIZE_MAX / 2))
+
+static uint32_t roundup_pow2_uint32(uint32_t val);
+static const char *get_abt_env(const char *env_suffix);
+static ABT_bool is_false(const char *str, ABT_bool include0);
+static ABT_bool is_true(const char *str, ABT_bool include1);
+static ABT_bool load_env_bool(const char *env_suffix, ABT_bool default_val);
+static int load_env_int(const char *env_suffix, int default_val, int min_val,
+                        int max_val);
+static uint32_t load_env_uint32(const char *env_suffix, uint32_t default_val,
+                                uint32_t min_val, uint32_t max_val);
+static uint64_t load_env_uint64(const char *env_suffix, uint64_t default_val,
+                                uint64_t min_val, uint64_t max_val);
+static size_t load_env_size(const char *env_suffix, size_t default_val,
+                            size_t min_val, size_t max_val);
+
 void ABTD_env_init(ABTI_global *p_global)
 {
-    char *env;
+    const char *env;
 
     /* Get the number of available cores in the system */
     p_global->num_cores = sysconf(_SC_NPROCESSORS_ONLN);
 
-    /* By default, we use the CPU affinity */
-    p_global->set_affinity = ABT_TRUE;
-    env = getenv("ABT_SET_AFFINITY");
-    if (env == NULL)
-        env = getenv("ABT_ENV_SET_AFFINITY");
-    if (env != NULL) {
-        if (strcasecmp(env, "n") == 0 || strcasecmp(env, "no") == 0) {
-            p_global->set_affinity = ABT_FALSE;
-        }
-    }
-    if (p_global->set_affinity == ABT_TRUE) {
+    /* ABT_SET_AFFINITY, ABT_ENV_SET_AFFINITY */
+    env = get_abt_env("SET_AFFINITY");
+    if (env != NULL && is_false(env, ABT_FALSE)) {
+        p_global->set_affinity = ABT_FALSE;
+    } else {
+        /* By default, we use the CPU affinity */
+        p_global->set_affinity = ABT_TRUE;
         ABTD_affinity_init(env);
     }
 
 #ifdef ABT_CONFIG_USE_DEBUG_LOG_PRINT
     /* If the debug log printing is set in configure, logging is turned on by
      * default. */
-    p_global->use_logging = ABT_TRUE;
-    p_global->use_debug = ABT_TRUE;
+    const ABT_bool default_use_logging = ABT_TRUE;
+    const ABT_bool default_use_debug = ABT_TRUE;
 #else
     /* Otherwise, logging is not turned on by default. */
-    p_global->use_logging = ABT_FALSE;
-    p_global->use_debug = ABT_FALSE;
+    const ABT_bool default_use_logging = ABT_FALSE;
+    const ABT_bool default_use_debug = ABT_FALSE;
 #endif
-    env = getenv("ABT_USE_LOG");
-    if (env == NULL)
-        env = getenv("ABT_ENV_USE_LOG");
-    if (env != NULL) {
-        if (strcmp(env, "0") == 0 || strcasecmp(env, "n") == 0 ||
-            strcasecmp(env, "no") == 0) {
-            p_global->use_logging = ABT_FALSE;
-        } else {
-            p_global->use_logging = ABT_TRUE;
-        }
-    }
-    env = getenv("ABT_USE_DEBUG");
-    if (env == NULL)
-        env = getenv("ABT_ENV_USE_DEBUG");
-    if (env != NULL) {
-        if (strcmp(env, "0") == 0 || strcasecmp(env, "n") == 0 ||
-            strcasecmp(env, "no") == 0) {
-            p_global->use_debug = ABT_FALSE;
-        } else {
-            p_global->use_debug = ABT_TRUE;
-        }
-    }
+    /* ABT_USE_LOG, ABT_ENV_USE_LOG */
+    p_global->use_logging = load_env_bool("USE_LOG", default_use_logging);
 
-    /* Maximum size of the internal ES array */
-    env = getenv("ABT_MAX_NUM_XSTREAMS");
-    if (env == NULL)
-        env = getenv("ABT_ENV_MAX_NUM_XSTREAMS");
-    if (env != NULL) {
-        p_global->max_xstreams = atoi(env);
-    } else {
-        p_global->max_xstreams = p_global->num_cores;
-    }
+    /* ABT_USE_DEBUG, ABT_ENV_USE_DEBUG */
+    p_global->use_debug = load_env_bool("USE_DEBUG", default_use_debug);
 
-    /* Default key table size */
-    env = getenv("ABT_KEY_TABLE_SIZE");
-    if (env == NULL)
-        env = getenv("ABT_ENV_KEY_TABLE_SIZE");
-    if (env != NULL) {
-        p_global->key_table_size = (uint32_t)atoi(env);
-    } else {
-        p_global->key_table_size = ABTD_KEY_TABLE_DEFAULT_SIZE;
-    }
-    /* key_table_size must be a power of 2. */
-    {
-        int i;
-        for (i = 0; i < sizeof(size_t) * 8; i++) {
-            if ((p_global->key_table_size - 1) >> i == 0)
-                break;
-        }
-        p_global->key_table_size = ((uint32_t)1) << i;
-    }
+    /* ABT_MAX_NUM_XSTREAMS, ABT_ENV_MAX_NUM_XSTREAMS
+     * Maximum size of the internal ES array */
+    p_global->max_xstreams =
+        load_env_int("MAX_NUM_XSTREAMS", p_global->num_cores, 1,
+                     ABTD_ENV_INT_MAX);
 
-    /* Default stack size for ULT */
-    env = getenv("ABT_THREAD_STACKSIZE");
-    if (env == NULL)
-        env = getenv("ABT_ENV_THREAD_STACKSIZE");
-    if (env != NULL) {
-        p_global->thread_stacksize = (size_t)atol(env);
-        ABTI_ASSERT(p_global->thread_stacksize >= 512);
-    } else {
-        p_global->thread_stacksize = ABTD_THREAD_DEFAULT_STACKSIZE;
-    }
-    /* Stack size must be a multiple of cacheline size. */
+    /* ABT_KEY_TABLE_SIZE, ABT_ENV_KEY_TABLE_SIZE
+     * Default key table size */
+    p_global->key_table_size = roundup_pow2_uint32(
+        load_env_uint32("KEY_TABLE_SIZE", ABTD_KEY_TABLE_DEFAULT_SIZE, 1,
+                        ABTD_ENV_UINT32_MAX));
+
+    /* ABT_THREAD_STACKSIZE, ABT_ENV_THREAD_STACKSIZE
+     * Default stack size for ULT */
     p_global->thread_stacksize =
-        ABTU_roundup_size(p_global->thread_stacksize,
+        ABTU_roundup_size(load_env_size("THREAD_STACKSIZE",
+                                        ABTD_THREAD_DEFAULT_STACKSIZE, 512,
+                                        ABTD_ENV_SIZE_MAX),
                           ABT_CONFIG_STATIC_CACHELINE_SIZE);
 
-    /* Default stack size for scheduler */
-    env = getenv("ABT_SCHED_STACKSIZE");
-    if (env == NULL)
-        env = getenv("ABT_ENV_SCHED_STACKSIZE");
-    if (env != NULL) {
-        p_global->sched_stacksize = (size_t)atol(env);
-        ABTI_ASSERT(p_global->sched_stacksize >= 512);
-    } else {
-        p_global->sched_stacksize = ABTD_SCHED_DEFAULT_STACKSIZE;
-    }
+    /* ABT_SCHED_STACKSIZE, ABT_ENV_SCHED_STACKSIZE
+     * Default stack size for scheduler */
+    p_global->sched_stacksize =
+        ABTU_roundup_size(load_env_size("SCHED_STACKSIZE",
+                                        ABTD_SCHED_DEFAULT_STACKSIZE, 512,
+                                        ABTD_ENV_SIZE_MAX),
+                          ABT_CONFIG_STATIC_CACHELINE_SIZE);
 
-    /* Default frequency for event checking by the scheduler */
-    env = getenv("ABT_SCHED_EVENT_FREQ");
-    if (env == NULL)
-        env = getenv("ABT_ENV_SCHED_EVENT_FREQ");
-    if (env != NULL) {
-        p_global->sched_event_freq = (uint32_t)atol(env);
-        ABTI_ASSERT(p_global->sched_event_freq >= 1);
-    } else {
-        p_global->sched_event_freq = ABTD_SCHED_EVENT_FREQ;
-    }
+    /* ABT_SCHED_EVENT_FREQ, ABT_ENV_SCHED_EVENT_FREQ
+     * Default frequency for event checking by the scheduler */
+    p_global->sched_event_freq =
+        load_env_uint32("SCHED_EVENT_FREQ", ABTD_SCHED_EVENT_FREQ, 1,
+                        ABTD_ENV_UINT32_MAX);
 
-    /* Default nanoseconds for scheduler sleep */
-    env = getenv("ABT_SCHED_SLEEP_NSEC");
-    if (env == NULL)
-        env = getenv("ABT_ENV_SCHED_SLEEP_NSEC");
-    if (env != NULL) {
-        p_global->sched_sleep_nsec = atol(env);
-        ABTI_ASSERT(p_global->sched_sleep_nsec >= 0);
-    } else {
-        p_global->sched_sleep_nsec = ABTD_SCHED_SLEEP_NSEC;
-    }
+    /* ABT_SCHED_SLEEP_NSEC, ABT_ENV_SCHED_SLEEP_NSEC
+     * Default nanoseconds for scheduler sleep */
+    p_global->sched_sleep_nsec =
+        load_env_uint64("SCHED_SLEEP_NSEC", ABTD_SCHED_SLEEP_NSEC, 0,
+                        ABTD_ENV_UINT64_MAX);
 
-    /* Mutex attributes */
-    env = getenv("ABT_MUTEX_MAX_HANDOVERS");
-    if (env == NULL)
-        env = getenv("ABT_ENV_MUTEX_MAX_HANDOVERS");
-    if (env != NULL) {
-        p_global->mutex_max_handovers = (uint32_t)atoi(env);
-        ABTI_ASSERT(p_global->mutex_max_handovers >= 1);
-    } else {
-        p_global->mutex_max_handovers = 64;
-    }
+    /* ABT_MUTEX_MAX_HANDOVERS, ABT_ENV_MUTEX_MAX_HANDOVERS
+     * Default maximum number of mutex handover */
+    p_global->mutex_max_handovers =
+        load_env_uint32("MUTEX_MAX_HANDOVERS", 64, 1, ABTD_ENV_UINT32_MAX);
 
-    env = getenv("ABT_MUTEX_MAX_WAKEUPS");
-    if (env == NULL)
-        env = getenv("ABT_ENV_MUTEX_MAX_WAKEUPS");
-    if (env != NULL) {
-        p_global->mutex_max_wakeups = (uint32_t)atoi(env);
-        ABTI_ASSERT(p_global->mutex_max_wakeups >= 1);
-    } else {
-        p_global->mutex_max_wakeups = 1;
-    }
+    /* ABT_MUTEX_MAX_WAKEUPS, ABT_ENV_MUTEX_MAX_WAKEUPS
+     * Default maximum number of mutex wakeup operations */
+    p_global->mutex_max_wakeups =
+        load_env_uint32("MUTEX_MAX_WAKEUPS", 1, 1, ABTD_ENV_UINT32_MAX);
 
-    /* Huge page size */
-    env = getenv("ABT_HUGE_PAGE_SIZE");
-    if (env == NULL)
-        env = getenv("ABT_ENV_HUGE_PAGE_SIZE");
-    if (env != NULL) {
-        p_global->huge_page_size = (size_t)atol(env);
-    } else {
-        p_global->huge_page_size = ABTD_HUGE_PAGE_SIZE;
-    }
+    /* ABT_HUGE_PAGE_SIZE, ABT_ENV_HUGE_PAGE_SIZE
+     * Huge page size */
+    p_global->huge_page_size =
+        load_env_size("HUGE_PAGE_SIZE", ABTD_HUGE_PAGE_SIZE, 4096,
+                      ABTD_ENV_SIZE_MAX);
 
 #ifdef ABT_CONFIG_USE_MEM_POOL
-    /* Page size for memory allocation */
-    env = getenv("ABT_MEM_PAGE_SIZE");
-    if (env == NULL)
-        env = getenv("ABT_ENV_MEM_PAGE_SIZE");
-    if (env != NULL) {
-        p_global->mem_page_size = (size_t)atol(env);
-    } else {
-        p_global->mem_page_size = ABTD_MEM_PAGE_SIZE;
-    }
+    /* ABT_MEM_PAGE_SIZE, ABT_ENV_MEM_PAGE_SIZE
+     * Page size for memory allocation */
+    p_global->mem_page_size =
+        ABTU_roundup_size(load_env_size("MEM_PAGE_SIZE", ABTD_MEM_PAGE_SIZE,
+                                        4096, ABTD_ENV_SIZE_MAX),
+                          ABT_CONFIG_STATIC_CACHELINE_SIZE);
 
-    /* Stack page size for memory allocation */
-    env = getenv("ABT_MEM_STACK_PAGE_SIZE");
-    if (env == NULL)
-        env = getenv("ABT_ENV_MEM_STACK_PAGE_SIZE");
-    if (env != NULL) {
-        p_global->mem_sp_size = (size_t)atol(env);
-    } else {
-        p_global->mem_sp_size = ABTD_MEM_STACK_PAGE_SIZE;
-    }
+    /* ABT_MEM_STACK_PAGE_SIZE, ABT_ENV_MEM_STACK_PAGE_SIZE
+     * Stack page size for memory allocation */
+    p_global->mem_sp_size =
+        ABTU_roundup_size(load_env_size("MEM_STACK_PAGE_SIZE",
+                                        ABTD_MEM_STACK_PAGE_SIZE,
+                                        p_global->thread_stacksize * 4,
+                                        ABTD_ENV_SIZE_MAX),
+                          ABT_CONFIG_STATIC_CACHELINE_SIZE);
 
-    /* Maximum number of stacks that each ES can keep during execution */
-    env = getenv("ABT_MEM_MAX_NUM_STACKS");
-    if (env == NULL)
-        env = getenv("ABT_ENV_MEM_MAX_NUM_STACKS");
-    if (env != NULL) {
-        p_global->mem_max_stacks = (uint32_t)atol(env);
-    } else {
-        /* Each execution stream caches too many stacks in total. Let's
-         * reduce the max # of stacks. */
-        p_global->mem_max_stacks =
-            ABTU_min_uint32(ABTD_MEM_MAX_TOTAL_STACK_SIZE /
-                                p_global->thread_stacksize,
-                            ABTD_MEM_MAX_NUM_STACKS);
-    }
+    /* ABT_MEM_MAX_NUM_STACKS, ABT_ENV_MEM_MAX_NUM_STACKS
+     * Maximum number of stacks that each ES can keep during execution. */
+    /* If each execution stream caches too many stacks in total, let's reduce
+     * the max # of stacks. */
+    const uint32_t default_mem_max_stacks =
+        ABTU_min_uint32(ABTD_MEM_MAX_TOTAL_STACK_SIZE /
+                            p_global->thread_stacksize,
+                        ABTD_MEM_MAX_NUM_STACKS);
     /* The value must be a multiple of ABT_MEM_POOL_MAX_LOCAL_BUCKETS. */
     p_global->mem_max_stacks =
-        ABTU_roundup_uint32(p_global->mem_max_stacks,
+        ABTU_roundup_uint32(load_env_uint32("MEM_MAX_NUM_STACKS",
+                                            default_mem_max_stacks,
+                                            ABT_MEM_POOL_MAX_LOCAL_BUCKETS,
+                                            ABTD_ENV_UINT32_MAX),
                             ABT_MEM_POOL_MAX_LOCAL_BUCKETS);
 
-    /* Maximum number of descriptors that each ES can keep during execution */
-    env = getenv("ABT_MEM_MAX_NUM_DESCS");
-    if (env == NULL)
-        env = getenv("ABT_ENV_MEM_MAX_NUM_DESCS");
-    if (env != NULL) {
-        p_global->mem_max_descs = (uint32_t)atol(env);
-    } else {
-        p_global->mem_max_descs = ABTD_MEM_MAX_NUM_DESCS;
-    }
+    /* ABT_MEM_MAX_NUM_DESCS, ABT_ENV_MEM_MAX_NUM_DESCS
+     * Maximum number of descriptors that each ES can keep during execution */
     /* The value must be a multiple of ABT_MEM_POOL_MAX_LOCAL_BUCKETS. */
     p_global->mem_max_descs =
-        ABTU_roundup_uint32(p_global->mem_max_descs,
+        ABTU_roundup_uint32(load_env_uint32("MEM_MAX_NUM_DESCS",
+                                            ABTD_MEM_MAX_NUM_DESCS,
+                                            ABT_MEM_POOL_MAX_LOCAL_BUCKETS,
+                                            ABTD_ENV_UINT32_MAX),
                             ABT_MEM_POOL_MAX_LOCAL_BUCKETS);
 
-    /* How to allocate large pages.  The default is to use mmap() for huge
+    /* ABT_MEM_LP_ALLOC, ABT_ENV_MEM_LP_ALLOC
+     * How to allocate large pages.  The default is to use mmap() for huge
      * pages and then to fall back to allocate regular pages using mmap() when
      * huge pages are run out of. */
-    env = getenv("ABT_MEM_LP_ALLOC");
-    if (env == NULL)
-        env = getenv("ABT_ENV_MEM_LP_ALLOC");
+    env = get_abt_env("MEM_LP_ALLOC");
 #if defined(HAVE_MAP_ANONYMOUS) || defined(HAVE_MAP_ANON)
 #if defined(__x86_64__)
     int lp_alloc = ABTI_MEM_LP_MMAP_HP_RP;
@@ -286,21 +222,153 @@ void ABTD_env_init(ABTI_global *p_global)
     }
 #endif
 
-    /* Whether to print the configuration on ABT_init() */
-    env = getenv("ABT_PRINT_CONFIG");
-    if (env == NULL)
-        env = getenv("ABT_ENV_PRINT_CONFIG");
-    if (env != NULL) {
-        if (strcmp(env, "1") == 0 || strcasecmp(env, "yes") == 0 ||
-            strcasecmp(env, "y") == 0) {
-            p_global->print_config = ABT_TRUE;
+    /* ABT_PRINT_CONFIG, ABT_ENV_PRINT_CONFIG
+     * Whether to print the configuration on ABT_init() */
+    p_global->print_config = load_env_bool("PRINT_CONFIG", ABT_FALSE);
+
+    /* Init timer */
+    ABTD_time_init();
+}
+
+/*****************************************************************************/
+/* Internal static functions                                                 */
+/*****************************************************************************/
+
+static uint32_t roundup_pow2_uint32(uint32_t val)
+{
+    /* 3 -> 4
+     * 4 -> 4
+     * 5 -> 8 */
+    if (val == 0)
+        return 0;
+    int i;
+    for (i = 0; i < sizeof(uint32_t) * 8; i++) {
+        if ((val - 1) >> i == 0)
+            break;
+    }
+    return ((uint32_t)1) << i;
+}
+
+static const char *get_abt_env(const char *env_suffix)
+{
+    /* Valid prefix is ABT_ and ABT_ENV_. ABT_ is prioritized. */
+    char buffer[128];
+    const char *prefixes[] = { "ABT_", "ABT_ENV_" };
+    int i;
+    for (i = 0; i < sizeof(prefixes) / sizeof(prefixes[0]); i++) {
+        strcpy(buffer, prefixes[i]);
+        strcpy(buffer + strlen(prefixes[i]), env_suffix);
+        const char *env = getenv(buffer);
+        if (env)
+            return env;
+    }
+    return NULL;
+}
+
+static ABT_bool is_false(const char *str, ABT_bool include0)
+{
+    if (include0 && strcmp(str, "0") == 0) {
+        return ABT_TRUE;
+    } else if (strcasecmp(str, "n") == 0 || strcasecmp(str, "no") == 0 ||
+               strcasecmp(str, "false") == 0 || strcasecmp(str, "off") == 0) {
+        return ABT_TRUE;
+    }
+    return ABT_FALSE;
+}
+
+static ABT_bool is_true(const char *str, ABT_bool include1)
+{
+    if (include1 && strcmp(str, "1") == 0) {
+        return ABT_TRUE;
+    } else if (strcasecmp(str, "y") == 0 || strcasecmp(str, "yes") == 0 ||
+               strcasecmp(str, "true") == 0 || strcasecmp(str, "on") == 0) {
+        return ABT_TRUE;
+    }
+    return ABT_FALSE;
+}
+
+static ABT_bool load_env_bool(const char *env_suffix, ABT_bool default_val)
+{
+    const char *env = get_abt_env(env_suffix);
+    if (!env) {
+        return default_val;
+    } else {
+        if (default_val) {
+            /* If env is not "false", return true */
+            return is_false(env, ABT_TRUE) ? ABT_FALSE : ABT_TRUE;
         } else {
-            p_global->print_config = ABT_FALSE;
+            /* If env is not "true", return false */
+            return is_true(env, ABT_TRUE) ? ABT_TRUE : ABT_FALSE;
         }
+    }
+}
+
+static int load_env_int(const char *env_suffix, int default_val, int min_val,
+                        int max_val)
+{
+    const char *env = get_abt_env(env_suffix);
+    if (!env) {
+        return ABTU_max_int(min_val, ABTU_min_int(max_val, default_val));
     } else {
-        p_global->print_config = ABT_FALSE;
+        int val;
+        int abt_errno = ABTU_atoi(env, &val, NULL);
+        if (abt_errno != ABT_SUCCESS) {
+            return ABTU_max_int(min_val, ABTU_min_int(max_val, default_val));
+        } else {
+            return ABTU_max_int(min_val, ABTU_min_int(max_val, val));
+        }
     }
+}
 
-    /* Init timer */
-    ABTD_time_init();
+static uint32_t load_env_uint32(const char *env_suffix, uint32_t default_val,
+                                uint32_t min_val, uint32_t max_val)
+{
+    const char *env = get_abt_env(env_suffix);
+    if (!env) {
+        return ABTU_max_uint32(min_val, ABTU_min_uint32(max_val, default_val));
+    } else {
+        uint32_t val;
+        int abt_errno = ABTU_atoui32(env, &val, NULL);
+        if (abt_errno != ABT_SUCCESS) {
+            return ABTU_max_uint32(min_val,
+                                   ABTU_min_uint32(max_val, default_val));
+        } else {
+            return ABTU_max_uint32(min_val, ABTU_min_uint32(max_val, val));
+        }
+    }
+}
+
+static uint64_t load_env_uint64(const char *env_suffix, uint64_t default_val,
+                                uint64_t min_val, uint64_t max_val)
+{
+    const char *env = get_abt_env(env_suffix);
+    if (!env) {
+        return ABTU_max_uint64(min_val, ABTU_min_uint64(max_val, default_val));
+    } else {
+        uint64_t val;
+        int abt_errno = ABTU_atoui64(env, &val, NULL);
+        if (abt_errno != ABT_SUCCESS) {
+            return ABTU_max_uint64(min_val,
+                                   ABTU_min_uint64(max_val, default_val));
+        } else {
+            return ABTU_max_uint64(min_val, ABTU_min_uint64(max_val, val));
+        }
+    }
+}
+
+static size_t load_env_size(const char *env_suffix, size_t default_val,
+                            size_t min_val, size_t max_val)
+{
+    const char *env = get_abt_env(env_suffix);
+    if (!env) {
+        return ABTU_max_size(min_val, ABTU_min_size(max_val, default_val));
+    } else {
+        size_t val;
+        int abt_errno = ABTU_atosz(env, &val, NULL);
+        if (abt_errno != ABT_SUCCESS) {
+            return ABTU_max_size(min_val, ABTU_min_size(max_val, default_val));
+        } else {
+            return ABTU_max_size(min_val, ABTU_min_size(max_val, val));
+        }
+    }
 }
-- 
2.21.0 (Apple Git-122.2)


From 0c303257d2d5092e4c892490e08bd26ce8302330 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Mon, 16 Nov 2020 20:09:03 -0600
Subject: [PATCH 12/40] test/basic: fix error test to comply with c90

---
 test/basic/error.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/test/basic/error.c b/test/basic/error.c
index 8689a82..4bc9615 100644
--- a/test/basic/error.c
+++ b/test/basic/error.c
@@ -16,7 +16,7 @@ typedef struct {
 
 int main(int argc, char *argv[])
 {
-    int ret;
+    int ret, i;
 
     /* init and thread creation */
     ATS_read_args(argc, argv);
@@ -76,7 +76,7 @@ int main(int argc, char *argv[])
         { "ABT_ERR_INV_ARG", ABT_ERR_INV_ARG },
     };
 
-    for (int i = 0; i < sizeof(error_pairs) / sizeof(error_pairs[0]); i++) {
+    for (i = 0; i < sizeof(error_pairs) / sizeof(error_pairs[0]); i++) {
         char str[256];
         ret = ABT_error_get_str(error_pairs[i].code, str, NULL);
         ATS_ERROR(ret, "ABT_error_get_str");
-- 
2.21.0 (Apple Git-122.2)


From 7a04e6626305b3ce8030d851208fc18bba6391f5 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Tue, 17 Nov 2020 13:09:13 -0600
Subject: [PATCH 13/40] examples/profiling: do not use __builtin_expect with
 Solaris

Solaris compiler 12.5 does not support __builtin_expect().
---
 examples/profiling/abtx_prof.h | 5 +++++
 1 file changed, 5 insertions(+)

diff --git a/examples/profiling/abtx_prof.h b/examples/profiling/abtx_prof.h
index ce7f929..9883790 100644
--- a/examples/profiling/abtx_prof.h
+++ b/examples/profiling/abtx_prof.h
@@ -132,8 +132,13 @@ static int ABTX_prof_finalize(ABTX_prof_context context);
  */
 
 #ifndef ABTX_PROF_USE_BUILTIN_EXPECT
+#if defined(__SUNPRO_C) && __SUNPRO_C < 0x5150
+/* Solaris Studio <= 12.5 (Sun C 5.14) does not support __builtin_expect() */
+#define ABTX_PROF_USE_BUILTIN_EXPECT 0
+#else
 #define ABTX_PROF_USE_BUILTIN_EXPECT 1
 #endif
+#endif /* ABTX_PROF_USE_BUILTIN_EXPECT */
 
 #ifndef ABTX_PROF_USE_ALWAYS_INLINE
 #define ABTX_PROF_USE_ALWAYS_INLINE 1
-- 
2.21.0 (Apple Git-122.2)


From 53ffa5c40bf7715e1f230585af763f26c62d661a Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Tue, 17 Nov 2020 15:01:57 -0600
Subject: [PATCH 14/40] atomic: implement ABTD_atomic_size

ABTD_atomic_size is an atomic type for size_t.
---
 src/include/abtd_atomic.h | 166 ++++++++++++++++++++++++++++++++++++++
 1 file changed, 166 insertions(+)

diff --git a/src/include/abtd_atomic.h b/src/include/abtd_atomic.h
index 74475bc..2307d6d 100644
--- a/src/include/abtd_atomic.h
+++ b/src/include/abtd_atomic.h
@@ -16,6 +16,10 @@ typedef struct ABTD_atomic_int {
     int val;
 } ABTD_atomic_int;
 
+typedef struct ABTD_atomic_size {
+    size_t val;
+} ABTD_atomic_size;
+
 typedef struct ABTD_atomic_int32 {
     int32_t val;
 } ABTD_atomic_int32;
@@ -44,6 +48,10 @@ typedef struct ABTD_atomic_ptr {
     {                                                                          \
         (val)                                                                  \
     }
+#define ABTD_ATOMIC_SIZE_STATIC_INITIALIZER(val)                               \
+    {                                                                          \
+        (val)                                                                  \
+    }
 #define ABTD_ATOMIC_INT32_STATIC_INITIALIZER(val)                              \
     {                                                                          \
         (val)                                                                  \
@@ -78,6 +86,20 @@ static inline int ABTDI_atomic_val_cas_int(ABTD_atomic_int *ptr, int oldv,
 #endif
 }
 
+static inline size_t ABTDI_atomic_val_cas_size(ABTD_atomic_size *ptr,
+                                               size_t oldv, size_t newv,
+                                               int weak)
+{
+#ifdef ABT_CONFIG_HAVE_ATOMIC_BUILTIN
+    size_t tmp_oldv = oldv;
+    int ret = __atomic_compare_exchange_n(&ptr->val, &oldv, newv, weak,
+                                          __ATOMIC_ACQ_REL, __ATOMIC_ACQUIRE);
+    return ret ? tmp_oldv : oldv;
+#else
+    return __sync_val_compare_and_swap(&ptr->val, oldv, newv);
+#endif
+}
+
 static inline int32_t ABTDI_atomic_val_cas_int32(ABTD_atomic_int32 *ptr,
                                                  int32_t oldv, int32_t newv,
                                                  int weak)
@@ -158,6 +180,17 @@ static inline int ABTDI_atomic_bool_cas_int(ABTD_atomic_int *ptr, int oldv,
 #endif
 }
 
+static inline int ABTDI_atomic_bool_cas_size(ABTD_atomic_size *ptr, size_t oldv,
+                                             size_t newv, int weak)
+{
+#ifdef ABT_CONFIG_HAVE_ATOMIC_BUILTIN
+    return __atomic_compare_exchange_n(&ptr->val, &oldv, newv, weak,
+                                       __ATOMIC_ACQ_REL, __ATOMIC_ACQUIRE);
+#else
+    return __sync_bool_compare_and_swap(&ptr->val, oldv, newv);
+#endif
+}
+
 static inline int ABTDI_atomic_bool_cas_int32(ABTD_atomic_int32 *ptr,
                                               int32_t oldv, int32_t newv,
                                               int weak)
@@ -223,6 +256,12 @@ static inline int ABTD_atomic_val_cas_weak_int(ABTD_atomic_int *ptr, int oldv,
     return ABTDI_atomic_val_cas_int(ptr, oldv, newv, 1);
 }
 
+static inline size_t ABTD_atomic_val_cas_weak_size(ABTD_atomic_size *ptr,
+                                                   size_t oldv, size_t newv)
+{
+    return ABTDI_atomic_val_cas_size(ptr, oldv, newv, 1);
+}
+
 static inline int32_t ABTD_atomic_val_cas_weak_int32(ABTD_atomic_int32 *ptr,
                                                      int32_t oldv, int32_t newv)
 {
@@ -261,6 +300,12 @@ static inline int ABTD_atomic_val_cas_strong_int(ABTD_atomic_int *ptr, int oldv,
     return ABTDI_atomic_val_cas_int(ptr, oldv, newv, 0);
 }
 
+static inline size_t ABTD_atomic_val_cas_strong_size(ABTD_atomic_size *ptr,
+                                                     size_t oldv, size_t newv)
+{
+    return ABTDI_atomic_val_cas_size(ptr, oldv, newv, 0);
+}
+
 static inline int32_t ABTD_atomic_val_cas_strong_int32(ABTD_atomic_int32 *ptr,
                                                        int32_t oldv,
                                                        int32_t newv)
@@ -301,6 +346,12 @@ static inline int ABTD_atomic_bool_cas_weak_int(ABTD_atomic_int *ptr, int oldv,
     return ABTDI_atomic_bool_cas_int(ptr, oldv, newv, 1);
 }
 
+static inline int ABTD_atomic_bool_cas_weak_size(ABTD_atomic_size *ptr,
+                                                 size_t oldv, size_t newv)
+{
+    return ABTDI_atomic_bool_cas_size(ptr, oldv, newv, 1);
+}
+
 static inline int ABTD_atomic_bool_cas_weak_int32(ABTD_atomic_int32 *ptr,
                                                   int32_t oldv, int32_t newv)
 {
@@ -337,6 +388,12 @@ static inline int ABTD_atomic_bool_cas_strong_int(ABTD_atomic_int *ptr,
     return ABTDI_atomic_bool_cas_int(ptr, oldv, newv, 0);
 }
 
+static inline int ABTD_atomic_bool_cas_strong_size(ABTD_atomic_size *ptr,
+                                                   size_t oldv, size_t newv)
+{
+    return ABTDI_atomic_bool_cas_size(ptr, oldv, newv, 0);
+}
+
 static inline int ABTD_atomic_bool_cas_strong_int32(ABTD_atomic_int32 *ptr,
                                                     int32_t oldv, int32_t newv)
 {
@@ -378,6 +435,15 @@ static inline int ABTD_atomic_fetch_add_int(ABTD_atomic_int *ptr, int v)
 #endif
 }
 
+static inline size_t ABTD_atomic_fetch_add_size(ABTD_atomic_size *ptr, size_t v)
+{
+#ifdef ABT_CONFIG_HAVE_ATOMIC_BUILTIN
+    return __atomic_fetch_add(&ptr->val, v, __ATOMIC_ACQ_REL);
+#else
+    return __sync_fetch_and_add(&ptr->val, v);
+#endif
+}
+
 static inline int32_t ABTD_atomic_fetch_add_int32(ABTD_atomic_int32 *ptr,
                                                   int32_t v)
 {
@@ -427,6 +493,15 @@ static inline int ABTD_atomic_fetch_sub_int(ABTD_atomic_int *ptr, int v)
 #endif
 }
 
+static inline size_t ABTD_atomic_fetch_sub_size(ABTD_atomic_size *ptr, size_t v)
+{
+#ifdef ABT_CONFIG_HAVE_ATOMIC_BUILTIN
+    return __atomic_fetch_sub(&ptr->val, v, __ATOMIC_ACQ_REL);
+#else
+    return __sync_fetch_and_sub(&ptr->val, v);
+#endif
+}
+
 static inline int32_t ABTD_atomic_fetch_sub_int32(ABTD_atomic_int32 *ptr,
                                                   int32_t v)
 {
@@ -476,6 +551,15 @@ static inline int ABTD_atomic_fetch_and_int(ABTD_atomic_int *ptr, int v)
 #endif
 }
 
+static inline size_t ABTD_atomic_fetch_and_size(ABTD_atomic_size *ptr, size_t v)
+{
+#ifdef ABT_CONFIG_HAVE_ATOMIC_BUILTIN
+    return __atomic_fetch_and(&ptr->val, v, __ATOMIC_ACQ_REL);
+#else
+    return __sync_fetch_and_and(&ptr->val, v);
+#endif
+}
+
 static inline int32_t ABTD_atomic_fetch_and_int32(ABTD_atomic_int32 *ptr,
                                                   int32_t v)
 {
@@ -525,6 +609,15 @@ static inline int ABTD_atomic_fetch_or_int(ABTD_atomic_int *ptr, int v)
 #endif
 }
 
+static inline size_t ABTD_atomic_fetch_or_size(ABTD_atomic_size *ptr, size_t v)
+{
+#ifdef ABT_CONFIG_HAVE_ATOMIC_BUILTIN
+    return __atomic_fetch_or(&ptr->val, v, __ATOMIC_ACQ_REL);
+#else
+    return __sync_fetch_and_or(&ptr->val, v);
+#endif
+}
+
 static inline int32_t ABTD_atomic_fetch_or_int32(ABTD_atomic_int32 *ptr,
                                                  int32_t v)
 {
@@ -574,6 +667,15 @@ static inline int ABTD_atomic_fetch_xor_int(ABTD_atomic_int *ptr, int v)
 #endif
 }
 
+static inline size_t ABTD_atomic_fetch_xor_size(ABTD_atomic_size *ptr, size_t v)
+{
+#ifdef ABT_CONFIG_HAVE_ATOMIC_BUILTIN
+    return __atomic_fetch_xor(&ptr->val, v, __ATOMIC_ACQ_REL);
+#else
+    return __sync_fetch_and_xor(&ptr->val, v);
+#endif
+}
+
 static inline int32_t ABTD_atomic_fetch_xor_int32(ABTD_atomic_int32 *ptr,
                                                   int32_t v)
 {
@@ -671,6 +773,19 @@ static inline int ABTD_atomic_relaxed_load_int(const ABTD_atomic_int *ptr)
 #endif
 }
 
+static inline size_t ABTD_atomic_relaxed_load_size(const ABTD_atomic_size *ptr)
+{
+#ifdef ABT_CONFIG_HAVE_ATOMIC_BUILTIN
+#ifndef __SUNPRO_C
+    return __atomic_load_n(&ptr->val, __ATOMIC_RELAXED);
+#else
+    return __atomic_load_n((size_t *)&ptr->val, __ATOMIC_RELAXED);
+#endif
+#else
+    return *(volatile size_t *)&ptr->val;
+#endif
+}
+
 static inline int32_t
 ABTD_atomic_relaxed_load_int32(const ABTD_atomic_int32 *ptr)
 {
@@ -776,6 +891,22 @@ static inline int ABTD_atomic_acquire_load_int(const ABTD_atomic_int *ptr)
 #endif
 }
 
+static inline size_t ABTD_atomic_acquire_load_size(const ABTD_atomic_size *ptr)
+{
+#ifdef ABT_CONFIG_HAVE_ATOMIC_BUILTIN
+#ifndef __SUNPRO_C
+    return __atomic_load_n(&ptr->val, __ATOMIC_ACQUIRE);
+#else
+    return __atomic_load_n((size_t *)&ptr->val, __ATOMIC_ACQUIRE);
+#endif
+#else
+    __sync_synchronize();
+    size_t val = *(volatile size_t *)&ptr->val;
+    __sync_synchronize();
+    return val;
+#endif
+}
+
 static inline int32_t
 ABTD_atomic_acquire_load_int32(const ABTD_atomic_int32 *ptr)
 {
@@ -871,6 +1002,16 @@ static inline void ABTD_atomic_relaxed_store_int(ABTD_atomic_int *ptr, int val)
 #endif
 }
 
+static inline void ABTD_atomic_relaxed_store_size(ABTD_atomic_size *ptr,
+                                                  size_t val)
+{
+#ifdef ABT_CONFIG_HAVE_ATOMIC_BUILTIN
+    __atomic_store_n(&ptr->val, val, __ATOMIC_RELAXED);
+#else
+    *(volatile size_t *)&ptr->val = val;
+#endif
+}
+
 static inline void ABTD_atomic_relaxed_store_int32(ABTD_atomic_int32 *ptr,
                                                    int32_t val)
 {
@@ -932,6 +1073,18 @@ static inline void ABTD_atomic_release_store_int(ABTD_atomic_int *ptr, int val)
 #endif
 }
 
+static inline void ABTD_atomic_release_store_size(ABTD_atomic_size *ptr,
+                                                  size_t val)
+{
+#ifdef ABT_CONFIG_HAVE_ATOMIC_BUILTIN
+    __atomic_store_n(&ptr->val, val, __ATOMIC_RELEASE);
+#else
+    __sync_synchronize();
+    *(volatile size_t *)&ptr->val = val;
+    __sync_synchronize();
+#endif
+}
+
 static inline void ABTD_atomic_release_store_int32(ABTD_atomic_int32 *ptr,
                                                    int32_t val)
 {
@@ -1005,6 +1158,19 @@ static inline int ABTD_atomic_exchange_int(ABTD_atomic_int *ptr, int v)
 #endif
 }
 
+static inline size_t ABTD_atomic_exchange_size(ABTD_atomic_size *ptr, size_t v)
+{
+#ifdef ABT_CONFIG_HAVE_ATOMIC_BUILTIN
+    return __atomic_exchange_n(&ptr->val, v, __ATOMIC_ACQ_REL);
+#else
+    size_t val;
+    do {
+        val = ABTD_atomic_acquire_load_size(ptr);
+    } while (!ABTD_atomic_bool_cas_weak_size(ptr, val, v));
+    return val;
+#endif
+}
+
 static inline int32_t ABTD_atomic_exchange_int32(ABTD_atomic_int32 *ptr,
                                                  int32_t v)
 {
-- 
2.21.0 (Apple Git-122.2)


From 885dc44ba885ed324444cffa49db2f2addecfe81 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Tue, 17 Nov 2020 15:02:07 -0600
Subject: [PATCH 15/40] barrier/future/eventual: use size_t for internal
 counters

Although the current API does not accept such, synchronization objects in
Argobots can deal with more than UINT32_MAX threads.  All types that count the
number of threads for synchronization are changed to size_t.
---
 src/barrier.c      | 24 +++++++++++++-----------
 src/eventual.c     | 12 +++++++-----
 src/futures.c      | 19 ++++++++++---------
 src/include/abti.h | 10 +++++-----
 4 files changed, 35 insertions(+), 30 deletions(-)

diff --git a/src/barrier.c b/src/barrier.c
index 5199393..31c2399 100644
--- a/src/barrier.c
+++ b/src/barrier.c
@@ -27,20 +27,21 @@ int ABT_barrier_create(uint32_t num_waiters, ABT_barrier *newbarrier)
 {
     int abt_errno;
     ABTI_barrier *p_newbarrier;
+    size_t arg_num_waiters = num_waiters;
 
     abt_errno = ABTU_malloc(sizeof(ABTI_barrier), (void **)&p_newbarrier);
     ABTI_CHECK_ERROR(abt_errno);
 
     ABTI_spinlock_clear(&p_newbarrier->lock);
-    p_newbarrier->num_waiters = num_waiters;
+    p_newbarrier->num_waiters = arg_num_waiters;
     p_newbarrier->counter = 0;
-    abt_errno = ABTU_malloc(num_waiters * sizeof(ABTI_ythread *),
+    abt_errno = ABTU_malloc(arg_num_waiters * sizeof(ABTI_ythread *),
                             (void **)&p_newbarrier->waiters);
     if (ABTI_IS_ERROR_CHECK_ENABLED && abt_errno != ABT_SUCCESS) {
         ABTU_free(p_newbarrier);
         ABTI_HANDLE_ERROR(abt_errno);
     }
-    abt_errno = ABTU_malloc(num_waiters * sizeof(ABT_unit_type),
+    abt_errno = ABTU_malloc(arg_num_waiters * sizeof(ABT_unit_type),
                             (void **)&p_newbarrier->waiter_type);
     if (ABTI_IS_ERROR_CHECK_ENABLED && abt_errno != ABT_SUCCESS) {
         ABTU_free(p_newbarrier->waiters);
@@ -71,27 +72,28 @@ int ABT_barrier_reinit(ABT_barrier barrier, uint32_t num_waiters)
     ABTI_barrier *p_barrier = ABTI_barrier_get_ptr(barrier);
     ABTI_CHECK_NULL_BARRIER_PTR(p_barrier);
     ABTI_ASSERT(p_barrier->counter == 0);
+    size_t arg_num_waiters = num_waiters;
 
     /* Only when num_waiters is different from p_barrier->num_waiters, we
      * change p_barrier. */
-    if (num_waiters < p_barrier->num_waiters) {
+    if (arg_num_waiters < p_barrier->num_waiters) {
         /* We can reuse waiters and waiter_type arrays */
-        p_barrier->num_waiters = num_waiters;
-    } else if (num_waiters > p_barrier->num_waiters) {
+        p_barrier->num_waiters = arg_num_waiters;
+    } else if (arg_num_waiters > p_barrier->num_waiters) {
         /* Free existing arrays and reallocate them */
         int abt_errno;
         ABTI_ythread **new_waiters;
         ABT_unit_type *new_waiter_types;
-        abt_errno = ABTU_malloc(num_waiters * sizeof(ABTI_ythread *),
+        abt_errno = ABTU_malloc(arg_num_waiters * sizeof(ABTI_ythread *),
                                 (void **)&new_waiters);
         ABTI_CHECK_ERROR(abt_errno);
-        abt_errno = ABTU_malloc(num_waiters * sizeof(ABT_unit_type),
+        abt_errno = ABTU_malloc(arg_num_waiters * sizeof(ABT_unit_type),
                                 (void **)&new_waiter_types);
         if (ABTI_IS_ERROR_CHECK_ENABLED && abt_errno != ABT_SUCCESS) {
             ABTU_free(new_waiters);
             ABTI_HANDLE_ERROR(abt_errno);
         }
-        p_barrier->num_waiters = num_waiters;
+        p_barrier->num_waiters = arg_num_waiters;
         ABTU_free(p_barrier->waiters);
         ABTU_free(p_barrier->waiter_type);
         p_barrier->waiters = new_waiters;
@@ -151,7 +153,7 @@ int ABT_barrier_wait(ABT_barrier barrier)
     ABTI_local *p_local = ABTI_local_get_local();
     ABTI_barrier *p_barrier = ABTI_barrier_get_ptr(barrier);
     ABTI_CHECK_NULL_BARRIER_PTR(p_barrier);
-    uint32_t pos;
+    size_t pos;
 
     ABTI_spinlock_acquire(&p_barrier->lock);
 
@@ -204,7 +206,7 @@ int ABT_barrier_wait(ABT_barrier barrier)
         }
     } else {
         /* Signal all the waiting ULTs */
-        int i;
+        size_t i;
         for (i = 0; i < p_barrier->num_waiters - 1; i++) {
             ABTI_ythread *p_ythread = p_barrier->waiters[i];
             if (p_barrier->waiter_type[i] == ABT_UNIT_TYPE_THREAD) {
diff --git a/src/eventual.c b/src/eventual.c
index d1d68b1..0096d63 100644
--- a/src/eventual.c
+++ b/src/eventual.c
@@ -33,17 +33,18 @@ int ABT_eventual_create(int nbytes, ABT_eventual *neweventual)
 {
     int abt_errno;
     ABTI_eventual *p_eventual;
+    size_t arg_nbytes = nbytes;
 
     abt_errno = ABTU_malloc(sizeof(ABTI_eventual), (void **)&p_eventual);
     ABTI_CHECK_ERROR(abt_errno);
 
     ABTI_spinlock_clear(&p_eventual->lock);
     p_eventual->ready = ABT_FALSE;
-    p_eventual->nbytes = nbytes;
-    if (nbytes == 0) {
+    p_eventual->nbytes = arg_nbytes;
+    if (arg_nbytes == 0) {
         p_eventual->value = NULL;
     } else {
-        abt_errno = ABTU_malloc(nbytes, &p_eventual->value);
+        abt_errno = ABTU_malloc(arg_nbytes, &p_eventual->value);
         if (ABTI_IS_ERROR_CHECK_ENABLED && abt_errno != ABT_SUCCESS) {
             ABTU_free(p_eventual);
             ABTI_HANDLE_ERROR(abt_errno);
@@ -224,13 +225,14 @@ int ABT_eventual_set(ABT_eventual eventual, void *value, int nbytes)
     ABTI_local *p_local = ABTI_local_get_local();
     ABTI_eventual *p_eventual = ABTI_eventual_get_ptr(eventual);
     ABTI_CHECK_NULL_EVENTUAL_PTR(p_eventual);
-    ABTI_CHECK_TRUE(nbytes <= p_eventual->nbytes, ABT_ERR_INV_EVENTUAL);
+    size_t arg_nbytes = nbytes;
+    ABTI_CHECK_TRUE(arg_nbytes <= p_eventual->nbytes, ABT_ERR_INV_EVENTUAL);
 
     ABTI_spinlock_acquire(&p_eventual->lock);
 
     p_eventual->ready = ABT_TRUE;
     if (p_eventual->value)
-        memcpy(p_eventual->value, value, nbytes);
+        memcpy(p_eventual->value, value, arg_nbytes);
 
     if (p_eventual->p_head == NULL) {
         ABTI_spinlock_release(&p_eventual->lock);
diff --git a/src/futures.c b/src/futures.c
index 8f3c9c5..5419ff4 100644
--- a/src/futures.c
+++ b/src/futures.c
@@ -58,14 +58,15 @@ int ABT_future_create(uint32_t compartments, void (*cb_func)(void **arg),
 {
     int abt_errno;
     ABTI_future *p_future;
+    size_t arg_compartments = compartments;
 
     abt_errno = ABTU_malloc(sizeof(ABTI_future), (void **)&p_future);
     ABTI_CHECK_ERROR(abt_errno);
     ABTI_spinlock_clear(&p_future->lock);
-    ABTD_atomic_relaxed_store_uint32(&p_future->counter, 0);
-    p_future->compartments = compartments;
-    abt_errno =
-        ABTU_malloc(compartments * sizeof(void *), (void **)&p_future->array);
+    ABTD_atomic_relaxed_store_size(&p_future->counter, 0);
+    p_future->compartments = arg_compartments;
+    abt_errno = ABTU_malloc(arg_compartments * sizeof(void *),
+                            (void **)&p_future->array);
     if (ABTI_IS_ERROR_CHECK_ENABLED && abt_errno != ABT_SUCCESS) {
         ABTU_free(p_future);
         ABTI_HANDLE_ERROR(abt_errno);
@@ -129,7 +130,7 @@ int ABT_future_wait(ABT_future future)
     ABTI_CHECK_NULL_FUTURE_PTR(p_future);
 
     ABTI_spinlock_acquire(&p_future->lock);
-    if (ABTD_atomic_relaxed_load_uint32(&p_future->counter) <
+    if (ABTD_atomic_relaxed_load_size(&p_future->counter) <
         p_future->compartments) {
         ABTI_ythread *p_ythread = NULL;
         ABTI_thread *p_thread;
@@ -203,7 +204,7 @@ int ABT_future_test(ABT_future future, ABT_bool *flag)
     ABTI_future *p_future = ABTI_future_get_ptr(future);
     ABTI_CHECK_NULL_FUTURE_PTR(p_future);
 
-    uint32_t counter = ABTD_atomic_acquire_load_uint32(&p_future->counter);
+    size_t counter = ABTD_atomic_acquire_load_size(&p_future->counter);
     *flag = (counter == p_future->compartments) ? ABT_TRUE : ABT_FALSE;
     return ABT_SUCCESS;
 }
@@ -233,7 +234,7 @@ int ABT_future_set(ABT_future future, void *value)
 
     ABTI_spinlock_acquire(&p_future->lock);
 
-    int counter = ABTD_atomic_relaxed_load_uint32(&p_future->counter);
+    size_t counter = ABTD_atomic_relaxed_load_size(&p_future->counter);
 #ifndef ABT_CONFIG_DISABLE_ERROR_CHECK
     if (counter >= p_future->compartments) {
         ABTI_spinlock_release(&p_future->lock);
@@ -242,7 +243,7 @@ int ABT_future_set(ABT_future future, void *value)
 #endif
     p_future->array[counter] = value;
     counter++;
-    ABTD_atomic_release_store_uint32(&p_future->counter, counter);
+    ABTD_atomic_release_store_size(&p_future->counter, counter);
 
     if (counter == p_future->compartments) {
         if (p_future->p_callback != NULL)
@@ -302,7 +303,7 @@ int ABT_future_reset(ABT_future future)
     ABTI_CHECK_NULL_FUTURE_PTR(p_future);
 
     ABTI_spinlock_acquire(&p_future->lock);
-    ABTD_atomic_release_store_uint32(&p_future->counter, 0);
+    ABTD_atomic_release_store_size(&p_future->counter, 0);
     ABTI_spinlock_release(&p_future->lock);
     return ABT_SUCCESS;
 }
diff --git a/src/include/abti.h b/src/include/abti.h
index 597d629..b002ddb 100644
--- a/src/include/abti.h
+++ b/src/include/abti.h
@@ -391,15 +391,15 @@ struct ABTI_eventual {
     ABTI_spinlock lock;
     ABT_bool ready;
     void *value;
-    int nbytes;
+    size_t nbytes;
     ABTI_thread *p_head; /* Head of waiters */
     ABTI_thread *p_tail; /* Tail of waiters */
 };
 
 struct ABTI_future {
     ABTI_spinlock lock;
-    ABTD_atomic_uint32 counter;
-    uint32_t compartments;
+    ABTD_atomic_size counter;
+    size_t compartments;
     void **array;
     void (*p_callback)(void **arg);
     ABTI_thread *p_head; /* Head of waiters */
@@ -407,8 +407,8 @@ struct ABTI_future {
 };
 
 struct ABTI_barrier {
-    uint32_t num_waiters;
-    volatile uint32_t counter;
+    size_t num_waiters;
+    volatile size_t counter;
     ABTI_ythread **waiters;
     ABT_unit_type *waiter_type;
     ABTI_spinlock lock;
-- 
2.21.0 (Apple Git-122.2)


From 12c93478aab67bb7a607fe2485787bd23cbc0d30 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Tue, 17 Nov 2020 15:02:14 -0600
Subject: [PATCH 16/40] info: use int-type atomic variables for stack dump

Because the number of execution streams is represented by int, we do not need
uint32_t for a barrier.  To suppress signed/unsigned warning, int is used for a
barrier counter.  Because flag does not need to be unsigned, type of
print_stack_flag is also changed to int.
---
 src/info.c | 44 ++++++++++++++++++++++----------------------
 1 file changed, 22 insertions(+), 22 deletions(-)

diff --git a/src/info.c b/src/info.c
index e05f480..f308dc4 100644
--- a/src/info.c
+++ b/src/info.c
@@ -508,23 +508,23 @@ ABTU_ret_err static int print_all_thread_stacks(FILE *fp);
 #define PRINT_STACK_FLAG_WAIT 2
 #define PRINT_STACK_FLAG_FINALIZE 3
 
-static ABTD_atomic_uint32 print_stack_flag =
-    ABTD_ATOMIC_UINT32_STATIC_INITIALIZER(PRINT_STACK_FLAG_UNSET);
+static ABTD_atomic_int print_stack_flag =
+    ABTD_ATOMIC_INT_STATIC_INITIALIZER(PRINT_STACK_FLAG_UNSET);
 static FILE *print_stack_fp = NULL;
 static double print_stack_timeout = 0.0;
 static void (*print_cb_func)(ABT_bool, void *) = NULL;
 static void *print_arg = NULL;
-static ABTD_atomic_uint32 print_stack_barrier =
-    ABTD_ATOMIC_UINT32_STATIC_INITIALIZER(0);
+static ABTD_atomic_int print_stack_barrier =
+    ABTD_ATOMIC_INT_STATIC_INITIALIZER(0);
 
 void ABTI_info_check_print_all_thread_stacks(void)
 {
-    if (ABTD_atomic_acquire_load_uint32(&print_stack_flag) !=
+    if (ABTD_atomic_acquire_load_int(&print_stack_flag) !=
         PRINT_STACK_FLAG_WAIT)
         return;
 
     /* Wait for the other execution streams using a barrier mechanism. */
-    uint32_t self_value = ABTD_atomic_fetch_add_uint32(&print_stack_barrier, 1);
+    int self_value = ABTD_atomic_fetch_add_int(&print_stack_barrier, 1);
     if (self_value == 0) {
         /* This ES becomes the main ES. */
         double start_time = ABTI_get_wtime();
@@ -534,7 +534,7 @@ void ABTI_info_check_print_all_thread_stacks(void)
          * printing data. */
         ABTI_spinlock_acquire(&gp_ABTI_global->xstream_list_lock);
         while (1) {
-            if (ABTD_atomic_acquire_load_uint32(&print_stack_barrier) >=
+            if (ABTD_atomic_acquire_load_int(&print_stack_barrier) >=
                 gp_ABTI_global->num_xstreams) {
                 break;
             }
@@ -554,7 +554,7 @@ void ABTI_info_check_print_all_thread_stacks(void)
             fprintf(print_stack_fp,
                     "ABT_info_trigger_print_all_thread_stacks: "
                     "timeout (only %d ESs stop)\n",
-                    (int)ABTD_atomic_acquire_load_uint32(&print_stack_barrier));
+                    ABTD_atomic_acquire_load_int(&print_stack_barrier));
         }
         int abt_errno = print_all_thread_stacks(print_stack_fp);
         if (ABTI_IS_ERROR_CHECK_ENABLED && abt_errno != ABT_SUCCESS) {
@@ -566,23 +566,23 @@ void ABTI_info_check_print_all_thread_stacks(void)
         if (print_cb_func)
             print_cb_func(force_print, print_arg);
         /* Update print_stack_flag to 3. */
-        ABTD_atomic_release_store_uint32(&print_stack_flag,
-                                         PRINT_STACK_FLAG_FINALIZE);
+        ABTD_atomic_release_store_int(&print_stack_flag,
+                                      PRINT_STACK_FLAG_FINALIZE);
     } else {
         /* Wait for the main ES's work. */
-        while (ABTD_atomic_acquire_load_uint32(&print_stack_flag) !=
+        while (ABTD_atomic_acquire_load_int(&print_stack_flag) !=
                PRINT_STACK_FLAG_FINALIZE)
             ABTD_atomic_pause();
     }
-    ABTI_ASSERT(ABTD_atomic_acquire_load_uint32(&print_stack_flag) ==
+    ABTI_ASSERT(ABTD_atomic_acquire_load_int(&print_stack_flag) ==
                 PRINT_STACK_FLAG_FINALIZE);
 
     /* Decrement the barrier value. */
-    uint32_t dec_value = ABTD_atomic_fetch_sub_uint32(&print_stack_barrier, 1);
+    int dec_value = ABTD_atomic_fetch_sub_int(&print_stack_barrier, 1);
     if (dec_value == 0) {
         /* The last execution stream resets the flag. */
-        ABTD_atomic_release_store_uint32(&print_stack_flag,
-                                         PRINT_STACK_FLAG_UNSET);
+        ABTD_atomic_release_store_int(&print_stack_flag,
+                                      PRINT_STACK_FLAG_UNSET);
     }
 }
 
@@ -757,21 +757,21 @@ static void info_trigger_print_all_thread_stacks(
 {
     /* This function is signal-safe, so it may not call other functions unless
      * you really know what the called functions do. */
-    if (ABTD_atomic_acquire_load_uint32(&print_stack_flag) ==
+    if (ABTD_atomic_acquire_load_int(&print_stack_flag) ==
         PRINT_STACK_FLAG_UNSET) {
-        if (ABTD_atomic_bool_cas_strong_uint32(&print_stack_flag,
-                                               PRINT_STACK_FLAG_UNSET,
-                                               PRINT_STACK_FLAG_INITIALIZE)) {
+        if (ABTD_atomic_bool_cas_strong_int(&print_stack_flag,
+                                            PRINT_STACK_FLAG_UNSET,
+                                            PRINT_STACK_FLAG_INITIALIZE)) {
             /* Save fp and timeout. */
             print_stack_fp = fp;
             print_stack_timeout = timeout;
             print_cb_func = cb_func;
             print_arg = arg;
             /* Here print_stack_barrier must be 0. */
-            ABTI_ASSERT(ABTD_atomic_acquire_load_uint32(&print_stack_barrier) ==
+            ABTI_ASSERT(ABTD_atomic_acquire_load_int(&print_stack_barrier) ==
                         0);
-            ABTD_atomic_release_store_uint32(&print_stack_flag,
-                                             PRINT_STACK_FLAG_WAIT);
+            ABTD_atomic_release_store_int(&print_stack_flag,
+                                          PRINT_STACK_FLAG_WAIT);
         }
     }
 }
-- 
2.21.0 (Apple Git-122.2)


From 95b5bbc849559164a679c21e01929b5f3481799b Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Tue, 17 Nov 2020 15:02:22 -0600
Subject: [PATCH 17/40] mutex: fix warning about signed/unsigned comparison

---
 src/include/abti.h                | 4 ++--
 src/include/abti_ythread_htable.h | 2 +-
 src/mutex.c                       | 8 ++++----
 3 files changed, 7 insertions(+), 7 deletions(-)

diff --git a/src/include/abti.h b/src/include/abti.h
index b002ddb..842a45b 100644
--- a/src/include/abti.h
+++ b/src/include/abti.h
@@ -568,9 +568,9 @@ void ABTI_ktable_free(ABTI_local *p_local, ABTI_ktable *p_ktable);
 
 /* Mutex */
 void ABTI_mutex_wait(ABTI_xstream **pp_local_xstream, ABTI_mutex *p_mutex,
-                     int val);
+                     uint32_t val);
 void ABTI_mutex_wait_low(ABTI_xstream **pp_local_xstream, ABTI_mutex *p_mutex,
-                         int val);
+                         uint32_t val);
 void ABTI_mutex_wake_de(ABTI_local *p_local, ABTI_mutex *p_mutex);
 
 /* Information */
diff --git a/src/include/abti_ythread_htable.h b/src/include/abti_ythread_htable.h
index fbefbd0..8fe3f84 100644
--- a/src/include/abti_ythread_htable.h
+++ b/src/include/abti_ythread_htable.h
@@ -53,7 +53,7 @@ struct ABTI_ythread_htable {
     ABTI_spinlock mutex; /* To protect table */
 #endif
     ABTD_atomic_uint32 num_elems;
-    uint32_t num_rows;
+    int num_rows;
     ABTI_ythread_queue *queue;
 
     ABTI_ythread_queue *h_list; /* list of non-empty high prio. queues */
diff --git a/src/mutex.c b/src/mutex.c
index 79b7125..e0528dc 100644
--- a/src/mutex.c
+++ b/src/mutex.c
@@ -428,13 +428,13 @@ int ABT_mutex_equal(ABT_mutex mutex1, ABT_mutex mutex2, ABT_bool *result)
 /*****************************************************************************/
 
 void ABTI_mutex_wait(ABTI_xstream **pp_local_xstream, ABTI_mutex *p_mutex,
-                     int val)
+                     uint32_t val)
 {
     ABTI_xstream *p_local_xstream = *pp_local_xstream;
     ABTI_ythread_htable *p_htable = p_mutex->p_htable;
     ABTI_ythread *p_self = ABTI_thread_get_ythread(p_local_xstream->p_thread);
 
-    int rank = (int)p_local_xstream->rank;
+    int rank = p_local_xstream->rank;
     ABTI_ASSERT(rank < p_htable->num_rows);
     ABTI_ythread_queue *p_queue = &p_htable->queue[rank];
 
@@ -464,13 +464,13 @@ void ABTI_mutex_wait(ABTI_xstream **pp_local_xstream, ABTI_mutex *p_mutex,
 }
 
 void ABTI_mutex_wait_low(ABTI_xstream **pp_local_xstream, ABTI_mutex *p_mutex,
-                         int val)
+                         uint32_t val)
 {
     ABTI_xstream *p_local_xstream = *pp_local_xstream;
     ABTI_ythread_htable *p_htable = p_mutex->p_htable;
     ABTI_ythread *p_self = ABTI_thread_get_ythread(p_local_xstream->p_thread);
 
-    int rank = (int)p_local_xstream->rank;
+    int rank = p_local_xstream->rank;
     ABTI_ASSERT(rank < p_htable->num_rows);
     ABTI_ythread_queue *p_queue = &p_htable->queue[rank];
 
-- 
2.21.0 (Apple Git-122.2)


From 594ed6c3a5513dc85bbfe47df1f613e1f54f8723 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Tue, 17 Nov 2020 15:02:28 -0600
Subject: [PATCH 18/40] sched: use size_t for num_pools

Though the number of pools should not be more than INT_MAX, there is no reason
to use signed int to manage it.  The type of num_pools is changed to size_t.
This change fixes several warnings.
---
 src/include/abti.h |  2 +-
 src/info.c         |  5 +++--
 src/sched/sched.c  | 17 +++++++----------
 src/stream.c       |  2 +-
 4 files changed, 12 insertions(+), 14 deletions(-)

diff --git a/src/include/abti.h b/src/include/abti.h
index 842a45b..4d7cf95 100644
--- a/src/include/abti.h
+++ b/src/include/abti.h
@@ -262,7 +262,7 @@ struct ABTI_sched {
     ABT_sched_type type;        /* Can yield or not (ULT or task) */
     ABTD_atomic_uint32 request; /* Request */
     ABT_pool *pools;            /* Thread pools */
-    int num_pools;              /* Number of thread pools */
+    size_t num_pools;           /* Number of thread pools */
     ABTI_ythread *p_ythread;    /* Associated ULT */
     void *data;                 /* Data for a specific scheduler */
 
diff --git a/src/info.c b/src/info.c
index f308dc4..9112216 100644
--- a/src/info.c
+++ b/src/info.c
@@ -778,7 +778,8 @@ static void info_trigger_print_all_thread_stacks(
 
 ABTU_ret_err static int print_all_thread_stacks(FILE *fp)
 {
-    int i, abt_errno;
+    size_t i;
+    int abt_errno;
     struct info_pool_set_t pool_set;
 
     abt_errno = info_initialize_pool_set(&pool_set);
@@ -794,7 +795,7 @@ ABTU_ret_err static int print_all_thread_stacks(FILE *fp)
         for (i = 0; i < p_main_sched->num_pools; i++) {
             ABT_pool pool = p_main_sched->pools[i];
             ABTI_ASSERT(pool != ABT_POOL_NULL);
-            fprintf(fp, "  pools[%d] : %p\n", i,
+            fprintf(fp, "  pools[%zu] : %p\n", i,
                     (void *)ABTI_pool_get_ptr(pool));
             abt_errno = info_add_pool_set(pool, &pool_set);
             if (ABTI_IS_ERROR_CHECK_ENABLED && abt_errno != ABT_SUCCESS) {
diff --git a/src/sched/sched.c b/src/sched/sched.c
index 3bfc436..2f24ae4 100644
--- a/src/sched/sched.c
+++ b/src/sched/sched.c
@@ -166,7 +166,7 @@ int ABT_sched_get_pools(ABT_sched sched, int max_pools, int idx,
 {
     ABTI_sched *p_sched = ABTI_sched_get_ptr(sched);
     ABTI_CHECK_NULL_SCHED_PTR(p_sched);
-    ABTI_CHECK_TRUE(idx + max_pools <= p_sched->num_pools, ABT_ERR_SCHED);
+    ABTI_CHECK_TRUE((size_t)(idx + max_pools) <= p_sched->num_pools, ABT_ERR_SCHED);
 
     int p;
     for (p = idx; p < idx + max_pools; p++) {
@@ -306,8 +306,7 @@ int ABT_sched_get_size(ABT_sched sched, size_t *size)
 
 size_t ABTI_sched_get_size(ABTI_sched *p_sched)
 {
-    size_t pool_size = 0;
-    int p;
+    size_t pool_size = 0, p;
 
     for (p = 0; p < p_sched->num_pools; p++) {
         ABTI_pool *p_pool = ABTI_pool_get_ptr(p_sched->pools[p]);
@@ -500,7 +499,7 @@ void ABTI_sched_free(ABTI_local *p_local, ABTI_sched *p_sched,
     ABTI_ASSERT(p_sched->used == ABTI_SCHED_NOT_USED);
     /* If sched is a default provided one, it should free its pool here.
      * Otherwise, freeing the pool is the user's responsibility. */
-    int p;
+    size_t p;
     for (p = 0; p < p_sched->num_pools; p++) {
         ABTI_pool *p_pool = ABTI_pool_get_ptr(p_sched->pools[p]);
         int32_t num_scheds = ABTI_pool_release(p_pool);
@@ -585,8 +584,7 @@ ABTU_ret_err int ABTI_sched_get_migration_pool(ABTI_sched *p_sched,
 
 size_t ABTI_sched_get_total_size(ABTI_sched *p_sched)
 {
-    size_t pool_size = 0;
-    int p;
+    size_t pool_size = 0, p;
 
     for (p = 0; p < p_sched->num_pools; p++) {
         ABTI_pool *p_pool = ABTI_pool_get_ptr(p_sched->pools[p]);
@@ -603,8 +601,7 @@ size_t ABTI_sched_get_total_size(ABTI_sched *p_sched)
  * between different schedulers associated with different ESs. */
 size_t ABTI_sched_get_effective_size(ABTI_local *p_local, ABTI_sched *p_sched)
 {
-    size_t pool_size = 0;
-    int p;
+    size_t pool_size = 0, p;
 
     for (p = 0; p < p_sched->num_pools; p++) {
         ABT_pool pool = p_sched->pools[p];
@@ -689,7 +686,7 @@ void ABTI_sched_print(ABTI_sched *p_sched, FILE *p_os, int indent,
                 "%*sused     : %s\n"
                 "%*sautomatic: %s\n"
                 "%*srequest  : 0x%x\n"
-                "%*snum_pools: %d\n"
+                "%*snum_pools: %zu\n"
                 "%*ssize     : %zu\n"
                 "%*stot_size : %zu\n"
                 "%*sdata     : %p\n",
@@ -705,7 +702,7 @@ void ABTI_sched_print(ABTI_sched *p_sched, FILE *p_os, int indent,
                 indent, "", ABTI_sched_get_total_size(p_sched), indent, "",
                 p_sched->data);
         if (print_sub == ABT_TRUE) {
-            int i;
+            size_t i;
             for (i = 0; i < p_sched->num_pools; i++) {
                 ABTI_pool *p_pool = ABTI_pool_get_ptr(p_sched->pools[i]);
                 ABTI_pool_print(p_pool, p_os, indent + 2);
diff --git a/src/stream.c b/src/stream.c
index db6b6ce..8a87b37 100644
--- a/src/stream.c
+++ b/src/stream.c
@@ -1361,7 +1361,7 @@ xstream_update_main_sched(ABTI_xstream **pp_local_xstream,
     ABTI_ythread *p_ythread = NULL;
     ABTI_sched *p_main_sched;
     ABTI_pool *p_tar_pool = NULL;
-    int p;
+    size_t p;
 
     /* The main scheduler will to be a ULT, not a tasklet */
     p_sched->type = ABT_SCHED_TYPE_ULT;
-- 
2.21.0 (Apple Git-122.2)


From 6b6ad2ce17e7945d30902804f1dd18d6474616b3 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Tue, 17 Nov 2020 15:02:34 -0600
Subject: [PATCH 19/40] warning: fix signed/unsigned comparison warnings

---
 examples/profiling/abtx_prof.h  |  4 ++--
 src/arch/abtd_affinity.c        | 19 ++++++++++--------
 src/arch/abtd_affinity_parser.c | 35 ++++++++++++++++++---------------
 src/arch/abtd_env.c             |  4 ++--
 src/error.c                     |  2 +-
 src/include/abtd.h              |  4 ++--
 src/include/abti_mem_pool.h     | 35 +++++++++++++++++----------------
 src/mem/mem_pool.c              |  8 ++++----
 src/sched/sched.c               |  3 ++-
 test/basic/error.c              |  2 +-
 test/basic/sched_set_main.c     |  5 ++---
 test/benchmark/task_ops_all.c   |  6 +++---
 test/benchmark/thread_ops_all.c |  6 +++---
 13 files changed, 70 insertions(+), 63 deletions(-)

diff --git a/examples/profiling/abtx_prof.h b/examples/profiling/abtx_prof.h
index 9883790..3a4bd7d 100644
--- a/examples/profiling/abtx_prof.h
+++ b/examples/profiling/abtx_prof.h
@@ -238,7 +238,7 @@ static inline uint64_t ABTXI_prof_get_cycles()
 #ifdef ABTXI_PROF_USE_CYCLES
 
 #define ABTXI_PROF_T int64_t
-#define ABTXI_PROF_T_INVALID 0xFFFFFFFFFFFFFFFF
+#define ABTXI_PROF_T_INVALID ((int64_t)0xFFFFFFFFFFFFFFFF)
 #define ABTXI_PROF_T_ZERO ((int64_t)0)
 #define ABTXI_prof_get_time() ABTXI_prof_get_cycles()
 #define ABTXI_PROF_T_STRING "HW cycles"
@@ -863,7 +863,7 @@ static char *ABTXI_prof_sprintf(ABTXI_prof_str_mem *p_str, size_t max_n,
     while (p_str->p_next) {
         p_str = p_str->p_next;
     }
-    if (p_str->len - p_str->cursor < max_n) {
+    if (p_str->len - p_str->cursor < (int)max_n) {
         int newlen = max_n > 4096 ? max_n : 4096;
         ABTXI_prof_str_mem *p_new = ABTXI_prof_str_mem_alloc(newlen);
         p_str->p_next = p_new;
diff --git a/src/arch/abtd_affinity.c b/src/arch/abtd_affinity.c
index 7fd9f5c..61e1242 100644
--- a/src/arch/abtd_affinity.c
+++ b/src/arch/abtd_affinity.c
@@ -183,7 +183,7 @@ typedef cpuset_t cpu_set_t;
 
 typedef struct {
     ABTD_affinity_cpuset initial_cpuset;
-    size_t num_cpusets;
+    uint32_t num_cpusets;
     ABTD_affinity_cpuset *cpusets;
 } global_affinity;
 
@@ -194,8 +194,9 @@ static inline int int_rem(int a, unsigned int b)
     /* Return x where a = n * b + x and 0 <= x < b */
     /* Because of ambiguity in the C specification, it uses a branch to check if
      * the result is positive. */
-    int ret = (a % b) + b;
-    return ret >= b ? (ret - b) : ret;
+    int int_b = b;
+    int ret = (a % int_b) + int_b;
+    return ret >= int_b ? (ret - int_b) : ret;
 }
 
 ABTU_ret_err static int get_num_cores(pthread_t native_thread, int *p_num_cores)
@@ -249,7 +250,7 @@ ABTU_ret_err static int apply_cpuset(pthread_t native_thread,
                                      const ABTD_affinity_cpuset *p_cpuset)
 {
 #ifdef HAVE_PTHREAD_SETAFFINITY_NP
-    size_t i;
+    uint32_t i;
     cpu_set_t cpuset;
     CPU_ZERO(&cpuset);
     for (i = 0; i < p_cpuset->num_cpuids; i++) {
@@ -268,7 +269,8 @@ void ABTD_affinity_init(const char *affinity_str)
     g_affinity.cpusets = NULL;
     g_affinity.initial_cpuset.cpuids = NULL;
     pthread_t self_native_thread = pthread_self();
-    int i, ret;
+    uint32_t i;
+    int ret;
     ret = get_num_cores(self_native_thread, &gp_ABTI_global->num_cores);
     if (ret != ABT_SUCCESS || gp_ABTI_global->num_cores == 0) {
         gp_ABTI_global->set_affinity = ABT_FALSE;
@@ -299,7 +301,7 @@ void ABTD_affinity_init(const char *affinity_str)
         ABTI_ASSERT(ret == ABT_SUCCESS);
         for (i = 0; i < p_list->num; i++) {
             const ABTD_affinity_id_list *p_id_list = p_list->p_id_lists[i];
-            int j, num_cpuids = 0, len_cpuids = 8;
+            uint32_t j, num_cpuids = 0, len_cpuids = 8;
             ret = ABTU_malloc(sizeof(int) * len_cpuids,
                               (void **)&g_affinity.cpusets[i].cpuids);
             ABTI_ASSERT(ret == ABT_SUCCESS);
@@ -313,7 +315,8 @@ void ABTD_affinity_init(const char *affinity_str)
                                       g_affinity.initial_cpuset.num_cpuids);
                 int cpuid = g_affinity.initial_cpuset.cpuids[cpuid_i];
                 /* If it is unique, add it.*/
-                int k, is_unique = 1;
+                uint32_t k;
+                int is_unique = 1;
                 for (k = 0; k < num_cpuids; k++) {
                     if (g_affinity.cpusets[i].cpuids[k] == cpuid) {
                         is_unique = 0;
@@ -373,7 +376,7 @@ void ABTD_affinity_finalize(void)
     }
     /* Free g_afinity. */
     ABTD_affinity_cpuset_destroy(&g_affinity.initial_cpuset);
-    int i;
+    uint32_t i;
     for (i = 0; i < g_affinity.num_cpusets; i++) {
         ABTD_affinity_cpuset_destroy(&g_affinity.cpusets[i]);
     }
diff --git a/src/arch/abtd_affinity_parser.c b/src/arch/abtd_affinity_parser.c
index 5329283..871ac45 100644
--- a/src/arch/abtd_affinity_parser.c
+++ b/src/arch/abtd_affinity_parser.c
@@ -21,14 +21,14 @@ static void id_list_free(ABTD_affinity_id_list *p_id_list)
     ABTU_free(p_id_list);
 }
 
-static void id_list_add(ABTD_affinity_id_list *p_id_list, int id, int num,
+static void id_list_add(ABTD_affinity_id_list *p_id_list, int id, uint32_t num,
                         int stride)
 {
     /* Needs to add num ids. */
-    int i, ret;
-    ret = ABTU_realloc(sizeof(int) * p_id_list->num,
-                       sizeof(int) * (p_id_list->num + num),
-                       (void **)&p_id_list->ids);
+    uint32_t i;
+    int ret = ABTU_realloc(sizeof(int) * p_id_list->num,
+                           sizeof(int) * (p_id_list->num + num),
+                           (void **)&p_id_list->ids);
     ABTI_ASSERT(ret == ABT_SUCCESS);
     for (i = 0; i < num; i++) {
         p_id_list->ids[p_id_list->num + i] = id + stride * i;
@@ -48,7 +48,7 @@ static ABTD_affinity_list *list_create(void)
 static void list_free(ABTD_affinity_list *p_list)
 {
     if (p_list) {
-        int i;
+        uint32_t i;
         for (i = 0; i < p_list->num; i++)
             id_list_free(p_list->p_id_lists[i]);
         free(p_list->p_id_lists);
@@ -57,10 +57,11 @@ static void list_free(ABTD_affinity_list *p_list)
 }
 
 static void list_add(ABTD_affinity_list *p_list, ABTD_affinity_id_list *p_base,
-                     int num, int stride)
+                     uint32_t num, int stride)
 {
     /* Needs to add num id-lists. */
-    int i, j, ret;
+    uint32_t i, j;
+    int ret;
 
     ret = ABTU_realloc(sizeof(ABTD_affinity_id_list *) * p_list->num,
                        sizeof(ABTD_affinity_id_list *) * (p_list->num + num),
@@ -86,9 +87,10 @@ static inline int is_whitespace(char c)
 }
 
 /* Integer. */
-static int consume_int(const char *str, int *p_index, int *p_val)
+static int consume_int(const char *str, uint32_t *p_index, int *p_val)
 {
-    int index = *p_index, val = 0, val_sign = 1;
+    uint32_t index = *p_index;
+    int val = 0, val_sign = 1;
     char flag = 'n';
     while (1) {
         char c = *(str + index);
@@ -122,9 +124,10 @@ static int consume_int(const char *str, int *p_index, int *p_val)
 }
 
 /* Positive integer */
-static int consume_pint(const char *str, int *p_index, int *p_val)
+static int consume_pint(const char *str, uint32_t *p_index, int *p_val)
 {
-    int index = *p_index, val;
+    uint32_t index = *p_index;
+    int val;
     /* The value must be positive. */
     if (consume_int(str, &index, &val) && val > 0) {
         *p_index = index;
@@ -135,9 +138,9 @@ static int consume_pint(const char *str, int *p_index, int *p_val)
 }
 
 /* Symbol.  If succeeded, it returns a consumed characters. */
-static int consume_symbol(const char *str, int *p_index, char symbol)
+static int consume_symbol(const char *str, uint32_t *p_index, char symbol)
 {
-    int index = *p_index;
+    uint32_t index = *p_index;
     while (1) {
         char c = *(str + index);
         if (c == symbol) {
@@ -154,7 +157,7 @@ static int consume_symbol(const char *str, int *p_index, char symbol)
 }
 
 static ABTD_affinity_id_list *parse_es_id_list(const char *affinity_str,
-                                               int *p_index)
+                                               uint32_t *p_index)
 {
     ABTD_affinity_id_list *p_id_list = id_list_create();
     int val;
@@ -206,7 +209,7 @@ static ABTD_affinity_list *parse_list(const char *affinity_str)
 {
     if (!affinity_str)
         return NULL;
-    int index = 0;
+    uint32_t index = 0;
     ABTD_affinity_list *p_list = list_create();
     ABTD_affinity_id_list *p_id_list = NULL;
     while (1) {
diff --git a/src/arch/abtd_env.c b/src/arch/abtd_env.c
index 70d54a8..bd1188c 100644
--- a/src/arch/abtd_env.c
+++ b/src/arch/abtd_env.c
@@ -241,7 +241,7 @@ static uint32_t roundup_pow2_uint32(uint32_t val)
      * 5 -> 8 */
     if (val == 0)
         return 0;
-    int i;
+    uint32_t i;
     for (i = 0; i < sizeof(uint32_t) * 8; i++) {
         if ((val - 1) >> i == 0)
             break;
@@ -254,7 +254,7 @@ static const char *get_abt_env(const char *env_suffix)
     /* Valid prefix is ABT_ and ABT_ENV_. ABT_ is prioritized. */
     char buffer[128];
     const char *prefixes[] = { "ABT_", "ABT_ENV_" };
-    int i;
+    uint32_t i;
     for (i = 0; i < sizeof(prefixes) / sizeof(prefixes[0]); i++) {
         strcpy(buffer, prefixes[i]);
         strcpy(buffer + strlen(prefixes[i]), env_suffix);
diff --git a/src/error.c b/src/error.c
index ee8495b..2d2d023 100644
--- a/src/error.c
+++ b/src/error.c
@@ -82,7 +82,7 @@ int ABT_error_get_str(int err, char *str, size_t *len)
                                      "ABT_ERR_INV_ARG" };
 
     ABTI_CHECK_TRUE(err >= ABT_SUCCESS &&
-                        err < sizeof(err_str) / sizeof(err_str[0]),
+                        err < (int)(sizeof(err_str) / sizeof(err_str[0])),
                     ABT_ERR_INV_ARG);
     /* This entry does not exist. */
     ABTI_CHECK_TRUE(err_str[err], ABT_ERR_INV_ARG);
diff --git a/src/include/abtd.h b/src/include/abtd.h
index 8b57293..677ddc1 100644
--- a/src/include/abtd.h
+++ b/src/include/abtd.h
@@ -65,11 +65,11 @@ void ABTD_affinity_cpuset_destroy(ABTD_affinity_cpuset *p_cpuset);
 
 /* ES Affinity Parser */
 typedef struct ABTD_affinity_id_list {
-    int num;
+    uint32_t num;
     int *ids; /* id here can be negative. */
 } ABTD_affinity_id_list;
 typedef struct ABTD_affinity_parser_list {
-    int num;
+    uint32_t num;
     ABTD_affinity_id_list **p_id_lists;
 } ABTD_affinity_list;
 ABTD_affinity_list *ABTD_affinity_list_create(const char *affinity_str);
diff --git a/src/include/abti_mem_pool.h b/src/include/abti_mem_pool.h
index b094a2a..2264731 100644
--- a/src/include/abti_mem_pool.h
+++ b/src/include/abti_mem_pool.h
@@ -14,7 +14,7 @@ typedef union ABTI_mem_pool_header_bucket_info {
     /* This is used when it is in ABTI_mem_pool_global_pool */
     ABTI_sync_lifo_element lifo_elem;
     /* This is used when it is in ABTI_mem_pool_local_pool */
-    int num_headers;
+    size_t num_headers;
 } ABTI_mem_pool_header_bucket_info;
 
 typedef struct ABTI_mem_pool_header {
@@ -47,15 +47,16 @@ typedef struct ABTI_mem_pool_page {
  *   .
  */
 typedef struct ABTI_mem_pool_global_pool {
-    size_t header_size;         /* Size of header */
-    size_t page_size;           /* Size of page (mem of ABTI_mem_pool_page) */
-    size_t alignment_hint;      /* Alignment hint for page */
-    size_t header_offset;       /* Offset of ABTI_mem_pool_header from the top
-                                 * of the memory segment; i.e., the pool returns
-                                 * p_header_memory_top + offset. */
-    int num_headers_per_bucket; /* Number of headers per bucket. */
-    int num_lp_type_requests;   /* Number of requests for large page allocation.
-                                 */
+    size_t header_size;    /* Size of header */
+    size_t page_size;      /* Size of page (mem of ABTI_mem_pool_page) */
+    size_t alignment_hint; /* Alignment hint for page */
+    size_t header_offset;  /* Offset of ABTI_mem_pool_header from the top
+                            * of the memory segment; i.e., the pool returns
+                            * p_header_memory_top + offset. */
+    size_t num_headers_per_bucket; /* Number of headers per bucket. */
+    uint32_t
+        num_lp_type_requests; /* Number of requests for large page allocation.
+                               */
     ABTU_MEM_LARGEPAGE_TYPE
     lp_type_requests[4]; /* Requests for large page allocation */
     ABTU_align_member_var(ABT_CONFIG_STATIC_CACHELINE_SIZE)
@@ -96,10 +97,10 @@ typedef struct ABTI_mem_pool_local_pool {
 } ABTI_mem_pool_local_pool;
 
 void ABTI_mem_pool_init_global_pool(
-    ABTI_mem_pool_global_pool *p_global_pool, int num_headers_per_bucket,
+    ABTI_mem_pool_global_pool *p_global_pool, size_t num_headers_per_bucket,
     size_t header_size, size_t header_offset, size_t page_size,
-    const ABTU_MEM_LARGEPAGE_TYPE *lp_type_requests, int num_lp_type_requests,
-    size_t alignment_hint);
+    const ABTU_MEM_LARGEPAGE_TYPE *lp_type_requests,
+    uint32_t num_lp_type_requests, size_t alignment_hint);
 void ABTI_mem_pool_destroy_global_pool(
     ABTI_mem_pool_global_pool *p_global_pool);
 void ABTI_mem_pool_init_local_pool(ABTI_mem_pool_local_pool *p_local_pool,
@@ -115,7 +116,7 @@ ABTI_mem_pool_alloc(ABTI_mem_pool_local_pool *p_local_pool, void **p_mem)
 {
     size_t bucket_index = p_local_pool->bucket_index;
     ABTI_mem_pool_header *cur_bucket = p_local_pool->buckets[bucket_index];
-    int num_headers_in_cur_bucket = cur_bucket->bucket_info.num_headers;
+    size_t num_headers_in_cur_bucket = cur_bucket->bucket_info.num_headers;
     /* At least one header is available in the current bucket, so it must be
      * larger than 0. */
     ABTI_ASSERT(num_headers_in_cur_bucket >= 1);
@@ -124,14 +125,14 @@ ABTI_mem_pool_alloc(ABTI_mem_pool_local_pool *p_local_pool, void **p_mem)
         if (bucket_index == 0) {
             /* cur_bucket is the last header in this pool.
              * Let's get some buckets from the global pool. */
-            int i;
+            size_t i;
             for (i = 0; i < ABT_MEM_POOL_NUM_TAKE_BUCKETS; i++) {
                 int abt_errno =
                     ABTI_mem_pool_take_bucket(p_local_pool->p_global_pool,
                                               &p_local_pool->buckets[i]);
                 if (ABTI_IS_ERROR_CHECK_ENABLED && abt_errno != ABT_SUCCESS) {
                     /* Return buckets that have been already taken. */
-                    int j;
+                    size_t j;
                     for (j = 0; j < i; j++) {
                         ABTI_mem_pool_return_bucket(p_local_pool->p_global_pool,
                                                     p_local_pool->buckets[j]);
@@ -166,7 +167,7 @@ static inline void ABTI_mem_pool_free(ABTI_mem_pool_local_pool *p_local_pool,
         p_local_pool->num_headers_per_bucket) {
         /* cur_bucket is full. */
         if (++bucket_index == ABT_MEM_POOL_MAX_LOCAL_BUCKETS) {
-            int i;
+            size_t i;
             /* All buckets are full, so let's return some old buckets. */
             for (i = 0; i < ABT_MEM_POOL_NUM_RETURN_BUCKETS; i++) {
                 ABTI_mem_pool_return_bucket(p_local_pool->p_global_pool,
diff --git a/src/mem/mem_pool.c b/src/mem/mem_pool.c
index 2a82f5a..e45dee3 100644
--- a/src/mem/mem_pool.c
+++ b/src/mem/mem_pool.c
@@ -75,10 +75,10 @@ mem_pool_return_partial_bucket(ABTI_mem_pool_global_pool *p_global_pool,
 }
 
 void ABTI_mem_pool_init_global_pool(
-    ABTI_mem_pool_global_pool *p_global_pool, int num_headers_per_bucket,
+    ABTI_mem_pool_global_pool *p_global_pool, size_t num_headers_per_bucket,
     size_t header_size, size_t header_offset, size_t page_size,
-    const ABTU_MEM_LARGEPAGE_TYPE *lp_type_requests, int num_lp_type_requests,
-    size_t alignment_hint)
+    const ABTU_MEM_LARGEPAGE_TYPE *lp_type_requests,
+    uint32_t num_lp_type_requests, size_t alignment_hint)
 {
     p_global_pool->num_headers_per_bucket = num_headers_per_bucket;
     ABTI_ASSERT(header_offset + sizeof(ABTI_mem_pool_header) <= header_size);
@@ -148,7 +148,7 @@ void ABTI_mem_pool_destroy_local_pool(ABTI_mem_pool_local_pool *p_local_pool)
         ABTI_mem_pool_return_bucket(p_local_pool->p_global_pool,
                                     p_local_pool->buckets[i]);
     }
-    const int num_headers_per_bucket = p_local_pool->num_headers_per_bucket;
+    const size_t num_headers_per_bucket = p_local_pool->num_headers_per_bucket;
     ABTI_mem_pool_header *cur_bucket = p_local_pool->buckets[bucket_index];
     if (cur_bucket->bucket_info.num_headers == num_headers_per_bucket) {
         /* The last bucket is also full. Return the last bucket as well. */
diff --git a/src/sched/sched.c b/src/sched/sched.c
index 2f24ae4..2ad7007 100644
--- a/src/sched/sched.c
+++ b/src/sched/sched.c
@@ -166,7 +166,8 @@ int ABT_sched_get_pools(ABT_sched sched, int max_pools, int idx,
 {
     ABTI_sched *p_sched = ABTI_sched_get_ptr(sched);
     ABTI_CHECK_NULL_SCHED_PTR(p_sched);
-    ABTI_CHECK_TRUE((size_t)(idx + max_pools) <= p_sched->num_pools, ABT_ERR_SCHED);
+    ABTI_CHECK_TRUE((size_t)(idx + max_pools) <= p_sched->num_pools,
+                    ABT_ERR_SCHED);
 
     int p;
     for (p = idx; p < idx + max_pools; p++) {
diff --git a/test/basic/error.c b/test/basic/error.c
index 4bc9615..a0ccfcd 100644
--- a/test/basic/error.c
+++ b/test/basic/error.c
@@ -76,7 +76,7 @@ int main(int argc, char *argv[])
         { "ABT_ERR_INV_ARG", ABT_ERR_INV_ARG },
     };
 
-    for (i = 0; i < sizeof(error_pairs) / sizeof(error_pairs[0]); i++) {
+    for (i = 0; i < (int)(sizeof(error_pairs) / sizeof(error_pairs[0])); i++) {
         char str[256];
         ret = ABT_error_get_str(error_pairs[i].code, str, NULL);
         ATS_ERROR(ret, "ABT_error_get_str");
diff --git a/test/basic/sched_set_main.c b/test/basic/sched_set_main.c
index d96814f..7a199a2 100644
--- a/test/basic/sched_set_main.c
+++ b/test/basic/sched_set_main.c
@@ -78,9 +78,8 @@ static void thread_func(void *arg)
 
 int main(int argc, char *argv[])
 {
-    size_t i;
     int ret;
-    int num_xstreams = DEFAULT_NUM_XSTREAMS;
+    int i, num_xstreams = DEFAULT_NUM_XSTREAMS;
     ABT_xstream *xstreams;
     ABT_pool *pools;
     ABT_thread *threads;
@@ -114,7 +113,7 @@ int main(int argc, char *argv[])
 
     /* Create ULTs */
     for (i = 1; i < num_xstreams; i++) {
-        ret = ABT_thread_create(pools[i], thread_func, (void *)i,
+        ret = ABT_thread_create(pools[i], thread_func, (void *)((uintptr_t)i),
                                 ABT_THREAD_ATTR_NULL, &threads[i]);
         ATS_ERROR(ret, "ABT_thread_create");
     }
diff --git a/test/benchmark/task_ops_all.c b/test/benchmark/task_ops_all.c
index fb813b5..8367a5f 100644
--- a/test/benchmark/task_ops_all.c
+++ b/test/benchmark/task_ops_all.c
@@ -66,7 +66,7 @@ int main(int argc, char *argv[])
     ABT_pool(*all_pools)[2];
     ABT_sched *scheds;
     ABT_thread *top_threads;
-    size_t i, t;
+    int i, t;
     uint64_t t_start;
 
     /* read command-line arguments */
@@ -128,7 +128,7 @@ int main(int argc, char *argv[])
 
         /* warm-up */
         for (i = 0; i < num_xstreams; i++) {
-            ABT_thread_create(all_pools[i][0], test_fn, (void *)i,
+            ABT_thread_create(all_pools[i][0], test_fn, (void *)((uintptr_t)i),
                               ABT_THREAD_ATTR_NULL, &top_threads[i]);
         }
         for (i = 0; i < num_xstreams; i++) {
@@ -138,7 +138,7 @@ int main(int argc, char *argv[])
         /* measurement */
         t_start = ATS_get_cycles();
         for (i = 0; i < num_xstreams; i++) {
-            ABT_thread_create(all_pools[i][0], test_fn, (void *)i,
+            ABT_thread_create(all_pools[i][0], test_fn, (void *)((uintptr_t)i),
                               ABT_THREAD_ATTR_NULL, &top_threads[i]);
         }
         for (i = 0; i < num_xstreams; i++) {
diff --git a/test/benchmark/thread_ops_all.c b/test/benchmark/thread_ops_all.c
index 96be1df..5f1ac24 100644
--- a/test/benchmark/thread_ops_all.c
+++ b/test/benchmark/thread_ops_all.c
@@ -285,7 +285,7 @@ int main(int argc, char *argv[])
     ABT_pool(*all_pools)[2];
     ABT_sched *scheds;
     ABT_thread *top_threads;
-    size_t i, t;
+    int i, t;
     uint64_t t_start;
 
     /* read command-line arguments */
@@ -381,7 +381,7 @@ int main(int argc, char *argv[])
 
         /* warm-up */
         for (i = 0; i < num_xstreams; i++) {
-            ABT_thread_create(all_pools[i][0], test_fn, (void *)i,
+            ABT_thread_create(all_pools[i][0], test_fn, (void *)((uintptr_t)i),
                               ABT_THREAD_ATTR_NULL, &top_threads[i]);
         }
         for (i = 0; i < num_xstreams; i++) {
@@ -395,7 +395,7 @@ int main(int argc, char *argv[])
         t_start = ATS_get_cycles();
 #endif
         for (i = 0; i < num_xstreams; i++) {
-            ABT_thread_create(all_pools[i][0], test_fn, (void *)i,
+            ABT_thread_create(all_pools[i][0], test_fn, (void *)((uintptr_t)i),
                               ABT_THREAD_ATTR_NULL, &top_threads[i]);
         }
         for (i = 0; i < num_xstreams; i++) {
-- 
2.21.0 (Apple Git-122.2)


From 175ec19a68f06af799e845349d799fb1473c623b Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Mon, 23 Nov 2020 08:13:19 -0600
Subject: [PATCH 20/40] eventual: use ABT_bool for ABT_eventual_test

ABT_bool should be used for the "is_ready" argument of ABT_eventual_test(),
which was int.  This patch fixes it.  Note that currently ABT_bool is int, so
it does not cause any ABI compatibility issue.
---
 src/eventual.c               | 4 ++--
 src/include/abt.h.in         | 2 +-
 test/basic/eventual_create.c | 3 ++-
 3 files changed, 5 insertions(+), 4 deletions(-)

diff --git a/src/eventual.c b/src/eventual.c
index 0096d63..f5911e1 100644
--- a/src/eventual.c
+++ b/src/eventual.c
@@ -185,11 +185,11 @@ int ABT_eventual_wait(ABT_eventual eventual, void **value)
  * @return Error code
  * @retval ABT_SUCCESS on success
  */
-int ABT_eventual_test(ABT_eventual eventual, void **value, int *is_ready)
+int ABT_eventual_test(ABT_eventual eventual, void **value, ABT_bool *is_ready)
 {
     ABTI_eventual *p_eventual = ABTI_eventual_get_ptr(eventual);
     ABTI_CHECK_NULL_EVENTUAL_PTR(p_eventual);
-    int flag = ABT_FALSE;
+    ABT_bool flag = ABT_FALSE;
 
     ABTI_spinlock_acquire(&p_eventual->lock);
     if (p_eventual->ready != ABT_FALSE) {
diff --git a/src/include/abt.h.in b/src/include/abt.h.in
index 6cd03b6..198f5dd 100644
--- a/src/include/abt.h.in
+++ b/src/include/abt.h.in
@@ -753,7 +753,7 @@ int ABT_rwlock_unlock(ABT_rwlock rwlock) ABT_API_PUBLIC;
 int ABT_eventual_create(int nbytes, ABT_eventual *neweventual) ABT_API_PUBLIC;
 int ABT_eventual_free(ABT_eventual *eventual) ABT_API_PUBLIC;
 int ABT_eventual_wait(ABT_eventual eventual, void **value) ABT_API_PUBLIC;
-int ABT_eventual_test(ABT_eventual eventual, void **value, int *is_ready) ABT_API_PUBLIC;
+int ABT_eventual_test(ABT_eventual eventual, void **value, ABT_bool *is_ready) ABT_API_PUBLIC;
 int ABT_eventual_set(ABT_eventual eventual, void *value, int nbytes) ABT_API_PUBLIC;
 int ABT_eventual_reset(ABT_eventual eventual) ABT_API_PUBLIC;
 
diff --git a/test/basic/eventual_create.c b/test/basic/eventual_create.c
index 81a2fc4..2cda2c9 100644
--- a/test/basic/eventual_create.c
+++ b/test/basic/eventual_create.c
@@ -30,7 +30,8 @@ void fn1(void *args)
 void fn2(void *args)
 {
     ATS_UNUSED(args);
-    int i = 0, is_ready = 0;
+    int i = 0;
+    ABT_bool is_ready = 0;
     void *data;
     ATS_printf(1, "Thread 2 iteration %d waiting from eventual\n", i);
     ABT_eventual_test(myeventual, &data, &is_ready);
-- 
2.21.0 (Apple Git-122.2)


From 2fe9cccc82a94ea758caf3312d88f54afbe6af3b Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Tue, 1 Dec 2020 18:54:16 -0600
Subject: [PATCH 21/40] waitlist: implement ABTI_waitlist

ABTI_waitlist is a helper to suspend and resume multiple threads, which is
useful to implement synchronization objects.  The next commit will change the
implementation of existing synchronization objects.
---
 src/include/Makefile.mk     |   1 +
 src/include/abti.h          |   9 +-
 src/include/abti_spinlock.h |   7 +-
 src/include/abti_waitlist.h | 214 ++++++++++++++++++++++++++++++++++++
 4 files changed, 229 insertions(+), 2 deletions(-)
 create mode 100644 src/include/abti_waitlist.h

diff --git a/src/include/Makefile.mk b/src/include/Makefile.mk
index 2410cf7..adcb28e 100644
--- a/src/include/Makefile.mk
+++ b/src/include/Makefile.mk
@@ -38,6 +38,7 @@ noinst_HEADERS = \
 	include/abti_timer.h \
 	include/abti_thread.h \
 	include/abti_thread_attr.h \
+	include/abti_waitlist.h \
 	include/abti_tool.h \
 	include/abti_valgrind.h \
 	include/abti_ythread.h \
diff --git a/src/include/abti.h b/src/include/abti.h
index 4d7cf95..bbb9c7c 100644
--- a/src/include/abti.h
+++ b/src/include/abti.h
@@ -118,6 +118,7 @@ typedef struct ABTI_ythread_queue ABTI_ythread_queue;
 typedef struct ABTI_key ABTI_key;
 typedef struct ABTI_ktelem ABTI_ktelem;
 typedef struct ABTI_ktable ABTI_ktable;
+typedef struct ABTI_waitlist ABTI_waitlist;
 typedef struct ABTI_mutex_attr ABTI_mutex_attr;
 typedef struct ABTI_mutex ABTI_mutex;
 typedef struct ABTI_cond ABTI_cond;
@@ -150,6 +151,11 @@ typedef struct ABTI_spinlock ABTI_spinlock;
 #include "abti_mem_pool.h"
 
 /* Definitions */
+struct ABTI_waitlist {
+    ABTI_thread *p_head;
+    ABTI_thread *p_tail;
+};
+
 struct ABTI_mutex_attr {
     uint32_t attrs;          /* bit-or'ed attributes */
     uint32_t nesting_cnt;    /* nesting count */
@@ -577,6 +583,7 @@ void ABTI_mutex_wake_de(ABTI_local *p_local, ABTI_mutex *p_mutex);
 void ABTI_info_print_config(FILE *fp);
 void ABTI_info_check_print_all_thread_stacks(void);
 
+#include "abti_timer.h"
 #include "abti_log.h"
 #include "abti_local.h"
 #include "abti_self.h"
@@ -588,6 +595,7 @@ void ABTI_info_check_print_all_thread_stacks(void);
 #include "abti_tool.h"
 #include "abti_ythread.h"
 #include "abti_thread_attr.h"
+#include "abti_waitlist.h"
 #include "abti_mutex.h"
 #include "abti_mutex_attr.h"
 #include "abti_cond.h"
@@ -596,7 +604,6 @@ void ABTI_info_check_print_all_thread_stacks(void);
 #include "abti_future.h"
 #include "abti_barrier.h"
 #include "abti_stream_barrier.h"
-#include "abti_timer.h"
 #include "abti_mem.h"
 #include "abti_key.h"
 
diff --git a/src/include/abti_spinlock.h b/src/include/abti_spinlock.h
index eb2ba9e..ef6f864 100644
--- a/src/include/abti_spinlock.h
+++ b/src/include/abti_spinlock.h
@@ -15,6 +15,11 @@ struct ABTI_spinlock {
         ABTD_ATOMIC_BOOL_STATIC_INITIALIZER(0)                                 \
     }
 
+static inline ABT_bool ABTI_spinlock_is_locked(const ABTI_spinlock *p_lock)
+{
+    return ABTD_atomic_acquire_load_bool(&p_lock->val);
+}
+
 static inline void ABTI_spinlock_clear(ABTI_spinlock *p_lock)
 {
     ABTD_atomic_relaxed_clear_bool(&p_lock->val);
@@ -23,7 +28,7 @@ static inline void ABTI_spinlock_clear(ABTI_spinlock *p_lock)
 static inline void ABTI_spinlock_acquire(ABTI_spinlock *p_lock)
 {
     while (ABTD_atomic_test_and_set_bool(&p_lock->val)) {
-        while (ABTD_atomic_acquire_load_bool(&p_lock->val) != ABT_FALSE)
+        while (ABTI_spinlock_is_locked(p_lock) != ABT_FALSE)
             ;
     }
 }
diff --git a/src/include/abti_waitlist.h b/src/include/abti_waitlist.h
new file mode 100644
index 0000000..d3344ab
--- /dev/null
+++ b/src/include/abti_waitlist.h
@@ -0,0 +1,214 @@
+/* -*- Mode: C; c-basic-offset:4 ; indent-tabs-mode:nil ; -*- */
+/*
+ * See COPYRIGHT in top-level directory.
+ */
+
+#ifndef ABTI_WAITLIST_H_INCLUDED
+#define ABTI_WAITLIST_H_INCLUDED
+
+#include "abt_config.h"
+
+static inline void ABTI_waitlist_init(ABTI_waitlist *p_waitlist)
+{
+    p_waitlist->p_head = NULL;
+    p_waitlist->p_tail = NULL;
+}
+
+static inline void
+ABTI_waitlist_wait_and_unlock(ABTI_local **pp_local, ABTI_waitlist *p_waitlist,
+                              ABTI_spinlock *p_lock, ABT_bool blocking,
+                              ABT_sync_event_type sync_event_type, void *p_sync)
+{
+    ABTI_ASSERT(ABTI_spinlock_is_locked(p_lock) == ABT_TRUE);
+    ABTI_ythread *p_ythread = NULL;
+    ABTI_xstream *p_local_xstream = ABTI_local_get_xstream_or_null(*pp_local);
+    if (!ABTI_IS_EXT_THREAD_ENABLED || p_local_xstream) {
+        p_ythread = ABTI_thread_get_ythread_or_null(p_local_xstream->p_thread);
+    }
+    if (!p_ythread || blocking) {
+        /* External thread, non-yieldable thread, or asked to block */
+        ABTI_thread thread;
+        thread.type = ABTI_THREAD_TYPE_EXT;
+        /* use state for synchronization */
+        ABTD_atomic_relaxed_store_int(&thread.state, ABT_THREAD_STATE_BLOCKED);
+        /* Add thread to the list. */
+        thread.p_next = NULL;
+        if (p_waitlist->p_head == NULL) {
+            p_waitlist->p_head = &thread;
+        } else {
+            p_waitlist->p_tail->p_next = &thread;
+        }
+        p_waitlist->p_tail = &thread;
+
+        /* Non-yieldable thread is waiting here. */
+        ABTI_spinlock_release(p_lock);
+        while (ABTD_atomic_acquire_load_int(&thread.state) !=
+               ABT_THREAD_STATE_READY)
+            ;
+    } else {
+        /* Add p_thread to the list. */
+        p_ythread->thread.p_next = NULL;
+        if (p_waitlist->p_head == NULL) {
+            p_waitlist->p_head = &p_ythread->thread;
+        } else {
+            p_waitlist->p_tail->p_next = &p_ythread->thread;
+        }
+        p_waitlist->p_tail = &p_ythread->thread;
+
+        /* Suspend the current ULT */
+        ABTI_ythread_set_blocked(p_ythread);
+        ABTI_spinlock_release(p_lock);
+        ABTI_ythread_suspend(&p_local_xstream, p_ythread,
+                             ABT_SYNC_EVENT_TYPE_EVENTUAL, p_sync);
+        /* Resumed. */
+        *pp_local = ABTI_xstream_get_local(p_local_xstream);
+    }
+}
+
+/* Return ABT_TRUE if timed out. */
+static inline ABT_bool ABTI_waitlist_wait_timedout_and_unlock(
+    ABTI_local **pp_local, ABTI_waitlist *p_waitlist, ABTI_spinlock *p_lock,
+    ABT_bool blocking, double target_time, ABT_sync_event_type sync_event_type,
+    void *p_sync)
+{
+    ABTI_ASSERT(ABTI_spinlock_is_locked(p_lock) == ABT_TRUE);
+    ABTI_ythread *p_ythread = NULL;
+    ABTI_xstream *p_local_xstream = ABTI_local_get_xstream_or_null(*pp_local);
+    if (!ABTI_IS_EXT_THREAD_ENABLED || p_local_xstream)
+        p_ythread = ABTI_thread_get_ythread_or_null(p_local_xstream->p_thread);
+
+    /* Always use a dummy thread. */
+    ABTI_thread thread;
+    thread.type = ABTI_THREAD_TYPE_EXT;
+    /* use state for synchronization */
+    ABTD_atomic_relaxed_store_int(&thread.state, ABT_THREAD_STATE_BLOCKED);
+
+    /* Add p_thread to the list.  This implementation is tricky since this
+     * updates p_prev as well for removal on timeout while the other functions
+     * (e.g., wait, broadcast, signal) do not update it. */
+    thread.p_next = NULL;
+    if (p_waitlist->p_head == NULL) {
+        p_waitlist->p_head = &thread;
+        thread.p_prev = NULL;
+    } else {
+        p_waitlist->p_tail->p_next = &thread;
+        thread.p_prev = p_waitlist->p_tail;
+    }
+    p_waitlist->p_tail = &thread;
+
+    /* Waiting here. */
+    ABTI_spinlock_release(p_lock);
+    while (ABTD_atomic_acquire_load_int(&thread.state) !=
+           ABT_THREAD_STATE_READY) {
+        double cur_time = ABTI_get_wtime();
+        if (cur_time >= target_time) {
+            /* Timeout.  Remove this thread if not signaled even after taking
+             * a lock. */
+            ABTI_spinlock_acquire(p_lock);
+            ABT_bool is_timedout =
+                (ABTD_atomic_acquire_load_int(&thread.state) !=
+                 ABT_THREAD_STATE_READY)
+                    ? ABT_TRUE
+                    : ABT_FALSE;
+            if (is_timedout) {
+                /* This thread is still in the list. */
+                if (p_waitlist->p_head == &thread) {
+                    /* thread is a head. */
+                    /* Note that thread->p_prev cannot be used to check whether
+                     * thread is a head or not because signal and broadcast do
+                     * not modify thread->p_prev. */
+                    p_waitlist->p_head = thread.p_next;
+                    if (!thread.p_next) {
+                        /* This thread is p_tail */
+                        ABTI_ASSERT(p_waitlist->p_tail == &thread);
+                        p_waitlist->p_tail = NULL;
+                    }
+                } else {
+                    /* thread is not a head and thus p_prev exists. */
+                    ABTI_ASSERT(thread.p_prev);
+                    thread.p_prev->p_next = thread.p_next;
+                    if (thread.p_next && thread.type == ABTI_THREAD_TYPE_EXT) {
+                        /* Only an external thread (created by this function)
+                         * checks p_prev.  Note that an external thread is
+                         * dummy, so updating p_prev is allowed. */
+                        thread.p_next->p_prev = thread.p_prev;
+                    } else {
+                        /* This thread is p_tail */
+                        ABTI_ASSERT(p_waitlist->p_tail == &thread);
+                        p_waitlist->p_tail = thread.p_prev;
+                    }
+                }
+                /* We do not need to modify thread->p_prev and p_next since this
+                 * dummy thread is no longer used. */
+            }
+            ABTI_spinlock_release(p_lock);
+            return is_timedout;
+        }
+        if (p_ythread && !blocking) {
+            ABTI_ythread_yield(&p_local_xstream, p_ythread, sync_event_type,
+                               p_sync);
+            *pp_local = ABTI_xstream_get_local(p_local_xstream);
+        } else {
+            ABTD_atomic_pause();
+        }
+    }
+    /* Singled */
+    return ABT_FALSE;
+}
+
+static inline void ABTI_waitlist_signal(ABTI_local *p_local,
+                                        ABTI_waitlist *p_waitlist)
+{
+    ABTI_thread *p_thread = p_waitlist->p_head;
+    if (p_thread) {
+        ABTI_thread *p_next = p_thread->p_next;
+        p_thread->p_next = NULL;
+
+        ABTI_ythread *p_ythread = ABTI_thread_get_ythread_or_null(p_thread);
+        if (p_ythread) {
+            ABTI_ythread_set_ready(p_local, p_ythread);
+        } else {
+            /* When p_thread is an external thread or a tasklet */
+            ABTD_atomic_release_store_int(&p_thread->state,
+                                          ABT_THREAD_STATE_READY);
+        }
+        /* After updating p_thread->state, p_thread can be updated and
+         * freed. */
+        p_waitlist->p_head = p_next;
+        if (!p_next)
+            p_waitlist->p_tail = NULL;
+    }
+}
+
+static inline void ABTI_waitlist_broadcast(ABTI_local *p_local,
+                                           ABTI_waitlist *p_waitlist)
+{
+    ABTI_thread *p_thread = p_waitlist->p_head;
+    if (p_thread) {
+        do {
+            ABTI_thread *p_next = p_thread->p_next;
+            p_thread->p_next = NULL;
+
+            ABTI_ythread *p_ythread = ABTI_thread_get_ythread_or_null(p_thread);
+            if (p_ythread) {
+                ABTI_ythread_set_ready(p_local, p_ythread);
+            } else {
+                /* When p_thread is an external thread or a tasklet */
+                ABTD_atomic_release_store_int(&p_thread->state,
+                                              ABT_THREAD_STATE_READY);
+            }
+            /* After updating p_thread->state, p_thread can be updated and
+             * freed. */
+            p_thread = p_next;
+        } while (p_thread);
+        p_waitlist->p_head = NULL;
+        p_waitlist->p_tail = NULL;
+    }
+}
+
+static inline ABT_bool ABTI_waitlist_is_empty(ABTI_waitlist *p_waitlist)
+{
+    return p_waitlist->p_head ? ABT_TRUE : ABT_FALSE;
+}
+
+#endif /* ABTI_WAITLIST_H_INCLUDED */
-- 
2.21.0 (Apple Git-122.2)


From b0913914964ae7b3ad3e77c7198f7d8dc520be89 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Tue, 1 Dec 2020 18:56:29 -0600
Subject: [PATCH 22/40] waitlist: use ABTI_waitlist for synchronization objects

This patch uses ABTI_waitlist for synchronization objects including ABT_barrier,
ABT_cond, ABT_eventual, and ABT_future.  This can reduce the common code that
manages a queue of waiting threads.
---
 src/barrier.c           | 105 +++---------------------------------
 src/cond.c              | 117 ++++------------------------------------
 src/eventual.c          |  92 ++++---------------------------
 src/futures.c           |  88 +++---------------------------
 src/include/abti.h      |  13 ++---
 src/include/abti_cond.h | 105 +++---------------------------------
 6 files changed, 43 insertions(+), 477 deletions(-)

diff --git a/src/barrier.c b/src/barrier.c
index 31c2399..88bffb7 100644
--- a/src/barrier.c
+++ b/src/barrier.c
@@ -35,20 +35,7 @@ int ABT_barrier_create(uint32_t num_waiters, ABT_barrier *newbarrier)
     ABTI_spinlock_clear(&p_newbarrier->lock);
     p_newbarrier->num_waiters = arg_num_waiters;
     p_newbarrier->counter = 0;
-    abt_errno = ABTU_malloc(arg_num_waiters * sizeof(ABTI_ythread *),
-                            (void **)&p_newbarrier->waiters);
-    if (ABTI_IS_ERROR_CHECK_ENABLED && abt_errno != ABT_SUCCESS) {
-        ABTU_free(p_newbarrier);
-        ABTI_HANDLE_ERROR(abt_errno);
-    }
-    abt_errno = ABTU_malloc(arg_num_waiters * sizeof(ABT_unit_type),
-                            (void **)&p_newbarrier->waiter_type);
-    if (ABTI_IS_ERROR_CHECK_ENABLED && abt_errno != ABT_SUCCESS) {
-        ABTU_free(p_newbarrier->waiters);
-        ABTU_free(p_newbarrier);
-        ABTI_HANDLE_ERROR(abt_errno);
-    }
-
+    ABTI_waitlist_init(&p_newbarrier->waitlist);
     /* Return value */
     *newbarrier = ABTI_barrier_get_handle(p_newbarrier);
     return ABT_SUCCESS;
@@ -76,28 +63,9 @@ int ABT_barrier_reinit(ABT_barrier barrier, uint32_t num_waiters)
 
     /* Only when num_waiters is different from p_barrier->num_waiters, we
      * change p_barrier. */
-    if (arg_num_waiters < p_barrier->num_waiters) {
+    if (arg_num_waiters != p_barrier->num_waiters) {
         /* We can reuse waiters and waiter_type arrays */
         p_barrier->num_waiters = arg_num_waiters;
-    } else if (arg_num_waiters > p_barrier->num_waiters) {
-        /* Free existing arrays and reallocate them */
-        int abt_errno;
-        ABTI_ythread **new_waiters;
-        ABT_unit_type *new_waiter_types;
-        abt_errno = ABTU_malloc(arg_num_waiters * sizeof(ABTI_ythread *),
-                                (void **)&new_waiters);
-        ABTI_CHECK_ERROR(abt_errno);
-        abt_errno = ABTU_malloc(arg_num_waiters * sizeof(ABT_unit_type),
-                                (void **)&new_waiter_types);
-        if (ABTI_IS_ERROR_CHECK_ENABLED && abt_errno != ABT_SUCCESS) {
-            ABTU_free(new_waiters);
-            ABTI_HANDLE_ERROR(abt_errno);
-        }
-        p_barrier->num_waiters = arg_num_waiters;
-        ABTU_free(p_barrier->waiters);
-        ABTU_free(p_barrier->waiter_type);
-        p_barrier->waiters = new_waiters;
-        p_barrier->waiter_type = new_waiter_types;
     }
     return ABT_SUCCESS;
 }
@@ -128,8 +96,6 @@ int ABT_barrier_free(ABT_barrier *barrier)
     /* p_barrier->counter must be checked after taking a lock. */
     ABTI_ASSERT(p_barrier->counter == 0);
 
-    ABTU_free(p_barrier->waiters);
-    ABTU_free(p_barrier->waiter_type);
     ABTU_free(p_barrier);
 
     /* Return value */
@@ -153,77 +119,22 @@ int ABT_barrier_wait(ABT_barrier barrier)
     ABTI_local *p_local = ABTI_local_get_local();
     ABTI_barrier *p_barrier = ABTI_barrier_get_ptr(barrier);
     ABTI_CHECK_NULL_BARRIER_PTR(p_barrier);
-    size_t pos;
 
     ABTI_spinlock_acquire(&p_barrier->lock);
 
     ABTI_ASSERT(p_barrier->counter < p_barrier->num_waiters);
-    pos = p_barrier->counter++;
+    p_barrier->counter++;
 
     /* If we do not have all the waiters yet */
     if (p_barrier->counter < p_barrier->num_waiters) {
-        ABTI_ythread *p_ythread = NULL;
-        ABT_unit_type type;
-        ABTD_atomic_int32 ext_signal = ABTD_ATOMIC_INT32_STATIC_INITIALIZER(0);
-
-        ABTI_xstream *p_local_xstream = ABTI_local_get_xstream_or_null(p_local);
-        if (!ABTI_IS_EXT_THREAD_ENABLED || p_local_xstream) {
-            p_ythread =
-                ABTI_thread_get_ythread_or_null(p_local_xstream->p_thread);
-        }
-        if (p_ythread) {
-            /* yieldable thread */
-            type = ABT_UNIT_TYPE_THREAD;
-        } else {
-            /* external thread or non-yieldable thread */
-            /* Check size if ext_signal can be stored in p_thread. */
-            ABTI_STATIC_ASSERT(sizeof(ext_signal) <= sizeof(p_ythread));
-            p_ythread = (ABTI_ythread *)&ext_signal;
-            type = ABT_UNIT_TYPE_EXT;
-        }
-
-        /* Keep the waiter's information */
-        p_barrier->waiters[pos] = p_ythread;
-        p_barrier->waiter_type[pos] = type;
-
-        if (type == ABT_UNIT_TYPE_THREAD) {
-            /* Change the ULT's state to BLOCKED */
-            ABTI_ythread_set_blocked(p_ythread);
-        }
-
-        ABTI_spinlock_release(&p_barrier->lock);
-
-        if (type == ABT_UNIT_TYPE_THREAD) {
-            /* Suspend the current ULT */
-            ABTI_ythread_suspend(&p_local_xstream, p_ythread,
-                                 ABT_SYNC_EVENT_TYPE_BARRIER,
-                                 (void *)p_barrier);
-        } else {
-            /* External thread is waiting here polling ext_signal. */
-            /* FIXME: need a better implementation */
-            while (!ABTD_atomic_acquire_load_int32(&ext_signal))
-                ;
-        }
+        ABTI_waitlist_wait_and_unlock(&p_local, &p_barrier->waitlist,
+                                      &p_barrier->lock, ABT_FALSE,
+                                      ABT_SYNC_EVENT_TYPE_BARRIER,
+                                      (void *)p_barrier);
     } else {
-        /* Signal all the waiting ULTs */
-        size_t i;
-        for (i = 0; i < p_barrier->num_waiters - 1; i++) {
-            ABTI_ythread *p_ythread = p_barrier->waiters[i];
-            if (p_barrier->waiter_type[i] == ABT_UNIT_TYPE_THREAD) {
-                ABTI_ythread_set_ready(p_local, p_ythread);
-            } else {
-                /* When p_cur is an external thread */
-                ABTD_atomic_int32 *p_ext_signal =
-                    (ABTD_atomic_int32 *)p_ythread;
-                ABTD_atomic_release_store_int32(p_ext_signal, 1);
-            }
-
-            p_barrier->waiters[i] = NULL;
-        }
-
+        ABTI_waitlist_broadcast(p_local, &p_barrier->waitlist);
         /* Reset counter */
         p_barrier->counter = 0;
-
         ABTI_spinlock_release(&p_barrier->lock);
     }
     return ABT_SUCCESS;
diff --git a/src/cond.c b/src/cond.c
index 3cee63b..30ad62f 100644
--- a/src/cond.c
+++ b/src/cond.c
@@ -7,7 +7,6 @@
 #include <sys/time.h>
 
 static inline double convert_timespec_to_sec(const struct timespec *p_ts);
-static inline void remove_thread(ABTI_cond *p_cond, ABTI_thread *p_thread);
 
 /** @defgroup COND Condition Variable
  * This group is for Condition Variable.
@@ -55,7 +54,7 @@ int ABT_cond_free(ABT_cond *cond)
     ABT_cond h_cond = *cond;
     ABTI_cond *p_cond = ABTI_cond_get_ptr(h_cond);
     ABTI_CHECK_NULL_COND_PTR(p_cond);
-    ABTI_CHECK_TRUE(p_cond->num_waiters == 0, ABT_ERR_COND);
+    ABTI_CHECK_TRUE(!ABTI_waitlist_is_empty(&p_cond->waitlist), ABT_ERR_COND);
 
     ABTI_cond_fini(p_cond);
     ABTU_free(p_cond);
@@ -142,51 +141,17 @@ int ABT_cond_timedwait(ABT_cond cond, ABT_mutex mutex,
         }
     }
 
-    if (p_cond->num_waiters == 0) {
-        thread.p_prev = &thread;
-        thread.p_next = &thread;
-        p_cond->p_head = &thread;
-        p_cond->p_tail = &thread;
-    } else {
-        p_cond->p_tail->p_next = &thread;
-        p_cond->p_head->p_prev = &thread;
-        thread.p_prev = p_cond->p_tail;
-        thread.p_next = p_cond->p_head;
-        p_cond->p_tail = &thread;
-    }
-
-    p_cond->num_waiters++;
-
-    ABTI_spinlock_release(&p_cond->lock);
-
     /* Unlock the mutex that the calling ULT is holding */
     ABTI_mutex_unlock(p_local, p_mutex);
-
-    ABTI_xstream *p_local_xstream = ABTI_local_get_xstream_or_null(p_local);
-    ABTI_ythread *p_ythread = NULL;
-    if (!ABTI_IS_EXT_THREAD_ENABLED || p_local_xstream) {
-        p_ythread = ABTI_thread_get_ythread_or_null(p_local_xstream->p_thread);
-    }
-    while (ABTD_atomic_acquire_load_int(&thread.state) !=
-           ABT_THREAD_STATE_READY) {
-        double cur_time = ABTI_get_wtime();
-        if (cur_time >= tar_time) {
-            remove_thread(p_cond, &thread);
-            /* Lock the mutex again */
-            ABTI_mutex_lock(&p_local, p_mutex);
-            return ABT_ERR_COND_TIMEDOUT;
-        }
-        if (p_ythread) {
-            ABTI_ythread_yield(&p_local_xstream, p_ythread,
-                               ABT_SYNC_EVENT_TYPE_COND, (void *)p_cond);
-            p_local = ABTI_xstream_get_local(p_local_xstream);
-        } else {
-            ABTD_atomic_pause();
-        }
-    }
+    ABT_bool is_timedout =
+        ABTI_waitlist_wait_timedout_and_unlock(&p_local, &p_cond->waitlist,
+                                               &p_cond->lock, ABT_FALSE,
+                                               tar_time,
+                                               ABT_SYNC_EVENT_TYPE_COND,
+                                               (void *)p_cond);
     /* Lock the mutex again */
     ABTI_mutex_lock(&p_local, p_mutex);
-    return ABT_SUCCESS;
+    return is_timedout ? ABT_ERR_COND_TIMEDOUT : ABT_SUCCESS;
 }
 
 /**
@@ -210,37 +175,9 @@ int ABT_cond_signal(ABT_cond cond)
     ABTI_CHECK_NULL_COND_PTR(p_cond);
 
     ABTI_spinlock_acquire(&p_cond->lock);
-
-    if (p_cond->num_waiters == 0) {
-        ABTI_spinlock_release(&p_cond->lock);
-        return ABT_SUCCESS;
-    }
-
-    /* Wake up the first waiting ULT */
-    ABTI_thread *p_thread = p_cond->p_head;
-
-    p_cond->num_waiters--;
-    if (p_cond->num_waiters == 0) {
-        p_cond->p_waiter_mutex = NULL;
-        p_cond->p_head = NULL;
-        p_cond->p_tail = NULL;
-    } else {
-        p_thread->p_prev->p_next = p_thread->p_next;
-        p_thread->p_next->p_prev = p_thread->p_prev;
-        p_cond->p_head = p_thread->p_next;
-    }
-    p_thread->p_prev = NULL;
-    p_thread->p_next = NULL;
-
-    ABTI_ythread *p_ythread = ABTI_thread_get_ythread_or_null(p_thread);
-    if (p_ythread) {
-        ABTI_ythread_set_ready(p_local, p_ythread);
-    } else {
-        /* When the head is an external thread */
-        ABTD_atomic_release_store_int(&p_thread->state, ABT_THREAD_STATE_READY);
-    }
-
+    ABTI_waitlist_signal(p_local, &p_cond->waitlist);
     ABTI_spinlock_release(&p_cond->lock);
+
     return ABT_SUCCESS;
 }
 
@@ -277,37 +214,3 @@ static inline double convert_timespec_to_sec(const struct timespec *p_ts)
     secs = ((double)p_ts->tv_sec) + 1.0e-9 * ((double)p_ts->tv_nsec);
     return secs;
 }
-
-static inline void remove_thread(ABTI_cond *p_cond, ABTI_thread *p_thread)
-{
-    if (p_thread->p_next == NULL)
-        return;
-
-    ABTI_spinlock_acquire(&p_cond->lock);
-
-    if (p_thread->p_next == NULL) {
-        ABTI_spinlock_release(&p_cond->lock);
-        return;
-    }
-
-    /* If p_thread is still in the queue, we have to remove it. */
-    p_cond->num_waiters--;
-    if (p_cond->num_waiters == 0) {
-        p_cond->p_waiter_mutex = NULL;
-        p_cond->p_head = NULL;
-        p_cond->p_tail = NULL;
-    } else {
-        p_thread->p_prev->p_next = p_thread->p_next;
-        p_thread->p_next->p_prev = p_thread->p_prev;
-        if (p_thread == p_cond->p_head) {
-            p_cond->p_head = p_thread->p_next;
-        } else if (p_thread == p_cond->p_tail) {
-            p_cond->p_tail = p_thread->p_prev;
-        }
-    }
-
-    ABTI_spinlock_release(&p_cond->lock);
-
-    p_thread->p_prev = NULL;
-    p_thread->p_next = NULL;
-}
diff --git a/src/eventual.c b/src/eventual.c
index f5911e1..2c92a47 100644
--- a/src/eventual.c
+++ b/src/eventual.c
@@ -50,8 +50,7 @@ int ABT_eventual_create(int nbytes, ABT_eventual *neweventual)
             ABTI_HANDLE_ERROR(abt_errno);
         }
     }
-    p_eventual->p_head = NULL;
-    p_eventual->p_tail = NULL;
+    ABTI_waitlist_init(&p_eventual->waitlist);
 
     *neweventual = ABTI_eventual_get_handle(p_eventual);
     return ABT_SUCCESS;
@@ -112,59 +111,16 @@ int ABT_eventual_wait(ABT_eventual eventual, void **value)
 
     ABTI_spinlock_acquire(&p_eventual->lock);
     if (p_eventual->ready == ABT_FALSE) {
-        ABTI_ythread *p_ythread = NULL;
-        ABTI_thread *p_thread;
-
-        ABTI_xstream *p_local_xstream = ABTI_local_get_xstream_or_null(p_local);
-        if (!ABTI_IS_EXT_THREAD_ENABLED || p_local_xstream) {
-            p_thread = p_local_xstream->p_thread;
-            p_ythread = ABTI_thread_get_ythread_or_null(p_thread);
-        }
-        if (!p_ythread) {
-            /* external thread or non-yieldable thread */
-            int abt_errno =
-                ABTU_calloc(1, sizeof(ABTI_thread), (void **)&p_thread);
-            if (ABTI_IS_ERROR_CHECK_ENABLED && abt_errno != ABT_SUCCESS) {
-                ABTI_spinlock_release(&p_eventual->lock);
-                ABTI_HANDLE_ERROR(abt_errno);
-            }
-            p_thread->type = ABTI_THREAD_TYPE_EXT;
-            /* use state for synchronization */
-            ABTD_atomic_relaxed_store_int(&p_thread->state,
-                                          ABT_THREAD_STATE_BLOCKED);
-        }
-
-        p_thread->p_next = NULL;
-        if (p_eventual->p_head == NULL) {
-            p_eventual->p_head = p_thread;
-            p_eventual->p_tail = p_thread;
-        } else {
-            p_eventual->p_tail->p_next = p_thread;
-            p_eventual->p_tail = p_thread;
-        }
-
-        if (p_ythread) {
-            ABTI_ythread_set_blocked(p_ythread);
-
-            ABTI_spinlock_release(&p_eventual->lock);
-
-            /* Suspend the current ULT */
-            ABTI_ythread_suspend(&p_local_xstream, p_ythread,
-                                 ABT_SYNC_EVENT_TYPE_EVENTUAL,
-                                 (void *)p_eventual);
-        } else {
-            ABTI_spinlock_release(&p_eventual->lock);
-
-            /* External thread is waiting here. */
-            while (ABTD_atomic_acquire_load_int(&p_thread->state) !=
-                   ABT_THREAD_STATE_READY)
-                ;
-            if (p_thread->type == ABTI_THREAD_TYPE_EXT)
-                ABTU_free(p_thread);
-        }
+        ABTI_waitlist_wait_and_unlock(&p_local, &p_eventual->waitlist,
+                                      &p_eventual->lock, ABT_FALSE,
+                                      ABT_SYNC_EVENT_TYPE_EVENTUAL,
+                                      (void *)p_eventual);
     } else {
         ABTI_spinlock_release(&p_eventual->lock);
     }
+    /* This value is updated outside the critical section, but it is okay since
+     * the "pointer" to the memory buffer is constant and there is no way to
+     * avoid updating this memory buffer by ABT_eventual_set() etc. */
     if (value)
         *value = p_eventual->value;
     return ABT_SUCCESS;
@@ -233,38 +189,8 @@ int ABT_eventual_set(ABT_eventual eventual, void *value, int nbytes)
     p_eventual->ready = ABT_TRUE;
     if (p_eventual->value)
         memcpy(p_eventual->value, value, arg_nbytes);
-
-    if (p_eventual->p_head == NULL) {
-        ABTI_spinlock_release(&p_eventual->lock);
-        return ABT_SUCCESS;
-    }
-
     /* Wake up all waiting ULTs */
-    ABTI_thread *p_head = p_eventual->p_head;
-    ABTI_thread *p_thread = p_head;
-    while (1) {
-        ABTI_thread *p_next = p_thread->p_next;
-        p_thread->p_next = NULL;
-
-        ABTI_ythread *p_ythread = ABTI_thread_get_ythread_or_null(p_thread);
-        if (p_ythread) {
-            ABTI_ythread_set_ready(p_local, p_ythread);
-        } else {
-            /* When the head is an external thread */
-            ABTD_atomic_release_store_int(&p_thread->state,
-                                          ABT_THREAD_STATE_READY);
-        }
-
-        /* Next ULT */
-        if (p_next != NULL) {
-            p_thread = p_next;
-        } else {
-            break;
-        }
-    }
-
-    p_eventual->p_head = NULL;
-    p_eventual->p_tail = NULL;
+    ABTI_waitlist_broadcast(p_local, &p_eventual->waitlist);
 
     ABTI_spinlock_release(&p_eventual->lock);
     return ABT_SUCCESS;
diff --git a/src/futures.c b/src/futures.c
index 5419ff4..bebe657 100644
--- a/src/futures.c
+++ b/src/futures.c
@@ -72,8 +72,7 @@ int ABT_future_create(uint32_t compartments, void (*cb_func)(void **arg),
         ABTI_HANDLE_ERROR(abt_errno);
     }
     p_future->p_callback = cb_func;
-    p_future->p_head = NULL;
-    p_future->p_tail = NULL;
+    ABTI_waitlist_init(&p_future->waitlist);
 
     *newfuture = ABTI_future_get_handle(p_future);
     return ABT_SUCCESS;
@@ -132,55 +131,10 @@ int ABT_future_wait(ABT_future future)
     ABTI_spinlock_acquire(&p_future->lock);
     if (ABTD_atomic_relaxed_load_size(&p_future->counter) <
         p_future->compartments) {
-        ABTI_ythread *p_ythread = NULL;
-        ABTI_thread *p_thread;
-
-        ABTI_xstream *p_local_xstream = ABTI_local_get_xstream_or_null(p_local);
-        if (!ABTI_IS_EXT_THREAD_ENABLED || p_local_xstream) {
-            p_thread = p_local_xstream->p_thread;
-            p_ythread = ABTI_thread_get_ythread_or_null(p_thread);
-        }
-        if (!p_ythread) {
-            /* external thread */
-            int abt_errno =
-                ABTU_calloc(1, sizeof(ABTI_thread), (void **)&p_thread);
-            if (ABTI_IS_ERROR_CHECK_ENABLED && abt_errno != ABT_SUCCESS) {
-                ABTI_spinlock_release(&p_future->lock);
-                ABTI_HANDLE_ERROR(abt_errno);
-            }
-            p_thread->type = ABTI_THREAD_TYPE_EXT;
-            /* use state for synchronization */
-            ABTD_atomic_relaxed_store_int(&p_thread->state,
-                                          ABT_THREAD_STATE_BLOCKED);
-        }
-
-        p_thread->p_next = NULL;
-        if (p_future->p_head == NULL) {
-            p_future->p_head = p_thread;
-            p_future->p_tail = p_thread;
-        } else {
-            p_future->p_tail->p_next = p_thread;
-            p_future->p_tail = p_thread;
-        }
-
-        if (p_ythread) {
-            ABTI_ythread_set_blocked(p_ythread);
-
-            ABTI_spinlock_release(&p_future->lock);
-
-            /* Suspend the current ULT */
-            ABTI_ythread_suspend(&p_local_xstream, p_ythread,
-                                 ABT_SYNC_EVENT_TYPE_FUTURE, (void *)p_future);
-
-        } else {
-            ABTI_spinlock_release(&p_future->lock);
-
-            /* External thread is waiting here. */
-            while (ABTD_atomic_acquire_load_int(&p_thread->state) !=
-                   ABT_THREAD_STATE_READY)
-                ;
-            ABTU_free(p_thread);
-        }
+        ABTI_waitlist_wait_and_unlock(&p_local, &p_future->waitlist,
+                                      &p_future->lock, ABT_FALSE,
+                                      ABT_SYNC_EVENT_TYPE_FUTURE,
+                                      (void *)p_future);
     } else {
         ABTI_spinlock_release(&p_future->lock);
     }
@@ -248,37 +202,7 @@ int ABT_future_set(ABT_future future, void *value)
     if (counter == p_future->compartments) {
         if (p_future->p_callback != NULL)
             (*p_future->p_callback)(p_future->array);
-
-        if (p_future->p_head == NULL) {
-            ABTI_spinlock_release(&p_future->lock);
-            return ABT_SUCCESS;
-        }
-
-        /* Wake up all waiting ULTs */
-        ABTI_thread *p_head = p_future->p_head;
-        ABTI_thread *p_thread = p_head;
-        while (1) {
-            ABTI_thread *p_next = p_thread->p_next;
-            p_thread->p_next = NULL;
-
-            ABTI_ythread *p_ythread = ABTI_thread_get_ythread_or_null(p_thread);
-            if (p_ythread) {
-                ABTI_ythread_set_ready(p_local, p_ythread);
-            } else {
-                /* When the head is an external thread */
-                ABTD_atomic_release_store_int(&p_thread->state,
-                                              ABT_THREAD_STATE_READY);
-            }
-
-            /* Next ULT */
-            if (p_next != NULL) {
-                p_thread = p_next;
-            } else {
-                break;
-            }
-        }
-        p_future->p_head = NULL;
-        p_future->p_tail = NULL;
+        ABTI_waitlist_broadcast(p_local, &p_future->waitlist);
     }
 
     ABTI_spinlock_release(&p_future->lock);
diff --git a/src/include/abti.h b/src/include/abti.h
index bbb9c7c..e203f97 100644
--- a/src/include/abti.h
+++ b/src/include/abti.h
@@ -381,9 +381,7 @@ struct ABTI_ktable {
 struct ABTI_cond {
     ABTI_spinlock lock;
     ABTI_mutex *p_waiter_mutex;
-    size_t num_waiters;
-    ABTI_thread *p_head; /* Head of waiters */
-    ABTI_thread *p_tail; /* Tail of waiters */
+    ABTI_waitlist waitlist;
 };
 
 struct ABTI_rwlock {
@@ -398,8 +396,7 @@ struct ABTI_eventual {
     ABT_bool ready;
     void *value;
     size_t nbytes;
-    ABTI_thread *p_head; /* Head of waiters */
-    ABTI_thread *p_tail; /* Tail of waiters */
+    ABTI_waitlist waitlist;
 };
 
 struct ABTI_future {
@@ -408,16 +405,14 @@ struct ABTI_future {
     size_t compartments;
     void **array;
     void (*p_callback)(void **arg);
-    ABTI_thread *p_head; /* Head of waiters */
-    ABTI_thread *p_tail; /* Tail of waiters */
+    ABTI_waitlist waitlist;
 };
 
 struct ABTI_barrier {
     size_t num_waiters;
     volatile size_t counter;
-    ABTI_ythread **waiters;
-    ABT_unit_type *waiter_type;
     ABTI_spinlock lock;
+    ABTI_waitlist waitlist;
 };
 
 struct ABTI_xstream_barrier {
diff --git a/src/include/abti_cond.h b/src/include/abti_cond.h
index c34b8fa..eb966ae 100644
--- a/src/include/abti_cond.h
+++ b/src/include/abti_cond.h
@@ -14,9 +14,7 @@ static inline void ABTI_cond_init(ABTI_cond *p_cond)
 {
     ABTI_spinlock_clear(&p_cond->lock);
     p_cond->p_waiter_mutex = NULL;
-    p_cond->num_waiters = 0;
-    p_cond->p_head = NULL;
-    p_cond->p_tail = NULL;
+    ABTI_waitlist_init(&p_cond->waitlist);
 }
 
 static inline void ABTI_cond_fini(ABTI_cond *p_cond)
@@ -60,24 +58,6 @@ static inline ABT_cond ABTI_cond_get_handle(ABTI_cond *p_cond)
 ABTU_ret_err static inline int
 ABTI_cond_wait(ABTI_local **pp_local, ABTI_cond *p_cond, ABTI_mutex *p_mutex)
 {
-    ABTI_ythread *p_ythread = NULL;
-    ABTI_thread *p_thread;
-
-    ABTI_xstream *p_local_xstream = ABTI_local_get_xstream_or_null(*pp_local);
-    if (!ABTI_IS_EXT_THREAD_ENABLED || p_local_xstream) {
-        p_thread = p_local_xstream->p_thread;
-        p_ythread = ABTI_thread_get_ythread_or_null(p_thread);
-    }
-    if (!p_ythread) {
-        /* external thread or non-yieldable thread */
-        int abt_errno = ABTU_calloc(1, sizeof(ABTI_thread), (void **)&p_thread);
-        ABTI_CHECK_ERROR(abt_errno);
-        p_thread->type = ABTI_THREAD_TYPE_EXT;
-        /* use state for synchronization */
-        ABTD_atomic_relaxed_store_int(&p_thread->state,
-                                      ABT_THREAD_STATE_BLOCKED);
-    }
-
     ABTI_spinlock_acquire(&p_cond->lock);
 
     if (p_cond->p_waiter_mutex == NULL) {
@@ -85,52 +65,14 @@ ABTI_cond_wait(ABTI_local **pp_local, ABTI_cond *p_cond, ABTI_mutex *p_mutex)
     } else {
         if (p_cond->p_waiter_mutex != p_mutex) {
             ABTI_spinlock_release(&p_cond->lock);
-            if (!p_ythread)
-                ABTU_free(p_thread);
             return ABT_ERR_INV_MUTEX;
         }
     }
 
-    if (p_cond->num_waiters == 0) {
-        p_thread->p_prev = p_thread;
-        p_thread->p_next = p_thread;
-        p_cond->p_head = p_thread;
-        p_cond->p_tail = p_thread;
-    } else {
-        p_cond->p_tail->p_next = p_thread;
-        p_cond->p_head->p_prev = p_thread;
-        p_thread->p_prev = p_cond->p_tail;
-        p_thread->p_next = p_cond->p_head;
-        p_cond->p_tail = p_thread;
-    }
-
-    p_cond->num_waiters++;
-
-    if (p_ythread) {
-        /* Change the ULT's state to BLOCKED */
-        ABTI_ythread_set_blocked(p_ythread);
-
-        ABTI_spinlock_release(&p_cond->lock);
-
-        /* Unlock the mutex that the calling ULT is holding */
-        /* FIXME: should check if mutex was locked by the calling ULT */
-        ABTI_mutex_unlock(ABTI_xstream_get_local(p_local_xstream), p_mutex);
-
-        /* Suspend the current ULT */
-        ABTI_ythread_suspend(&p_local_xstream, p_ythread,
-                             ABT_SYNC_EVENT_TYPE_COND, (void *)p_cond);
-        *pp_local = ABTI_xstream_get_local(p_local_xstream);
-    } else {
-        ABTI_spinlock_release(&p_cond->lock);
-        ABTI_mutex_unlock(ABTI_xstream_get_local(p_local_xstream), p_mutex);
-
-        /* External thread is waiting here. */
-        while (ABTD_atomic_acquire_load_int(&p_thread->state) !=
-               ABT_THREAD_STATE_READY)
-            ;
-        ABTU_free(p_thread);
-    }
-
+    ABTI_mutex_unlock(*pp_local, p_mutex);
+    ABTI_waitlist_wait_and_unlock(pp_local, &p_cond->waitlist, &p_cond->lock,
+                                  ABT_FALSE, ABT_SYNC_EVENT_TYPE_COND,
+                                  (void *)p_cond);
     /* Lock the mutex again */
     ABTI_mutex_lock(pp_local, p_mutex);
     return ABT_SUCCESS;
@@ -139,43 +81,8 @@ ABTI_cond_wait(ABTI_local **pp_local, ABTI_cond *p_cond, ABTI_mutex *p_mutex)
 static inline void ABTI_cond_broadcast(ABTI_local *p_local, ABTI_cond *p_cond)
 {
     ABTI_spinlock_acquire(&p_cond->lock);
-
-    if (p_cond->num_waiters == 0) {
-        ABTI_spinlock_release(&p_cond->lock);
-        return;
-    }
-
     /* Wake up all waiting ULTs */
-    ABTI_thread *p_head = p_cond->p_head;
-    ABTI_thread *p_thread = p_head;
-    while (1) {
-        ABTI_thread *p_next = p_thread->p_next;
-
-        p_thread->p_prev = NULL;
-        p_thread->p_next = NULL;
-
-        ABTI_ythread *p_ythread = ABTI_thread_get_ythread_or_null(p_thread);
-        if (p_ythread) {
-            ABTI_ythread_set_ready(p_local, p_ythread);
-        } else {
-            /* When the head is an external thread */
-            ABTD_atomic_release_store_int(&p_thread->state,
-                                          ABT_THREAD_STATE_READY);
-        }
-
-        /* Next ULT */
-        if (p_next != p_head) {
-            p_thread = p_next;
-        } else {
-            break;
-        }
-    }
-
-    p_cond->p_waiter_mutex = NULL;
-    p_cond->num_waiters = 0;
-    p_cond->p_head = NULL;
-    p_cond->p_tail = NULL;
-
+    ABTI_waitlist_broadcast(p_local, &p_cond->waitlist);
     ABTI_spinlock_release(&p_cond->lock);
 }
 
-- 
2.21.0 (Apple Git-122.2)


From e7444e0048f687e665cd3d84b738e3cc084d2a05 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Tue, 1 Dec 2020 19:00:46 -0600
Subject: [PATCH 23/40] mutex: remove complicated hash table-based mutex
 algorithm

The mutex logic that uses ABTI_thread_htable is broken and hard to fix.  This
patch removes this implementation.  Note that this algorithm is disabled by
default (which can be turned on by passing --disable-simple-mutex).
---
 src/Makefile.am                   |   3 +-
 src/include/Makefile.mk           |   1 -
 src/include/abti.h                |  43 +---
 src/include/abti_mutex.h          |  71 +------
 src/include/abti_ythread_htable.h | 177 -----------------
 src/mutex.c                       | 318 ------------------------------
 src/mutex_attr.c                  |   2 -
 src/rwlock.c                      |   1 -
 src/ythread_htable.c              | 218 --------------------
 9 files changed, 12 insertions(+), 822 deletions(-)
 delete mode 100644 src/include/abti_ythread_htable.h
 delete mode 100644 src/ythread_htable.c

diff --git a/src/Makefile.am b/src/Makefile.am
index 09811d5..5420587 100644
--- a/src/Makefile.am
+++ b/src/Makefile.am
@@ -26,8 +26,7 @@ abt_sources = \
 	timer.c \
 	tool.c \
 	unit.c \
-	ythread.c \
-	ythread_htable.c
+	ythread.c
 
 include $(top_srcdir)/src/arch/Makefile.mk
 include $(top_srcdir)/src/mem/Makefile.mk
diff --git a/src/include/Makefile.mk b/src/include/Makefile.mk
index adcb28e..382a888 100644
--- a/src/include/Makefile.mk
+++ b/src/include/Makefile.mk
@@ -42,5 +42,4 @@ noinst_HEADERS = \
 	include/abti_tool.h \
 	include/abti_valgrind.h \
 	include/abti_ythread.h \
-	include/abti_ythread_htable.h \
 	include/abtu.h
diff --git a/src/include/abti.h b/src/include/abti.h
index e203f97..c4b2fea 100644
--- a/src/include/abti.h
+++ b/src/include/abti.h
@@ -113,8 +113,6 @@ typedef struct ABTI_thread_attr ABTI_thread_attr;
 typedef struct ABTI_ythread ABTI_ythread;
 typedef struct ABTI_thread_mig_data ABTI_thread_mig_data;
 typedef uint32_t ABTI_thread_type;
-typedef struct ABTI_ythread_htable ABTI_ythread_htable;
-typedef struct ABTI_ythread_queue ABTI_ythread_queue;
 typedef struct ABTI_key ABTI_key;
 typedef struct ABTI_ktelem ABTI_ktelem;
 typedef struct ABTI_ktable ABTI_ktable;
@@ -160,16 +158,11 @@ struct ABTI_mutex_attr {
     uint32_t attrs;          /* bit-or'ed attributes */
     uint32_t nesting_cnt;    /* nesting count */
     ABTI_thread_id owner_id; /* owner's ID */
-    uint32_t max_handovers;  /* max. # of handovers */
-    uint32_t max_wakeups;    /* max. # of wakeups */
 };
 
 struct ABTI_mutex {
-    ABTD_atomic_uint32 val;        /* 0: unlocked, 1: locked */
-    ABTI_mutex_attr attr;          /* attributes */
-    ABTI_ythread_htable *p_htable; /* a set of queues */
-    ABTI_ythread *p_handover;      /* next ULT for the mutex handover */
-    ABTI_ythread *p_giver;         /* current ULT that hands over the mutex */
+    ABTD_atomic_uint32 val; /* 0: unlocked, 1: locked */
+    ABTI_mutex_attr attr;   /* attributes */
 };
 
 struct ABTI_global {
@@ -191,9 +184,10 @@ struct ABTI_global {
     uint64_t sched_sleep_nsec;    /* Default nanoseconds for scheduler sleep */
     ABTI_ythread *p_main_ythread; /* ULT of the main function */
 
-    uint32_t mutex_max_handovers; /* Default max. # of local handovers */
-    uint32_t mutex_max_wakeups;   /* Default max. # of wakeups */
-    size_t huge_page_size;        /* Huge page size */
+    uint32_t
+        mutex_max_handovers;    /* Default max. # of local handovers (unused) */
+    uint32_t mutex_max_wakeups; /* Default max. # of wakeups (unused) */
+    size_t huge_page_size;      /* Huge page size */
 #ifdef ABT_CONFIG_USE_MEM_POOL
     size_t mem_page_size;    /* Page size for memory allocation */
     size_t mem_sp_size;      /* Stack page size */
@@ -546,34 +540,9 @@ ABTU_ret_err int
 ABTI_thread_attr_dup(const ABTI_thread_attr *p_attr,
                      ABTI_thread_attr **pp_dup_attr) ABTU_ret_err;
 
-/* Thread hash table */
-ABTU_ret_err int ABTI_ythread_htable_create(uint32_t num_rows,
-                                            ABTI_ythread_htable **pp_htable);
-void ABTI_ythread_htable_free(ABTI_ythread_htable *p_htable);
-void ABTI_ythread_htable_push(ABTI_ythread_htable *p_htable, int idx,
-                              ABTI_ythread *p_ythread);
-void ABTI_ythread_htable_push_low(ABTI_ythread_htable *p_htable, int idx,
-                                  ABTI_ythread *p_ythread);
-ABTI_ythread *ABTI_ythread_htable_pop(ABTI_ythread_htable *p_htable,
-                                      ABTI_ythread_queue *p_queue);
-ABTI_ythread *ABTI_ythread_htable_pop_low(ABTI_ythread_htable *p_htable,
-                                          ABTI_ythread_queue *p_queue);
-ABT_bool ABTI_ythread_htable_switch_low(ABTI_xstream **pp_local_xstream,
-                                        ABTI_ythread_queue *p_queue,
-                                        ABTI_ythread *p_ythread,
-                                        ABTI_ythread_htable *p_htable,
-                                        ABT_sync_event_type sync_event_type,
-                                        void *p_sync);
 /* Key */
 void ABTI_ktable_free(ABTI_local *p_local, ABTI_ktable *p_ktable);
 
-/* Mutex */
-void ABTI_mutex_wait(ABTI_xstream **pp_local_xstream, ABTI_mutex *p_mutex,
-                     uint32_t val);
-void ABTI_mutex_wait_low(ABTI_xstream **pp_local_xstream, ABTI_mutex *p_mutex,
-                         uint32_t val);
-void ABTI_mutex_wake_de(ABTI_local *p_local, ABTI_mutex *p_mutex);
-
 /* Information */
 void ABTI_info_print_config(FILE *fp);
 void ABTI_info_check_print_all_thread_stacks(void);
diff --git a/src/include/abti_mutex.h b/src/include/abti_mutex.h
index 2998577..a171ca2 100644
--- a/src/include/abti_mutex.h
+++ b/src/include/abti_mutex.h
@@ -40,27 +40,9 @@ ABTU_ret_err static inline int ABTI_mutex_init(ABTI_mutex *p_mutex)
 {
     ABTD_atomic_relaxed_store_uint32(&p_mutex->val, 0);
     p_mutex->attr.attrs = ABTI_MUTEX_ATTR_NONE;
-    p_mutex->attr.max_handovers = gp_ABTI_global->mutex_max_handovers;
-    p_mutex->attr.max_wakeups = gp_ABTI_global->mutex_max_wakeups;
-#ifndef ABT_CONFIG_USE_SIMPLE_MUTEX
-    int abt_errno = ABTI_ythread_htable_create(gp_ABTI_global->max_xstreams,
-                                               &p_mutex->p_htable);
-    ABTI_CHECK_ERROR(abt_errno);
-    p_mutex->p_handover = NULL;
-    p_mutex->p_giver = NULL;
-#endif
     return ABT_SUCCESS;
 }
 
-#ifdef ABT_CONFIG_USE_SIMPLE_MUTEX
-#define ABTI_mutex_fini(p_mutex)
-#else
-static inline void ABTI_mutex_fini(ABTI_mutex *p_mutex)
-{
-    ABTI_ythread_htable_free(p_mutex->p_htable);
-}
-#endif
-
 static inline void ABTI_mutex_spinlock(ABTI_mutex *p_mutex)
 {
     /* ABTI_spinlock_ functions cannot be used since p_mutex->val can take
@@ -72,6 +54,11 @@ static inline void ABTI_mutex_spinlock(ABTI_mutex *p_mutex)
     LOG_DEBUG("%p: spinlock\n", p_mutex);
 }
 
+static inline void ABTI_mutex_fini(ABTI_mutex *p_mutex)
+{
+    ABTI_mutex_spinlock(p_mutex);
+}
+
 static inline void ABTI_mutex_lock(ABTI_local **pp_local, ABTI_mutex *p_mutex)
 {
     ABTI_xstream *p_local_xstream = ABTI_local_get_xstream_or_null(*pp_local);
@@ -85,7 +72,6 @@ static inline void ABTI_mutex_lock(ABTI_local **pp_local, ABTI_mutex *p_mutex)
         ABTI_mutex_spinlock(p_mutex);
         return;
     }
-#ifdef ABT_CONFIG_USE_SIMPLE_MUTEX
     LOG_DEBUG("%p: lock - try\n", p_mutex);
     while (!ABTD_atomic_bool_cas_strong_uint32(&p_mutex->val, 0, 1)) {
         ABTI_ythread_yield(&p_local_xstream, p_ythread,
@@ -93,43 +79,6 @@ static inline void ABTI_mutex_lock(ABTI_local **pp_local, ABTI_mutex *p_mutex)
         *pp_local = ABTI_xstream_get_local(p_local_xstream);
     }
     LOG_DEBUG("%p: lock - acquired\n", p_mutex);
-#else
-    /* Only ULTs can yield when the mutex has been locked. For others,
-     * just call mutex_spinlock. */
-    LOG_DEBUG("%p: lock - try\n", p_mutex);
-    int c;
-    if ((c = ABTD_atomic_val_cas_strong_uint32(&p_mutex->val, 0, 1)) != 0) {
-        if (c != 2) {
-            c = ABTD_atomic_exchange_uint32(&p_mutex->val, 2);
-        }
-        while (c != 0) {
-            ABTI_mutex_wait(&p_local_xstream, p_mutex, 2);
-            *pp_local = ABTI_xstream_get_local(p_local_xstream);
-
-            /* If the mutex has been handed over to the current ULT from
-             * other ULT on the same ES, we don't need to change the mutex
-             * state. */
-            if (p_mutex->p_handover) {
-                if (p_ythread == p_mutex->p_handover) {
-                    p_mutex->p_handover = NULL;
-                    ABTD_atomic_release_store_uint32(&p_mutex->val, 2);
-
-                    /* Push the previous ULT to its pool */
-                    ABTI_ythread *p_giver = p_mutex->p_giver;
-                    ABTD_atomic_release_store_int(&p_giver->thread.state,
-                                                  ABT_THREAD_STATE_READY);
-                    ABTI_pool_push(p_giver->thread.p_pool,
-                                   p_giver->thread.unit);
-                    break;
-                }
-            }
-
-            c = ABTD_atomic_exchange_uint32(&p_mutex->val, 2);
-        }
-    }
-    LOG_DEBUG("%p: lock - acquired\n", p_mutex);
-    return;
-#endif
 }
 
 static inline int ABTI_mutex_trylock(ABTI_mutex *p_mutex)
@@ -142,19 +91,9 @@ static inline int ABTI_mutex_trylock(ABTI_mutex *p_mutex)
 
 static inline void ABTI_mutex_unlock(ABTI_local *p_local, ABTI_mutex *p_mutex)
 {
-#ifdef ABT_CONFIG_USE_SIMPLE_MUTEX
     ABTD_atomic_mem_barrier();
     ABTD_atomic_release_store_uint32(&p_mutex->val, 0);
     LOG_DEBUG("%p: unlock w/o wake\n", p_mutex);
-#else
-    if (ABTD_atomic_fetch_sub_uint32(&p_mutex->val, 1) != 1) {
-        ABTD_atomic_release_store_uint32(&p_mutex->val, 0);
-        LOG_DEBUG("%p: unlock with wake\n", p_mutex);
-        ABTI_mutex_wake_de(p_local, p_mutex);
-    } else {
-        LOG_DEBUG("%p: unlock w/o wake\n", p_mutex);
-    }
-#endif
 }
 
 #endif /* ABTI_MUTEX_H_INCLUDED */
diff --git a/src/include/abti_ythread_htable.h b/src/include/abti_ythread_htable.h
deleted file mode 100644
index 8fe3f84..0000000
--- a/src/include/abti_ythread_htable.h
+++ /dev/null
@@ -1,177 +0,0 @@
-/* -*- Mode: C; c-basic-offset:4 ; indent-tabs-mode:nil ; -*- */
-/*
- * See COPYRIGHT in top-level directory.
- */
-
-#ifndef ABTI_YTHREAD_HTABLE_H_INCLUDED
-#define ABTI_YTHREAD_HTABLE_H_INCLUDED
-
-#include "abt_config.h"
-
-#if defined(HAVE_LH_LOCK_H)
-#include <lh_lock.h>
-#elif defined(HAVE_CLH_H)
-#include <clh.h>
-#else
-#define USE_PTHREAD_MUTEX
-#endif
-
-struct ABTI_ythread_queue {
-    ABTD_atomic_uint32 mutex; /* can be initialized by just assigning 0*/
-    uint32_t num_handovers;
-    uint32_t num_threads;
-    uint32_t pad0;
-    ABTI_ythread *head;
-    ABTI_ythread *tail;
-    char pad1[64 - sizeof(ABTD_atomic_uint32) - sizeof(uint32_t) * 3 -
-              sizeof(ABTI_ythread *) * 2];
-
-    /* low priority queue */
-    ABTD_atomic_uint32 low_mutex; /* can be initialized by just assigning 0*/
-    uint32_t low_num_threads;
-    ABTI_ythread *low_head;
-    ABTI_ythread *low_tail;
-    char pad2[64 - sizeof(ABTD_atomic_uint32) - sizeof(uint32_t) -
-              sizeof(ABTI_ythread *) * 2];
-
-    /* two doubly-linked lists */
-    ABTI_ythread_queue *p_h_next;
-    ABTI_ythread_queue *p_h_prev;
-    ABTI_ythread_queue *p_l_next;
-    ABTI_ythread_queue *p_l_prev;
-    char pad3[64 - sizeof(ABTI_ythread_queue *) * 4];
-};
-
-struct ABTI_ythread_htable {
-#if defined(HAVE_LH_LOCK_H)
-    lh_lock_t mutex;
-#elif defined(HAVE_CLH_H)
-    clh_lock_t mutex;
-#elif defined(USE_PTHREAD_MUTEX)
-    pthread_mutex_t mutex;
-#else
-    ABTI_spinlock mutex; /* To protect table */
-#endif
-    ABTD_atomic_uint32 num_elems;
-    int num_rows;
-    ABTI_ythread_queue *queue;
-
-    ABTI_ythread_queue *h_list; /* list of non-empty high prio. queues */
-    ABTI_ythread_queue *l_list; /* list of non-empty low prio. queues */
-};
-
-#if defined(HAVE_LH_LOCK_H)
-#define ABTI_THREAD_HTABLE_LOCK(m) lh_acquire_lock(&m)
-#define ABTI_THREAD_HTABLE_UNLOCK(m) lh_release_lock(&m)
-#elif defined(HAVE_CLH_H)
-#define ABTI_THREAD_HTABLE_LOCK(m) clh_acquire(&m)
-#define ABTI_THREAD_HTABLE_UNLOCK(m) clh_release(&m)
-#elif defined(USE_PTHREAD_MUTEX)
-#define ABTI_THREAD_HTABLE_LOCK(m) pthread_mutex_lock(&m)
-#define ABTI_THREAD_HTABLE_UNLOCK(m) pthread_mutex_unlock(&m)
-#else
-#define ABTI_THREAD_HTABLE_LOCK(m) ABTI_spinlock_acquire(&m)
-#define ABTI_THREAD_HTABLE_UNLOCK(m) ABTI_spinlock_release(&m)
-#endif
-
-static inline void ABTI_ythread_queue_acquire_mutex(ABTI_ythread_queue *p_queue)
-{
-    while (!ABTD_atomic_bool_cas_weak_uint32(&p_queue->mutex, 0, 1)) {
-        while (ABTD_atomic_acquire_load_uint32(&p_queue->mutex) != 0)
-            ;
-    }
-}
-
-static inline void ABTI_ythread_queue_release_mutex(ABTI_ythread_queue *p_queue)
-{
-    ABTD_atomic_release_store_uint32(&p_queue->mutex, 0);
-}
-
-static inline void
-ABTI_ythread_queue_acquire_low_mutex(ABTI_ythread_queue *p_queue)
-{
-    while (!ABTD_atomic_bool_cas_weak_uint32(&p_queue->low_mutex, 0, 1)) {
-        while (ABTD_atomic_acquire_load_uint32(&p_queue->low_mutex) != 0)
-            ;
-    }
-}
-
-static inline void
-ABTI_ythread_queue_release_low_mutex(ABTI_ythread_queue *p_queue)
-{
-    ABTD_atomic_release_store_uint32(&p_queue->low_mutex, 0);
-}
-
-static inline void ABTI_ythread_htable_add_h_node(ABTI_ythread_htable *p_htable,
-                                                  ABTI_ythread_queue *p_node)
-{
-    ABTI_ythread_queue *p_curr = p_htable->h_list;
-    if (!p_curr) {
-        p_node->p_h_next = p_node;
-        p_node->p_h_prev = p_node;
-        p_htable->h_list = p_node;
-    } else if (!p_node->p_h_next) {
-        p_node->p_h_next = p_curr;
-        p_node->p_h_prev = p_curr->p_h_prev;
-        p_curr->p_h_prev->p_h_next = p_node;
-        p_curr->p_h_prev = p_node;
-    }
-}
-
-static inline void ABTI_ythread_htable_del_h_head(ABTI_ythread_htable *p_htable)
-{
-    ABTI_ythread_queue *p_prev, *p_next;
-    ABTI_ythread_queue *p_node = p_htable->h_list;
-
-    if (p_node == p_node->p_h_next) {
-        p_node->p_h_next = NULL;
-        p_node->p_h_prev = NULL;
-        p_htable->h_list = NULL;
-    } else {
-        p_prev = p_node->p_h_prev;
-        p_next = p_node->p_h_next;
-        p_prev->p_h_next = p_next;
-        p_next->p_h_prev = p_prev;
-        p_node->p_h_next = NULL;
-        p_node->p_h_prev = NULL;
-        p_htable->h_list = p_next;
-    }
-}
-
-static inline void ABTI_ythread_htable_add_l_node(ABTI_ythread_htable *p_htable,
-                                                  ABTI_ythread_queue *p_node)
-{
-    ABTI_ythread_queue *p_curr = p_htable->l_list;
-    if (!p_curr) {
-        p_node->p_l_next = p_node;
-        p_node->p_l_prev = p_node;
-        p_htable->l_list = p_node;
-    } else if (!p_node->p_l_next) {
-        p_node->p_l_next = p_curr;
-        p_node->p_l_prev = p_curr->p_l_prev;
-        p_curr->p_l_prev->p_l_next = p_node;
-        p_curr->p_l_prev = p_node;
-    }
-}
-
-static inline void ABTI_ythread_htable_del_l_head(ABTI_ythread_htable *p_htable)
-{
-    ABTI_ythread_queue *p_prev, *p_next;
-    ABTI_ythread_queue *p_node = p_htable->l_list;
-
-    if (p_node == p_node->p_l_next) {
-        p_node->p_l_next = NULL;
-        p_node->p_l_prev = NULL;
-        p_htable->l_list = NULL;
-    } else {
-        p_prev = p_node->p_l_prev;
-        p_next = p_node->p_l_next;
-        p_prev->p_l_next = p_next;
-        p_next->p_l_prev = p_prev;
-        p_node->p_l_next = NULL;
-        p_node->p_l_prev = NULL;
-        p_htable->l_list = p_next;
-    }
-}
-
-#endif /* ABTI_YTHREAD_HTABLE_H_INCLUDED */
diff --git a/src/mutex.c b/src/mutex.c
index e0528dc..8cb3e0e 100644
--- a/src/mutex.c
+++ b/src/mutex.c
@@ -4,7 +4,6 @@
  */
 
 #include "abti.h"
-#include "abti_ythread_htable.h"
 
 static inline void mutex_lock_low(ABTI_local **pp_local, ABTI_mutex *p_mutex);
 static inline void mutex_unlock_se(ABTI_local **pp_local, ABTI_mutex *p_mutex);
@@ -111,7 +110,6 @@ int ABT_mutex_free(ABT_mutex *mutex)
     ABTI_mutex *p_mutex = ABTI_mutex_get_ptr(h_mutex);
     ABTI_CHECK_NULL_MUTEX_PTR(p_mutex);
 
-    ABTI_mutex_fini(p_mutex);
     ABTU_free(p_mutex);
 
     /* Return value */
@@ -423,151 +421,6 @@ int ABT_mutex_equal(ABT_mutex mutex1, ABT_mutex mutex2, ABT_bool *result)
     return ABT_SUCCESS;
 }
 
-/*****************************************************************************/
-/* Private APIs                                                              */
-/*****************************************************************************/
-
-void ABTI_mutex_wait(ABTI_xstream **pp_local_xstream, ABTI_mutex *p_mutex,
-                     uint32_t val)
-{
-    ABTI_xstream *p_local_xstream = *pp_local_xstream;
-    ABTI_ythread_htable *p_htable = p_mutex->p_htable;
-    ABTI_ythread *p_self = ABTI_thread_get_ythread(p_local_xstream->p_thread);
-
-    int rank = p_local_xstream->rank;
-    ABTI_ASSERT(rank < p_htable->num_rows);
-    ABTI_ythread_queue *p_queue = &p_htable->queue[rank];
-
-    ABTI_THREAD_HTABLE_LOCK(p_htable->mutex);
-
-    if (ABTD_atomic_acquire_load_uint32(&p_mutex->val) != val) {
-        ABTI_THREAD_HTABLE_UNLOCK(p_htable->mutex);
-        return;
-    }
-
-    if (p_queue->p_h_next == NULL) {
-        ABTI_ythread_htable_add_h_node(p_htable, p_queue);
-    }
-
-    /* Change the ULT's state to BLOCKED */
-    ABTI_ythread_set_blocked(p_self);
-
-    /* Push the current ULT to the queue */
-    ABTI_ythread_htable_push(p_htable, rank, p_self);
-
-    /* Unlock */
-    ABTI_THREAD_HTABLE_UNLOCK(p_htable->mutex);
-
-    /* Suspend the current ULT */
-    ABTI_ythread_suspend(pp_local_xstream, p_self, ABT_SYNC_EVENT_TYPE_MUTEX,
-                         (void *)p_mutex);
-}
-
-void ABTI_mutex_wait_low(ABTI_xstream **pp_local_xstream, ABTI_mutex *p_mutex,
-                         uint32_t val)
-{
-    ABTI_xstream *p_local_xstream = *pp_local_xstream;
-    ABTI_ythread_htable *p_htable = p_mutex->p_htable;
-    ABTI_ythread *p_self = ABTI_thread_get_ythread(p_local_xstream->p_thread);
-
-    int rank = p_local_xstream->rank;
-    ABTI_ASSERT(rank < p_htable->num_rows);
-    ABTI_ythread_queue *p_queue = &p_htable->queue[rank];
-
-    ABTI_THREAD_HTABLE_LOCK(p_htable->mutex);
-
-    if (ABTD_atomic_acquire_load_uint32(&p_mutex->val) != val) {
-        ABTI_THREAD_HTABLE_UNLOCK(p_htable->mutex);
-        return;
-    }
-
-    if (p_queue->p_l_next == NULL) {
-        ABTI_ythread_htable_add_l_node(p_htable, p_queue);
-    }
-
-    /* Change the ULT's state to BLOCKED */
-    ABTI_ythread_set_blocked(p_self);
-
-    /* Push the current ULT to the queue */
-    ABTI_ythread_htable_push_low(p_htable, rank, p_self);
-
-    /* Unlock */
-    ABTI_THREAD_HTABLE_UNLOCK(p_htable->mutex);
-
-    /* Suspend the current ULT */
-    ABTI_ythread_suspend(pp_local_xstream, p_self, ABT_SYNC_EVENT_TYPE_MUTEX,
-                         (void *)p_mutex);
-}
-
-void ABTI_mutex_wake_de(ABTI_local *p_local, ABTI_mutex *p_mutex)
-{
-    int n;
-    ABTI_ythread *p_ythread;
-    ABTI_ythread_htable *p_htable = p_mutex->p_htable;
-    int num = p_mutex->attr.max_wakeups;
-    ABTI_ythread_queue *p_start, *p_curr;
-
-    /* Wake up num ULTs in a round-robin manner */
-    for (n = 0; n < num; n++) {
-        p_ythread = NULL;
-
-        ABTI_THREAD_HTABLE_LOCK(p_htable->mutex);
-
-        if (ABTD_atomic_acquire_load_uint32(&p_htable->num_elems) == 0) {
-            ABTI_THREAD_HTABLE_UNLOCK(p_htable->mutex);
-            break;
-        }
-
-        /* Wake up the high-priority ULTs */
-        p_start = p_htable->h_list;
-        for (p_curr = p_start; p_curr;) {
-            p_ythread = ABTI_ythread_htable_pop(p_htable, p_curr);
-            if (p_curr->num_threads == 0) {
-                ABTI_ythread_htable_del_h_head(p_htable);
-            } else {
-                p_htable->h_list = p_curr->p_h_next;
-            }
-            if (p_ythread != NULL)
-                goto done;
-            p_curr = p_htable->h_list;
-            if (p_curr == p_start)
-                break;
-        }
-
-        /* Wake up the low-priority ULTs */
-        p_start = p_htable->l_list;
-        for (p_curr = p_start; p_curr;) {
-            p_ythread = ABTI_ythread_htable_pop_low(p_htable, p_curr);
-            if (p_curr->low_num_threads == 0) {
-                ABTI_ythread_htable_del_l_head(p_htable);
-            } else {
-                p_htable->l_list = p_curr->p_l_next;
-            }
-            if (p_ythread != NULL)
-                goto done;
-            p_curr = p_htable->l_list;
-            if (p_curr == p_start)
-                break;
-        }
-
-        /* Nothing to wake up */
-        ABTI_THREAD_HTABLE_UNLOCK(p_htable->mutex);
-        LOG_DEBUG("%p: nothing to wake up\n", p_mutex);
-        break;
-
-    done:
-        ABTI_THREAD_HTABLE_UNLOCK(p_htable->mutex);
-
-        /* Push p_ythread to the scheduler's pool */
-        LOG_DEBUG("%p: wake up U%" PRIu64 ":E%d\n", p_mutex,
-                  ABTI_thread_get_id(&p_ythread->thread),
-                  p_ythread->thread.p_last_xstream
-                      ? p_ythread->thread.p_last_xstream->rank
-                      : -1);
-        ABTI_ythread_set_ready(p_local, p_ythread);
-    }
-}
-
 /*****************************************************************************/
 /* Internal static functions                                                 */
 /*****************************************************************************/
@@ -579,7 +432,6 @@ static inline void mutex_lock_low(ABTI_local **pp_local, ABTI_mutex *p_mutex)
     if (!ABTI_IS_EXT_THREAD_ENABLED || p_local_xstream) {
         p_ythread = ABTI_thread_get_ythread_or_null(p_local_xstream->p_thread);
     }
-#ifdef ABT_CONFIG_USE_SIMPLE_MUTEX
     if (p_ythread) {
         LOG_DEBUG("%p: lock_low - try\n", p_mutex);
         while (!ABTD_atomic_bool_cas_strong_uint32(&p_mutex->val, 0, 1)) {
@@ -591,67 +443,6 @@ static inline void mutex_lock_low(ABTI_local **pp_local, ABTI_mutex *p_mutex)
     } else {
         ABTI_mutex_spinlock(p_mutex);
     }
-#else
-    /* Only ULTs can yield when the mutex has been locked. For others,
-     * just call mutex_spinlock. */
-    if (p_ythread) {
-        int c;
-        LOG_DEBUG("%p: lock_low - try\n", p_mutex);
-        /* If other ULTs associated with the same ES are waiting on the
-         * low-mutex queue, we give the header ULT a chance to try to get
-         * the mutex by context switching to it. */
-        ABTI_ythread_htable *p_htable = p_mutex->p_htable;
-        ABTI_ythread_queue *p_queue = &p_htable->queue[p_local_xstream->rank];
-        if (p_queue->low_num_threads > 0) {
-            ABT_bool ret =
-                ABTI_ythread_htable_switch_low(&p_local_xstream, p_queue,
-                                               p_ythread, p_htable,
-                                               ABT_SYNC_EVENT_TYPE_MUTEX,
-                                               (void *)p_mutex);
-            *pp_local = ABTI_xstream_get_local(p_local_xstream);
-            if (ret == ABT_TRUE) {
-                /* This ULT became a waiter in the mutex queue */
-                goto check_handover;
-            }
-        }
-
-        if ((c = ABTD_atomic_val_cas_strong_uint32(&p_mutex->val, 0, 1)) != 0) {
-            if (c != 2) {
-                c = ABTD_atomic_exchange_uint32(&p_mutex->val, 2);
-            }
-            while (c != 0) {
-                ABTI_mutex_wait_low(&p_local_xstream, p_mutex, 2);
-                *pp_local = ABTI_xstream_get_local(p_local_xstream);
-
-            check_handover:
-                /* If the mutex has been handed over to the current ULT from
-                 * other ULT on the same ES, we don't need to change the mutex
-                 * state. */
-                if (p_mutex->p_handover) {
-                    if (p_ythread == p_mutex->p_handover) {
-                        p_mutex->p_handover = NULL;
-                        ABTD_atomic_release_store_uint32(&p_mutex->val, 2);
-
-                        /* Push the previous ULT to its pool */
-                        ABTI_ythread *p_giver = p_mutex->p_giver;
-                        ABTD_atomic_release_store_int(&p_giver->thread.state,
-                                                      ABT_THREAD_STATE_READY);
-                        ABTI_pool_push(p_giver->thread.p_pool,
-                                       p_giver->thread.unit);
-                        break;
-                    }
-                }
-
-                c = ABTD_atomic_exchange_uint32(&p_mutex->val, 2);
-            }
-        }
-        LOG_DEBUG("%p: lock_low - acquired\n", p_mutex);
-    } else {
-        ABTI_mutex_spinlock(p_mutex);
-    }
-
-    return;
-#endif
 }
 
 /* Hand over the mutex to other ULT on the same ES */
@@ -662,7 +453,6 @@ static inline void mutex_unlock_se(ABTI_local **pp_local, ABTI_mutex *p_mutex)
     if (!ABTI_IS_EXT_THREAD_ENABLED || p_local_xstream) {
         p_ythread = ABTI_thread_get_ythread_or_null(p_local_xstream->p_thread);
     }
-#ifdef ABT_CONFIG_USE_SIMPLE_MUTEX
     ABTD_atomic_release_store_uint32(&p_mutex->val, 0);
     LOG_DEBUG("%p: unlock_se\n", p_mutex);
     if (p_ythread) {
@@ -670,112 +460,4 @@ static inline void mutex_unlock_se(ABTI_local **pp_local, ABTI_mutex *p_mutex)
                            ABT_SYNC_EVENT_TYPE_MUTEX, (void *)p_mutex);
         *pp_local = ABTI_xstream_get_local(p_local_xstream);
     }
-#else
-    /* If it is run on a non-yieldable thread. just unlock it. */
-    if (!p_ythread) {
-        ABTD_atomic_release_store_uint32(&p_mutex->val, 0); /* Unlock */
-        LOG_DEBUG("%p: unlock_se\n", p_mutex);
-        ABTI_mutex_wake_de(*pp_local, p_mutex);
-        return;
-    }
-
-    /* Unlock the mutex */
-    /* If p_mutex->val is 1 before decreasing it, it means there is no any
-     * waiter in the mutex queue.  We can just return. */
-    if (ABTD_atomic_fetch_sub_uint32(&p_mutex->val, 1) == 1) {
-        LOG_DEBUG("%p: unlock_se\n", p_mutex);
-        if (p_ythread) {
-            ABTI_ythread_yield(&p_local_xstream, p_ythread,
-                               ABT_SYNC_EVENT_TYPE_MUTEX, (void *)p_mutex);
-            *pp_local = ABTI_xstream_get_local(p_local_xstream);
-        }
-        return;
-    }
-
-    /* There are ULTs waiting in the mutex queue */
-    ABTI_ythread_htable *p_htable = p_mutex->p_htable;
-    ABTI_ythread *p_next = NULL;
-    ABTI_ythread_queue *p_queue = &p_htable->queue[(int)p_local_xstream->rank];
-
-check_cond:
-    /* Check whether the mutex handover is possible */
-    if (p_queue->num_handovers >= p_mutex->attr.max_handovers) {
-        ABTD_atomic_release_store_uint32(&p_mutex->val, 0); /* Unlock */
-        LOG_DEBUG("%p: unlock_se\n", p_mutex);
-        ABTI_mutex_wake_de(*pp_local, p_mutex);
-        p_queue->num_handovers = 0;
-        ABTI_ythread_yield(&p_local_xstream, p_ythread,
-                           ABT_SYNC_EVENT_TYPE_MUTEX, (void *)p_mutex);
-        *pp_local = ABTI_xstream_get_local(p_local_xstream);
-        return;
-    }
-
-    /* Hand over the mutex to high-priority ULTs */
-    if (p_queue->num_threads <= 1) {
-        if (p_htable->h_list != NULL) {
-            ABTD_atomic_release_store_uint32(&p_mutex->val, 0); /* Unlock */
-            LOG_DEBUG("%p: unlock_se\n", p_mutex);
-            ABTI_mutex_wake_de(*pp_local, p_mutex);
-            ABTI_ythread_yield(&p_local_xstream, p_ythread,
-                               ABT_SYNC_EVENT_TYPE_MUTEX, (void *)p_mutex);
-            *pp_local = ABTI_xstream_get_local(p_local_xstream);
-            return;
-        }
-    } else {
-        p_next = ABTI_ythread_htable_pop(p_htable, p_queue);
-        if (p_next == NULL)
-            goto check_cond;
-        else
-            goto handover;
-    }
-
-    /* When we don't have high-priority ULTs and other ESs don't either,
-     * we hand over the mutex to low-priority ULTs. */
-    if (p_queue->low_num_threads <= 1) {
-        ABTD_atomic_release_store_uint32(&p_mutex->val, 0); /* Unlock */
-        LOG_DEBUG("%p: unlock_se\n", p_mutex);
-        ABTI_mutex_wake_de(*pp_local, p_mutex);
-        ABTI_ythread_yield(&p_local_xstream, p_ythread,
-                           ABT_SYNC_EVENT_TYPE_MUTEX, (void *)p_mutex);
-        *pp_local = ABTI_xstream_get_local(p_local_xstream);
-        return;
-    } else {
-        p_next = ABTI_ythread_htable_pop_low(p_htable, p_queue);
-        if (p_next == NULL)
-            goto check_cond;
-    }
-
-handover:
-    /* We don't push p_ythread to the pool. Instead, we will yield_to p_ythread
-     * directly at the end of this function. */
-    p_queue->num_handovers++;
-
-    /* We are handing over the mutex */
-    p_mutex->p_handover = p_next;
-    p_mutex->p_giver = p_ythread;
-
-    LOG_DEBUG("%p: handover -> U%" PRIu64 "\n", p_mutex,
-              ABTI_thread_get_id(&p_next->thread));
-
-    /* yield_to the next ULT */
-    while (ABTD_atomic_acquire_load_uint32(&p_next->thread.request) &
-           ABTI_THREAD_REQ_BLOCK)
-        ;
-    ABTI_pool_dec_num_blocked(p_next->thread.p_pool);
-    ABTD_atomic_release_store_int(&p_next->thread.state,
-                                  ABT_THREAD_STATE_RUNNING);
-    ABTI_tool_event_ythread_resume(ABTI_xstream_get_local(p_local_xstream),
-                                   p_next, &p_ythread->thread);
-    /* This works as a "yield" for this thread. */
-    ABTI_tool_event_ythread_yield(p_local_xstream, p_ythread,
-                                  p_ythread->thread.p_parent,
-                                  ABT_SYNC_EVENT_TYPE_MUTEX, (void *)p_mutex);
-    ABTI_ythread *p_prev =
-        ABTI_ythread_context_switch_to_sibling(&p_local_xstream, p_ythread,
-                                               p_next);
-    /* Invoke an event of thread resume and run. */
-    *pp_local = ABTI_xstream_get_local(p_local_xstream);
-    ABTI_tool_event_thread_run(p_local_xstream, &p_ythread->thread,
-                               &p_prev->thread, p_ythread->thread.p_parent);
-#endif
 }
diff --git a/src/mutex_attr.c b/src/mutex_attr.c
index a7c4abf..3793034 100644
--- a/src/mutex_attr.c
+++ b/src/mutex_attr.c
@@ -34,8 +34,6 @@ int ABT_mutex_attr_create(ABT_mutex_attr *newattr)
     p_newattr->attrs = ABTI_MUTEX_ATTR_NONE;
     p_newattr->nesting_cnt = 0;
     p_newattr->owner_id = 0;
-    p_newattr->max_handovers = gp_ABTI_global->mutex_max_handovers;
-    p_newattr->max_wakeups = gp_ABTI_global->mutex_max_wakeups;
 
     /* Return value */
     *newattr = ABTI_mutex_attr_get_handle(p_newattr);
diff --git a/src/rwlock.c b/src/rwlock.c
index 1fab1c1..84f8f52 100644
--- a/src/rwlock.c
+++ b/src/rwlock.c
@@ -65,7 +65,6 @@ int ABT_rwlock_free(ABT_rwlock *rwlock)
     ABTI_rwlock *p_rwlock = ABTI_rwlock_get_ptr(h_rwlock);
     ABTI_CHECK_NULL_RWLOCK_PTR(p_rwlock);
 
-    ABTI_mutex_fini(&p_rwlock->mutex);
     ABTI_cond_fini(&p_rwlock->cond);
     ABTU_free(p_rwlock);
 
diff --git a/src/ythread_htable.c b/src/ythread_htable.c
deleted file mode 100644
index 3678385..0000000
--- a/src/ythread_htable.c
+++ /dev/null
@@ -1,218 +0,0 @@
-/* -*- Mode: C; c-basic-offset:4 ; indent-tabs-mode:nil ; -*- */
-/*
- * See COPYRIGHT in top-level directory.
- */
-
-#include "abti.h"
-#include "abti_ythread_htable.h"
-
-ABTU_ret_err int ABTI_ythread_htable_create(uint32_t num_rows,
-                                            ABTI_ythread_htable **pp_htable)
-{
-    ABTI_STATIC_ASSERT(sizeof(ABTI_ythread_queue) == 192);
-
-    int abt_errno;
-    ABTI_ythread_htable *p_htable;
-    size_t q_size = num_rows * sizeof(ABTI_ythread_queue);
-
-    abt_errno = ABTU_malloc(sizeof(ABTI_ythread_htable), (void **)&p_htable);
-    ABTI_CHECK_ERROR(abt_errno);
-
-    abt_errno = ABTU_memalign(64, q_size, (void **)&p_htable->queue);
-    if (ABTI_IS_ERROR_CHECK_ENABLED && abt_errno != ABT_SUCCESS) {
-        ABTU_free(p_htable);
-        return abt_errno;
-    }
-    memset(p_htable->queue, 0, q_size);
-
-#if defined(HAVE_LH_LOCK_H)
-    lh_lock_init(&p_htable->mutex);
-#elif defined(HAVE_CLH_H)
-    clh_init(&p_htable->mutex);
-#elif defined(USE_PTHREAD_MUTEX)
-    int ret = pthread_mutex_init(&p_htable->mutex, NULL);
-    if (ret) {
-        ABTU_free(p_htable->queue);
-        ABTU_free(p_htable);
-        return ABT_ERR_OTHER;
-    }
-#else
-    ABTI_spinlock_clear(&p_htable->mutex);
-#endif
-    ABTD_atomic_relaxed_store_uint32(&p_htable->num_elems, 0);
-    p_htable->num_rows = num_rows;
-    p_htable->h_list = NULL;
-    p_htable->l_list = NULL;
-    *pp_htable = p_htable;
-    return ABT_SUCCESS;
-}
-
-void ABTI_ythread_htable_free(ABTI_ythread_htable *p_htable)
-{
-    ABTI_ASSERT(ABTD_atomic_relaxed_load_uint32(&p_htable->num_elems) == 0);
-
-#if defined(HAVE_LH_LOCK_H)
-    lh_lock_destroy(&p_htable->mutex);
-#elif defined(HAVE_CLH_H)
-    clh_destroy(&p_htable->mutex);
-#elif defined(USE_PTHREAD_MUTEX)
-    int ret = pthread_mutex_destroy(&p_htable->mutex);
-    assert(!ret);
-#else
-    /* ABTI_spinlock needs no finalization. */
-#endif
-    ABTU_free(p_htable->queue);
-    ABTU_free(p_htable);
-}
-
-void ABTI_ythread_htable_push(ABTI_ythread_htable *p_htable, int idx,
-                              ABTI_ythread *p_ythread)
-{
-    ABTI_ythread_queue *p_queue;
-
-    if (idx >= p_htable->num_rows) {
-        ABTI_ASSERT(0);
-        ABTU_unreachable();
-    }
-
-    /* Add p_ythread to the end of the idx-th row */
-    p_queue = &p_htable->queue[idx];
-    ABTI_ythread_queue_acquire_mutex(p_queue);
-    if (p_queue->head == NULL) {
-        p_queue->head = p_ythread;
-        p_queue->tail = p_ythread;
-    } else {
-        p_queue->tail->thread.p_next = &p_ythread->thread;
-        p_queue->tail = p_ythread;
-    }
-    p_queue->num_threads++;
-    ABTI_ythread_queue_release_mutex(p_queue);
-    ABTD_atomic_fetch_add_uint32(&p_htable->num_elems, 1);
-}
-
-void ABTI_ythread_htable_push_low(ABTI_ythread_htable *p_htable, int idx,
-                                  ABTI_ythread *p_ythread)
-{
-    ABTI_ythread_queue *p_queue;
-
-    if (idx >= p_htable->num_rows) {
-        ABTI_ASSERT(0);
-        ABTU_unreachable();
-    }
-
-    /* Add p_ythread to the end of the idx-th row */
-    p_queue = &p_htable->queue[idx];
-    ABTI_ythread_queue_acquire_low_mutex(p_queue);
-    if (p_queue->low_head == NULL) {
-        p_queue->low_head = p_ythread;
-        p_queue->low_tail = p_ythread;
-    } else {
-        p_queue->low_tail->thread.p_next = &p_ythread->thread;
-        p_queue->low_tail = p_ythread;
-    }
-    p_queue->low_num_threads++;
-    ABTI_ythread_queue_release_low_mutex(p_queue);
-    ABTD_atomic_fetch_add_uint32(&p_htable->num_elems, 1);
-}
-
-ABTI_ythread *ABTI_ythread_htable_pop(ABTI_ythread_htable *p_htable,
-                                      ABTI_ythread_queue *p_queue)
-{
-    ABTI_ythread *p_ythread = NULL;
-
-    ABTI_ythread_queue_acquire_mutex(p_queue);
-    if (p_queue->head) {
-        ABTD_atomic_fetch_sub_uint32(&p_htable->num_elems, 1);
-        p_ythread = p_queue->head;
-        if (p_queue->head == p_queue->tail) {
-            p_queue->head = NULL;
-            p_queue->tail = NULL;
-        } else {
-            p_queue->head = ABTI_thread_get_ythread(p_ythread->thread.p_next);
-        }
-
-        p_queue->num_threads--;
-    }
-    ABTI_ythread_queue_release_mutex(p_queue);
-
-    return p_ythread;
-}
-
-ABTI_ythread *ABTI_ythread_htable_pop_low(ABTI_ythread_htable *p_htable,
-                                          ABTI_ythread_queue *p_queue)
-{
-    ABTI_ythread *p_ythread = NULL;
-
-    ABTI_ythread_queue_acquire_low_mutex(p_queue);
-    if (p_queue->low_head) {
-        ABTD_atomic_fetch_sub_uint32(&p_htable->num_elems, 1);
-        p_ythread = p_queue->low_head;
-        if (p_queue->low_head == p_queue->low_tail) {
-            p_queue->low_head = NULL;
-            p_queue->low_tail = NULL;
-        } else {
-            p_queue->low_head =
-                ABTI_thread_get_ythread(p_ythread->thread.p_next);
-        }
-
-        p_queue->low_num_threads--;
-    }
-    ABTI_ythread_queue_release_low_mutex(p_queue);
-
-    return p_ythread;
-}
-
-ABT_bool ABTI_ythread_htable_switch_low(ABTI_xstream **pp_local_xstream,
-                                        ABTI_ythread_queue *p_queue,
-                                        ABTI_ythread *p_ythread,
-                                        ABTI_ythread_htable *p_htable,
-                                        ABT_sync_event_type sync_event_type,
-                                        void *p_sync)
-{
-    ABTI_ythread *p_target = NULL;
-    ABTI_xstream *p_local_xstream = *pp_local_xstream;
-
-    ABTI_ythread_queue_acquire_low_mutex(p_queue);
-    if (p_queue->low_head) {
-        p_target = p_queue->low_head;
-
-        /* Push p_ythread to the queue */
-        ABTD_atomic_release_store_int(&p_ythread->thread.state,
-                                      ABT_THREAD_STATE_BLOCKED);
-        ABTI_tool_event_ythread_suspend(p_local_xstream, p_ythread,
-                                        p_ythread->thread.p_parent,
-                                        sync_event_type, p_sync);
-        if (p_queue->low_head == p_queue->low_tail) {
-            p_queue->low_head = p_ythread;
-            p_queue->low_tail = p_ythread;
-        } else {
-            p_queue->low_head =
-                ABTI_thread_get_ythread(p_target->thread.p_next);
-            p_queue->low_tail->thread.p_next = &p_ythread->thread;
-            p_queue->low_tail = p_ythread;
-        }
-    }
-    ABTI_ythread_queue_release_low_mutex(p_queue);
-
-    if (p_target) {
-        LOG_DEBUG("switch -> U%" PRIu64 "\n",
-                  ABTI_thread_get_id(&p_target->thread));
-
-        /* Context-switch to p_target */
-        ABTD_atomic_release_store_int(&p_target->thread.state,
-                                      ABT_THREAD_STATE_RUNNING);
-        ABTI_tool_event_ythread_resume(ABTI_xstream_get_local(p_local_xstream),
-                                       p_target,
-                                       p_local_xstream
-                                           ? p_local_xstream->p_thread
-                                           : NULL);
-        ABTI_ythread *p_prev =
-            ABTI_ythread_context_switch_to_sibling(pp_local_xstream, p_ythread,
-                                                   p_target);
-        ABTI_tool_event_thread_run(*pp_local_xstream, &p_ythread->thread,
-                                   &p_prev->thread, p_ythread->thread.p_parent);
-        return ABT_TRUE;
-    } else {
-        return ABT_FALSE;
-    }
-}
-- 
2.21.0 (Apple Git-122.2)


From aa320c629db88a7b918a4fcf76e1400ed94f5a6a Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Tue, 1 Dec 2020 19:01:32 -0600
Subject: [PATCH 24/40] mutex: refactor mutex algorithms

---
 src/cond.c                  |   2 +-
 src/include/abti.h          |   2 +-
 src/include/abti_cond.h     |   2 +-
 src/include/abti_mutex.h    | 136 ++++++++++++++++-------
 src/include/abti_spinlock.h |   6 ++
 src/mutex.c                 | 210 ++++--------------------------------
 src/rwlock.c                |  15 +--
 7 files changed, 131 insertions(+), 242 deletions(-)

diff --git a/src/cond.c b/src/cond.c
index 30ad62f..9d651df 100644
--- a/src/cond.c
+++ b/src/cond.c
@@ -142,7 +142,7 @@ int ABT_cond_timedwait(ABT_cond cond, ABT_mutex mutex,
     }
 
     /* Unlock the mutex that the calling ULT is holding */
-    ABTI_mutex_unlock(p_local, p_mutex);
+    ABTI_mutex_unlock(p_mutex);
     ABT_bool is_timedout =
         ABTI_waitlist_wait_timedout_and_unlock(&p_local, &p_cond->waitlist,
                                                &p_cond->lock, ABT_FALSE,
diff --git a/src/include/abti.h b/src/include/abti.h
index c4b2fea..eae0ec9 100644
--- a/src/include/abti.h
+++ b/src/include/abti.h
@@ -161,7 +161,7 @@ struct ABTI_mutex_attr {
 };
 
 struct ABTI_mutex {
-    ABTD_atomic_uint32 val; /* 0: unlocked, 1: locked */
+    ABTI_spinlock lock;     /* lock */
     ABTI_mutex_attr attr;   /* attributes */
 };
 
diff --git a/src/include/abti_cond.h b/src/include/abti_cond.h
index eb966ae..4e2597e 100644
--- a/src/include/abti_cond.h
+++ b/src/include/abti_cond.h
@@ -69,7 +69,7 @@ ABTI_cond_wait(ABTI_local **pp_local, ABTI_cond *p_cond, ABTI_mutex *p_mutex)
         }
     }
 
-    ABTI_mutex_unlock(*pp_local, p_mutex);
+    ABTI_mutex_unlock(p_mutex);
     ABTI_waitlist_wait_and_unlock(pp_local, &p_cond->waitlist, &p_cond->lock,
                                   ABT_FALSE, ABT_SYNC_EVENT_TYPE_COND,
                                   (void *)p_cond);
diff --git a/src/include/abti_mutex.h b/src/include/abti_mutex.h
index a171ca2..02e1347 100644
--- a/src/include/abti_mutex.h
+++ b/src/include/abti_mutex.h
@@ -36,64 +36,126 @@ static inline ABT_mutex ABTI_mutex_get_handle(ABTI_mutex *p_mutex)
 #endif
 }
 
-ABTU_ret_err static inline int ABTI_mutex_init(ABTI_mutex *p_mutex)
+static inline void ABTI_mutex_init(ABTI_mutex *p_mutex)
 {
-    ABTD_atomic_relaxed_store_uint32(&p_mutex->val, 0);
+    ABTI_spinlock_clear(&p_mutex->lock);
     p_mutex->attr.attrs = ABTI_MUTEX_ATTR_NONE;
-    return ABT_SUCCESS;
+    p_mutex->attr.nesting_cnt = 0;
+    p_mutex->attr.owner_id = 0;
 }
 
-static inline void ABTI_mutex_spinlock(ABTI_mutex *p_mutex)
+static inline void ABTI_mutex_fini(ABTI_mutex *p_mutex)
 {
-    /* ABTI_spinlock_ functions cannot be used since p_mutex->val can take
-     * other values (i.e., not UNLOCKED nor LOCKED.) */
-    while (!ABTD_atomic_bool_cas_weak_uint32(&p_mutex->val, 0, 1)) {
-        while (ABTD_atomic_acquire_load_uint32(&p_mutex->val) != 0)
-            ;
-    }
-    LOG_DEBUG("%p: spinlock\n", p_mutex);
 }
 
-static inline void ABTI_mutex_fini(ABTI_mutex *p_mutex)
+static inline void ABTI_mutex_lock_no_recursion(ABTI_local **pp_local,
+                                                ABTI_mutex *p_mutex)
 {
-    ABTI_mutex_spinlock(p_mutex);
+    ABTI_ythread *p_ythread = NULL;
+    ABTI_xstream *p_local_xstream = ABTI_local_get_xstream_or_null(*pp_local);
+    if (!ABTI_IS_EXT_THREAD_ENABLED || p_local_xstream)
+        p_ythread = ABTI_thread_get_ythread_or_null(p_local_xstream->p_thread);
+
+    if (p_ythread) {
+        while (ABTI_spinlock_try_acquire(&p_mutex->lock)) {
+            ABTI_ythread_yield(&p_local_xstream, p_ythread,
+                               ABT_SYNC_EVENT_TYPE_MUTEX, (void *)p_mutex);
+            *pp_local = ABTI_xstream_get_local(p_local_xstream);
+        }
+    } else {
+        /* Use spinlock. */
+        ABTI_spinlock_acquire(&p_mutex->lock);
+    }
 }
 
 static inline void ABTI_mutex_lock(ABTI_local **pp_local, ABTI_mutex *p_mutex)
 {
-    ABTI_xstream *p_local_xstream = ABTI_local_get_xstream_or_null(*pp_local);
-    if (ABTI_IS_EXT_THREAD_ENABLED && !p_local_xstream) {
-        ABTI_mutex_spinlock(p_mutex);
-        return;
-    }
-    ABTI_ythread *p_ythread =
-        ABTI_thread_get_ythread_or_null(p_local_xstream->p_thread);
-    if (!p_ythread) {
-        ABTI_mutex_spinlock(p_mutex);
-        return;
+    if (p_mutex->attr.attrs & ABTI_MUTEX_ATTR_RECURSIVE) {
+        /* Recursive mutex */
+        ABTI_thread_id self_id = ABTI_self_get_thread_id(*pp_local);
+        if (self_id != p_mutex->attr.owner_id) {
+            ABTI_mutex_lock_no_recursion(pp_local, p_mutex);
+            ABTI_ASSERT(p_mutex->attr.nesting_cnt == 0);
+            p_mutex->attr.owner_id = self_id;
+        } else {
+            /* Increment a nesting count. */
+            p_mutex->attr.nesting_cnt++;
+        }
+    } else {
+        ABTI_mutex_lock_no_recursion(pp_local, p_mutex);
     }
-    LOG_DEBUG("%p: lock - try\n", p_mutex);
-    while (!ABTD_atomic_bool_cas_strong_uint32(&p_mutex->val, 0, 1)) {
-        ABTI_ythread_yield(&p_local_xstream, p_ythread,
-                           ABT_SYNC_EVENT_TYPE_MUTEX, (void *)p_mutex);
-        *pp_local = ABTI_xstream_get_local(p_local_xstream);
+}
+
+static inline int ABTI_mutex_trylock_no_recursion(ABTI_mutex *p_mutex)
+{
+    return ABTI_spinlock_try_acquire(&p_mutex->lock) ? ABT_ERR_MUTEX_LOCKED
+                                                     : ABT_SUCCESS;
+}
+
+static inline int ABTI_mutex_trylock(ABTI_local *p_local, ABTI_mutex *p_mutex)
+{
+    if (p_mutex->attr.attrs & ABTI_MUTEX_ATTR_RECURSIVE) {
+        /* Recursive mutex */
+        ABTI_thread_id self_id = ABTI_self_get_thread_id(p_local);
+        if (self_id != p_mutex->attr.owner_id) {
+            int abt_errno = ABTI_mutex_trylock_no_recursion(p_mutex);
+            if (abt_errno == ABT_SUCCESS) {
+                ABTI_ASSERT(p_mutex->attr.nesting_cnt == 0);
+                p_mutex->attr.owner_id = self_id;
+            }
+            return abt_errno;
+        } else {
+            /* Increment a nesting count. */
+            p_mutex->attr.nesting_cnt++;
+            return ABT_SUCCESS;
+        }
+    } else {
+        return ABTI_mutex_trylock_no_recursion(p_mutex);
     }
-    LOG_DEBUG("%p: lock - acquired\n", p_mutex);
 }
 
-static inline int ABTI_mutex_trylock(ABTI_mutex *p_mutex)
+static inline void ABTI_mutex_spinlock_no_recursion(ABTI_mutex *p_mutex)
+{
+    ABTI_spinlock_acquire(&p_mutex->lock);
+}
+
+static inline void ABTI_mutex_spinlock(ABTI_local *p_local, ABTI_mutex *p_mutex)
 {
-    if (!ABTD_atomic_bool_cas_strong_uint32(&p_mutex->val, 0, 1)) {
-        return ABT_ERR_MUTEX_LOCKED;
+    if (p_mutex->attr.attrs & ABTI_MUTEX_ATTR_RECURSIVE) {
+        /* Recursive mutex */
+        ABTI_thread_id self_id = ABTI_self_get_thread_id(p_local);
+        if (self_id != p_mutex->attr.owner_id) {
+            ABTI_mutex_spinlock_no_recursion(p_mutex);
+            ABTI_ASSERT(p_mutex->attr.nesting_cnt == 0);
+            p_mutex->attr.owner_id = self_id;
+        } else {
+            /* Increment a nesting count. */
+            p_mutex->attr.nesting_cnt++;
+        }
+    } else {
+        ABTI_mutex_spinlock_no_recursion(p_mutex);
     }
-    return ABT_SUCCESS;
 }
 
-static inline void ABTI_mutex_unlock(ABTI_local *p_local, ABTI_mutex *p_mutex)
+static inline void ABTI_mutex_unlock_no_recursion(ABTI_mutex *p_mutex)
+{
+    ABTI_spinlock_release(&p_mutex->lock);
+}
+
+static inline void ABTI_mutex_unlock(ABTI_mutex *p_mutex)
 {
-    ABTD_atomic_mem_barrier();
-    ABTD_atomic_release_store_uint32(&p_mutex->val, 0);
-    LOG_DEBUG("%p: unlock w/o wake\n", p_mutex);
+    if (p_mutex->attr.attrs & ABTI_MUTEX_ATTR_RECURSIVE) {
+        /* recursive mutex */
+        if (p_mutex->attr.nesting_cnt == 0) {
+            p_mutex->attr.owner_id = 0;
+            ABTI_mutex_unlock_no_recursion(p_mutex);
+        } else {
+            p_mutex->attr.nesting_cnt--;
+        }
+    } else {
+        /* unknown attributes */
+        ABTI_mutex_unlock_no_recursion(p_mutex);
+    }
 }
 
 #endif /* ABTI_MUTEX_H_INCLUDED */
diff --git a/src/include/abti_spinlock.h b/src/include/abti_spinlock.h
index ef6f864..a7d59a3 100644
--- a/src/include/abti_spinlock.h
+++ b/src/include/abti_spinlock.h
@@ -33,6 +33,12 @@ static inline void ABTI_spinlock_acquire(ABTI_spinlock *p_lock)
     }
 }
 
+/* Return ABT_FALSE if the lock is acquired. */
+static inline ABT_bool ABTI_spinlock_try_acquire(ABTI_spinlock *p_lock)
+{
+    return ABTD_atomic_test_and_set_bool(&p_lock->val) ? ABT_TRUE : ABT_FALSE;
+}
+
 static inline void ABTI_spinlock_release(ABTI_spinlock *p_lock)
 {
     ABTD_atomic_release_clear_bool(&p_lock->val);
diff --git a/src/mutex.c b/src/mutex.c
index 8cb3e0e..a9fef0b 100644
--- a/src/mutex.c
+++ b/src/mutex.c
@@ -5,9 +5,6 @@
 
 #include "abti.h"
 
-static inline void mutex_lock_low(ABTI_local **pp_local, ABTI_mutex *p_mutex);
-static inline void mutex_unlock_se(ABTI_local **pp_local, ABTI_mutex *p_mutex);
-
 /** @defgroup MUTEX Mutex
  * Mutex is a synchronization method to support mutual exclusion between ULTs.
  * When more than one ULT competes for locking the same mutex, only one ULT is
@@ -36,16 +33,11 @@ static inline void mutex_unlock_se(ABTI_local **pp_local, ABTI_mutex *p_mutex);
  */
 int ABT_mutex_create(ABT_mutex *newmutex)
 {
-    int abt_errno;
     ABTI_mutex *p_newmutex;
 
-    abt_errno = ABTU_calloc(1, sizeof(ABTI_mutex), (void **)&p_newmutex);
+    int abt_errno = ABTU_malloc(sizeof(ABTI_mutex), (void **)&p_newmutex);
     ABTI_CHECK_ERROR(abt_errno);
-    abt_errno = ABTI_mutex_init(p_newmutex);
-    if (ABTI_IS_ERROR_CHECK_ENABLED && abt_errno != ABT_SUCCESS) {
-        ABTU_free(p_newmutex);
-        ABTI_HANDLE_ERROR(abt_errno);
-    }
+    ABTI_mutex_init(p_newmutex);
 
     /* Return value */
     *newmutex = ABTI_mutex_get_handle(p_newmutex);
@@ -70,18 +62,13 @@ int ABT_mutex_create(ABT_mutex *newmutex)
  */
 int ABT_mutex_create_with_attr(ABT_mutex_attr attr, ABT_mutex *newmutex)
 {
-    int abt_errno;
     ABTI_mutex_attr *p_attr = ABTI_mutex_attr_get_ptr(attr);
     ABTI_CHECK_NULL_MUTEX_ATTR_PTR(p_attr);
     ABTI_mutex *p_newmutex;
 
-    abt_errno = ABTU_malloc(sizeof(ABTI_mutex), (void **)&p_newmutex);
+    int abt_errno = ABTU_malloc(sizeof(ABTI_mutex), (void **)&p_newmutex);
     ABTI_CHECK_ERROR(abt_errno);
-    abt_errno = ABTI_mutex_init(p_newmutex);
-    if (ABTI_IS_ERROR_CHECK_ENABLED && abt_errno != ABT_SUCCESS) {
-        ABTU_free(p_newmutex);
-        ABTI_HANDLE_ERROR(abt_errno);
-    }
+    ABTI_mutex_init(p_newmutex);
     memcpy(&p_newmutex->attr, p_attr, sizeof(ABTI_mutex_attr));
 
     /* Return value */
@@ -140,26 +127,7 @@ int ABT_mutex_lock(ABT_mutex mutex)
     ABTI_local *p_local = ABTI_local_get_local();
     ABTI_mutex *p_mutex = ABTI_mutex_get_ptr(mutex);
     ABTI_CHECK_NULL_MUTEX_PTR(p_mutex);
-
-    if (p_mutex->attr.attrs == ABTI_MUTEX_ATTR_NONE) {
-        /* default attributes */
-        ABTI_mutex_lock(&p_local, p_mutex);
-
-    } else if (p_mutex->attr.attrs & ABTI_MUTEX_ATTR_RECURSIVE) {
-        /* recursive mutex */
-        ABTI_thread_id self_id = ABTI_self_get_thread_id(p_local);
-        if (self_id != p_mutex->attr.owner_id) {
-            ABTI_mutex_lock(&p_local, p_mutex);
-            p_mutex->attr.owner_id = self_id;
-            ABTI_ASSERT(p_mutex->attr.nesting_cnt == 0);
-        } else {
-            p_mutex->attr.nesting_cnt++;
-        }
-
-    } else {
-        /* unknown attributes */
-        ABTI_mutex_lock(&p_local, p_mutex);
-    }
+    ABTI_mutex_lock(&p_local, p_mutex);
     return ABT_SUCCESS;
 }
 
@@ -181,32 +149,17 @@ int ABT_mutex_lock_low(ABT_mutex mutex)
     ABTI_local *p_local = ABTI_local_get_local();
     ABTI_mutex *p_mutex = ABTI_mutex_get_ptr(mutex);
     ABTI_CHECK_NULL_MUTEX_PTR(p_mutex);
-
-    if (p_mutex->attr.attrs == ABTI_MUTEX_ATTR_NONE) {
-        /* default attributes */
-        mutex_lock_low(&p_local, p_mutex);
-
-    } else if (p_mutex->attr.attrs & ABTI_MUTEX_ATTR_RECURSIVE) {
-        /* recursive mutex */
-        ABTI_thread_id self_id = ABTI_self_get_thread_id(p_local);
-        if (self_id != p_mutex->attr.owner_id) {
-            mutex_lock_low(&p_local, p_mutex);
-            p_mutex->attr.owner_id = self_id;
-            ABTI_ASSERT(p_mutex->attr.nesting_cnt == 0);
-        } else {
-            p_mutex->attr.nesting_cnt++;
-        }
-
-    } else {
-        /* unknown attributes */
-        mutex_lock_low(&p_local, p_mutex);
-    }
+    ABTI_mutex_lock(&p_local, p_mutex);
     return ABT_SUCCESS;
 }
 
 int ABT_mutex_lock_high(ABT_mutex mutex)
 {
-    return ABT_mutex_lock(mutex);
+    ABTI_local *p_local = ABTI_local_get_local();
+    ABTI_mutex *p_mutex = ABTI_mutex_get_ptr(mutex);
+    ABTI_CHECK_NULL_MUTEX_PTR(p_mutex);
+    ABTI_mutex_lock(&p_local, p_mutex);
+    return ABT_SUCCESS;
 }
 
 /**
@@ -228,33 +181,10 @@ int ABT_mutex_lock_high(ABT_mutex mutex)
  */
 int ABT_mutex_trylock(ABT_mutex mutex)
 {
+    ABTI_local *p_local = ABTI_local_get_local();
     ABTI_mutex *p_mutex = ABTI_mutex_get_ptr(mutex);
     ABTI_CHECK_NULL_MUTEX_PTR(p_mutex);
-
-    int abt_errno;
-    if (p_mutex->attr.attrs == ABTI_MUTEX_ATTR_NONE) {
-        /* default attributes */
-        abt_errno = ABTI_mutex_trylock(p_mutex);
-
-    } else if (p_mutex->attr.attrs & ABTI_MUTEX_ATTR_RECURSIVE) {
-        /* recursive mutex */
-        ABTI_local *p_local = ABTI_local_get_local();
-        ABTI_thread_id self_id = ABTI_self_get_thread_id(p_local);
-        if (self_id != p_mutex->attr.owner_id) {
-            abt_errno = ABTI_mutex_trylock(p_mutex);
-            if (abt_errno == ABT_SUCCESS) {
-                p_mutex->attr.owner_id = self_id;
-                ABTI_ASSERT(p_mutex->attr.nesting_cnt == 0);
-            }
-        } else {
-            p_mutex->attr.nesting_cnt++;
-            abt_errno = ABT_SUCCESS;
-        }
-
-    } else {
-        /* unknown attributes */
-        abt_errno = ABTI_mutex_trylock(p_mutex);
-    }
+    int abt_errno = ABTI_mutex_trylock(p_local, p_mutex);
     /* Trylock always needs to return an error code. */
     return abt_errno;
 }
@@ -275,29 +205,10 @@ int ABT_mutex_trylock(ABT_mutex mutex)
  */
 int ABT_mutex_spinlock(ABT_mutex mutex)
 {
+    ABTI_local *p_local = ABTI_local_get_local();
     ABTI_mutex *p_mutex = ABTI_mutex_get_ptr(mutex);
     ABTI_CHECK_NULL_MUTEX_PTR(p_mutex);
-
-    if (p_mutex->attr.attrs == ABTI_MUTEX_ATTR_NONE) {
-        /* default attributes */
-        ABTI_mutex_spinlock(p_mutex);
-
-    } else if (p_mutex->attr.attrs & ABTI_MUTEX_ATTR_RECURSIVE) {
-        /* recursive mutex */
-        ABTI_local *p_local = ABTI_local_get_local();
-        ABTI_thread_id self_id = ABTI_self_get_thread_id(p_local);
-        if (self_id != p_mutex->attr.owner_id) {
-            ABTI_mutex_spinlock(p_mutex);
-            p_mutex->attr.owner_id = self_id;
-            ABTI_ASSERT(p_mutex->attr.nesting_cnt == 0);
-        } else {
-            p_mutex->attr.nesting_cnt++;
-        }
-
-    } else {
-        /* unknown attributes */
-        ABTI_mutex_spinlock(p_mutex);
-    }
+    ABTI_mutex_spinlock(p_local, p_mutex);
     return ABT_SUCCESS;
 }
 
@@ -315,30 +226,9 @@ int ABT_mutex_spinlock(ABT_mutex mutex)
  */
 int ABT_mutex_unlock(ABT_mutex mutex)
 {
-    ABTI_local *p_local = ABTI_local_get_local();
     ABTI_mutex *p_mutex = ABTI_mutex_get_ptr(mutex);
     ABTI_CHECK_NULL_MUTEX_PTR(p_mutex);
-
-    if (p_mutex->attr.attrs == ABTI_MUTEX_ATTR_NONE) {
-        /* default attributes */
-        ABTI_mutex_unlock(p_local, p_mutex);
-
-    } else if (p_mutex->attr.attrs & ABTI_MUTEX_ATTR_RECURSIVE) {
-        /* recursive mutex */
-        ABTI_CHECK_TRUE(ABTI_self_get_thread_id(p_local) ==
-                            p_mutex->attr.owner_id,
-                        ABT_ERR_INV_THREAD);
-        if (p_mutex->attr.nesting_cnt == 0) {
-            p_mutex->attr.owner_id = 0;
-            ABTI_mutex_unlock(p_local, p_mutex);
-        } else {
-            p_mutex->attr.nesting_cnt--;
-        }
-
-    } else {
-        /* unknown attributes */
-        ABTI_mutex_unlock(p_local, p_mutex);
-    }
+    ABTI_mutex_unlock(p_mutex);
     return ABT_SUCCESS;
 }
 
@@ -361,40 +251,17 @@ int ABT_mutex_unlock(ABT_mutex mutex)
  */
 int ABT_mutex_unlock_se(ABT_mutex mutex)
 {
-    ABTI_local *p_local = ABTI_local_get_local();
     ABTI_mutex *p_mutex = ABTI_mutex_get_ptr(mutex);
     ABTI_CHECK_NULL_MUTEX_PTR(p_mutex);
-
-    if (p_mutex->attr.attrs == ABTI_MUTEX_ATTR_NONE) {
-        /* default attributes */
-        mutex_unlock_se(&p_local, p_mutex);
-
-    } else if (p_mutex->attr.attrs & ABTI_MUTEX_ATTR_RECURSIVE) {
-        /* recursive mutex */
-        ABTI_CHECK_TRUE(ABTI_self_get_thread_id(p_local) ==
-                            p_mutex->attr.owner_id,
-                        ABT_ERR_INV_THREAD);
-        if (p_mutex->attr.nesting_cnt == 0) {
-            p_mutex->attr.owner_id = 0;
-            mutex_unlock_se(&p_local, p_mutex);
-        } else {
-            p_mutex->attr.nesting_cnt--;
-        }
-
-    } else {
-        /* unknown attributes */
-        mutex_unlock_se(&p_local, p_mutex);
-    }
+    ABTI_mutex_unlock(p_mutex);
     return ABT_SUCCESS;
 }
 
 int ABT_mutex_unlock_de(ABT_mutex mutex)
 {
-    ABTI_local *p_local = ABTI_local_get_local();
     ABTI_mutex *p_mutex = ABTI_mutex_get_ptr(mutex);
     ABTI_CHECK_NULL_MUTEX_PTR(p_mutex);
-
-    ABTI_mutex_unlock(p_local, p_mutex);
+    ABTI_mutex_unlock(p_mutex);
     return ABT_SUCCESS;
 }
 
@@ -420,44 +287,3 @@ int ABT_mutex_equal(ABT_mutex mutex1, ABT_mutex mutex2, ABT_bool *result)
     *result = (p_mutex1 == p_mutex2) ? ABT_TRUE : ABT_FALSE;
     return ABT_SUCCESS;
 }
-
-/*****************************************************************************/
-/* Internal static functions                                                 */
-/*****************************************************************************/
-
-static inline void mutex_lock_low(ABTI_local **pp_local, ABTI_mutex *p_mutex)
-{
-    ABTI_ythread *p_ythread = NULL;
-    ABTI_xstream *p_local_xstream = ABTI_local_get_xstream_or_null(*pp_local);
-    if (!ABTI_IS_EXT_THREAD_ENABLED || p_local_xstream) {
-        p_ythread = ABTI_thread_get_ythread_or_null(p_local_xstream->p_thread);
-    }
-    if (p_ythread) {
-        LOG_DEBUG("%p: lock_low - try\n", p_mutex);
-        while (!ABTD_atomic_bool_cas_strong_uint32(&p_mutex->val, 0, 1)) {
-            ABTI_ythread_yield(&p_local_xstream, p_ythread,
-                               ABT_SYNC_EVENT_TYPE_MUTEX, (void *)p_mutex);
-            *pp_local = ABTI_xstream_get_local(p_local_xstream);
-        }
-        LOG_DEBUG("%p: lock_low - acquired\n", p_mutex);
-    } else {
-        ABTI_mutex_spinlock(p_mutex);
-    }
-}
-
-/* Hand over the mutex to other ULT on the same ES */
-static inline void mutex_unlock_se(ABTI_local **pp_local, ABTI_mutex *p_mutex)
-{
-    ABTI_ythread *p_ythread = NULL;
-    ABTI_xstream *p_local_xstream = ABTI_local_get_xstream_or_null(*pp_local);
-    if (!ABTI_IS_EXT_THREAD_ENABLED || p_local_xstream) {
-        p_ythread = ABTI_thread_get_ythread_or_null(p_local_xstream->p_thread);
-    }
-    ABTD_atomic_release_store_uint32(&p_mutex->val, 0);
-    LOG_DEBUG("%p: unlock_se\n", p_mutex);
-    if (p_ythread) {
-        ABTI_ythread_yield(&p_local_xstream, p_ythread,
-                           ABT_SYNC_EVENT_TYPE_MUTEX, (void *)p_mutex);
-        *pp_local = ABTI_xstream_get_local(p_local_xstream);
-    }
-}
diff --git a/src/rwlock.c b/src/rwlock.c
index 84f8f52..6f818c4 100644
--- a/src/rwlock.c
+++ b/src/rwlock.c
@@ -23,18 +23,13 @@
  */
 int ABT_rwlock_create(ABT_rwlock *newrwlock)
 {
-    int abt_errno;
     ABTI_rwlock *p_newrwlock;
 
-    abt_errno = ABTU_malloc(sizeof(ABTI_rwlock), (void **)&p_newrwlock);
+    int abt_errno = ABTU_malloc(sizeof(ABTI_rwlock), (void **)&p_newrwlock);
     ABTI_CHECK_ERROR(abt_errno);
 
     ABTI_CHECK_TRUE(p_newrwlock != NULL, ABT_ERR_MEM);
-    abt_errno = ABTI_mutex_init(&p_newrwlock->mutex);
-    if (ABTI_IS_ERROR_CHECK_ENABLED && abt_errno != ABT_SUCCESS) {
-        ABTU_free(p_newrwlock);
-        ABTI_HANDLE_ERROR(abt_errno);
-    }
+    ABTI_mutex_init(&p_newrwlock->mutex);
     ABTI_cond_init(&p_newrwlock->cond);
     p_newrwlock->reader_count = 0;
     p_newrwlock->write_flag = 0;
@@ -102,7 +97,7 @@ int ABT_rwlock_rdlock(ABT_rwlock rwlock)
     if (abt_errno == ABT_SUCCESS) {
         p_rwlock->reader_count++;
     }
-    ABTI_mutex_unlock(p_local, &p_rwlock->mutex);
+    ABTI_mutex_unlock(&p_rwlock->mutex);
     ABTI_CHECK_ERROR(abt_errno);
     return ABT_SUCCESS;
 }
@@ -136,7 +131,7 @@ int ABT_rwlock_wrlock(ABT_rwlock rwlock)
     if (abt_errno == ABT_SUCCESS) {
         p_rwlock->write_flag = 1;
     }
-    ABTI_mutex_unlock(p_local, &p_rwlock->mutex);
+    ABTI_mutex_unlock(&p_rwlock->mutex);
     ABTI_CHECK_ERROR(abt_errno);
     return ABT_SUCCESS;
 }
@@ -167,6 +162,6 @@ int ABT_rwlock_unlock(ABT_rwlock rwlock)
         p_rwlock->reader_count--;
     }
     ABTI_cond_broadcast(p_local, &p_rwlock->cond);
-    ABTI_mutex_unlock(p_local, &p_rwlock->mutex);
+    ABTI_mutex_unlock(&p_rwlock->mutex);
     return ABT_SUCCESS;
 }
-- 
2.21.0 (Apple Git-122.2)


From f3a4fdd5efc8b55b99720a60b028f3ca0f5a0b49 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Tue, 1 Dec 2020 19:05:27 -0600
Subject: [PATCH 25/40] mutex: use ABTI_waitlist for mutex

The current busy-yield-based implementation can easily make pools full of
waiting threads, which is inefficient.  ABTI_waitlist-based implementation can
avoid such a case.

Note that by default ABT_mutex will use busy-yield-based implementation in order
not to change the default performance of ABT_mutex.  For example, the original
implementation performs better if there is no contention.  ABTI_waitlist-based
implementation can be enabled by passing --disable-simple-mutex at configuration
time.
---
 src/cond.c               |  2 +-
 src/include/abti.h       |  8 ++++++--
 src/include/abti_cond.h  |  2 +-
 src/include/abti_mutex.h | 44 ++++++++++++++++++++++++++++++++++++----
 src/mutex.c              |  9 +++++---
 src/rwlock.c             |  6 +++---
 6 files changed, 57 insertions(+), 14 deletions(-)

diff --git a/src/cond.c b/src/cond.c
index 9d651df..30ad62f 100644
--- a/src/cond.c
+++ b/src/cond.c
@@ -142,7 +142,7 @@ int ABT_cond_timedwait(ABT_cond cond, ABT_mutex mutex,
     }
 
     /* Unlock the mutex that the calling ULT is holding */
-    ABTI_mutex_unlock(p_mutex);
+    ABTI_mutex_unlock(p_local, p_mutex);
     ABT_bool is_timedout =
         ABTI_waitlist_wait_timedout_and_unlock(&p_local, &p_cond->waitlist,
                                                &p_cond->lock, ABT_FALSE,
diff --git a/src/include/abti.h b/src/include/abti.h
index eae0ec9..e6a9156 100644
--- a/src/include/abti.h
+++ b/src/include/abti.h
@@ -161,8 +161,12 @@ struct ABTI_mutex_attr {
 };
 
 struct ABTI_mutex {
-    ABTI_spinlock lock;     /* lock */
-    ABTI_mutex_attr attr;   /* attributes */
+    ABTI_spinlock lock;   /* lock */
+    ABTI_mutex_attr attr; /* attributes */
+#ifndef ABT_CONFIG_USE_SIMPLE_MUTEX
+    ABTI_spinlock waiter_lock; /* lock */
+    ABTI_waitlist waitlist;    /* waiting list */
+#endif
 };
 
 struct ABTI_global {
diff --git a/src/include/abti_cond.h b/src/include/abti_cond.h
index 4e2597e..eb966ae 100644
--- a/src/include/abti_cond.h
+++ b/src/include/abti_cond.h
@@ -69,7 +69,7 @@ ABTI_cond_wait(ABTI_local **pp_local, ABTI_cond *p_cond, ABTI_mutex *p_mutex)
         }
     }
 
-    ABTI_mutex_unlock(p_mutex);
+    ABTI_mutex_unlock(*pp_local, p_mutex);
     ABTI_waitlist_wait_and_unlock(pp_local, &p_cond->waitlist, &p_cond->lock,
                                   ABT_FALSE, ABT_SYNC_EVENT_TYPE_COND,
                                   (void *)p_cond);
diff --git a/src/include/abti_mutex.h b/src/include/abti_mutex.h
index 02e1347..84b2505 100644
--- a/src/include/abti_mutex.h
+++ b/src/include/abti_mutex.h
@@ -39,6 +39,10 @@ static inline ABT_mutex ABTI_mutex_get_handle(ABTI_mutex *p_mutex)
 static inline void ABTI_mutex_init(ABTI_mutex *p_mutex)
 {
     ABTI_spinlock_clear(&p_mutex->lock);
+#ifndef ABT_CONFIG_USE_SIMPLE_MUTEX
+    ABTI_spinlock_clear(&p_mutex->waiter_lock);
+    ABTI_waitlist_init(&p_mutex->waitlist);
+#endif
     p_mutex->attr.attrs = ABTI_MUTEX_ATTR_NONE;
     p_mutex->attr.nesting_cnt = 0;
     p_mutex->attr.owner_id = 0;
@@ -46,11 +50,33 @@ static inline void ABTI_mutex_init(ABTI_mutex *p_mutex)
 
 static inline void ABTI_mutex_fini(ABTI_mutex *p_mutex)
 {
+#ifndef ABT_CONFIG_USE_SIMPLE_MUTEX
+    ABTI_spinlock_acquire(&p_mutex->waiter_lock);
+#endif
 }
 
 static inline void ABTI_mutex_lock_no_recursion(ABTI_local **pp_local,
                                                 ABTI_mutex *p_mutex)
 {
+#ifndef ABT_CONFIG_USE_SIMPLE_MUTEX
+    while (ABTI_spinlock_try_acquire(&p_mutex->lock)) {
+        /* Failed to take a lock, so let's add it to the waiter list. */
+        ABTI_spinlock_acquire(&p_mutex->waiter_lock);
+        /* Maybe the mutex lock has been already released.  Check it. */
+        if (!ABTI_spinlock_try_acquire(&p_mutex->lock)) {
+            /* Lock has been taken. */
+            ABTI_spinlock_release(&p_mutex->waiter_lock);
+            break;
+        }
+        /* Wait on waitlist. */
+        ABTI_waitlist_wait_and_unlock(pp_local, &p_mutex->waitlist,
+                                      &p_mutex->waiter_lock, ABT_FALSE,
+                                      ABT_SYNC_EVENT_TYPE_MUTEX,
+                                      (void *)p_mutex);
+    }
+    /* Take a lock. */
+#else
+    /* Simple yield-based implementation */
     ABTI_ythread *p_ythread = NULL;
     ABTI_xstream *p_local_xstream = ABTI_local_get_xstream_or_null(*pp_local);
     if (!ABTI_IS_EXT_THREAD_ENABLED || p_local_xstream)
@@ -66,6 +92,7 @@ static inline void ABTI_mutex_lock_no_recursion(ABTI_local **pp_local,
         /* Use spinlock. */
         ABTI_spinlock_acquire(&p_mutex->lock);
     }
+#endif
 }
 
 static inline void ABTI_mutex_lock(ABTI_local **pp_local, ABTI_mutex *p_mutex)
@@ -137,24 +164,33 @@ static inline void ABTI_mutex_spinlock(ABTI_local *p_local, ABTI_mutex *p_mutex)
     }
 }
 
-static inline void ABTI_mutex_unlock_no_recursion(ABTI_mutex *p_mutex)
+static inline void ABTI_mutex_unlock_no_recursion(ABTI_local *p_local,
+                                                  ABTI_mutex *p_mutex)
 {
+#ifndef ABT_CONFIG_USE_SIMPLE_MUTEX
+    ABTI_spinlock_acquire(&p_mutex->waiter_lock);
+    ABTI_spinlock_release(&p_mutex->lock);
+    /* Operations of waitlist must be done while taking waiter_lock. */
+    ABTI_waitlist_broadcast(p_local, &p_mutex->waitlist);
+    ABTI_spinlock_release(&p_mutex->waiter_lock);
+#else
     ABTI_spinlock_release(&p_mutex->lock);
+#endif
 }
 
-static inline void ABTI_mutex_unlock(ABTI_mutex *p_mutex)
+static inline void ABTI_mutex_unlock(ABTI_local *p_local, ABTI_mutex *p_mutex)
 {
     if (p_mutex->attr.attrs & ABTI_MUTEX_ATTR_RECURSIVE) {
         /* recursive mutex */
         if (p_mutex->attr.nesting_cnt == 0) {
             p_mutex->attr.owner_id = 0;
-            ABTI_mutex_unlock_no_recursion(p_mutex);
+            ABTI_mutex_unlock_no_recursion(p_local, p_mutex);
         } else {
             p_mutex->attr.nesting_cnt--;
         }
     } else {
         /* unknown attributes */
-        ABTI_mutex_unlock_no_recursion(p_mutex);
+        ABTI_mutex_unlock_no_recursion(p_local, p_mutex);
     }
 }
 
diff --git a/src/mutex.c b/src/mutex.c
index a9fef0b..3748ff9 100644
--- a/src/mutex.c
+++ b/src/mutex.c
@@ -226,9 +226,10 @@ int ABT_mutex_spinlock(ABT_mutex mutex)
  */
 int ABT_mutex_unlock(ABT_mutex mutex)
 {
+    ABTI_local *p_local = ABTI_local_get_local();
     ABTI_mutex *p_mutex = ABTI_mutex_get_ptr(mutex);
     ABTI_CHECK_NULL_MUTEX_PTR(p_mutex);
-    ABTI_mutex_unlock(p_mutex);
+    ABTI_mutex_unlock(p_local, p_mutex);
     return ABT_SUCCESS;
 }
 
@@ -251,17 +252,19 @@ int ABT_mutex_unlock(ABT_mutex mutex)
  */
 int ABT_mutex_unlock_se(ABT_mutex mutex)
 {
+    ABTI_local *p_local = ABTI_local_get_local();
     ABTI_mutex *p_mutex = ABTI_mutex_get_ptr(mutex);
     ABTI_CHECK_NULL_MUTEX_PTR(p_mutex);
-    ABTI_mutex_unlock(p_mutex);
+    ABTI_mutex_unlock(p_local, p_mutex);
     return ABT_SUCCESS;
 }
 
 int ABT_mutex_unlock_de(ABT_mutex mutex)
 {
+    ABTI_local *p_local = ABTI_local_get_local();
     ABTI_mutex *p_mutex = ABTI_mutex_get_ptr(mutex);
     ABTI_CHECK_NULL_MUTEX_PTR(p_mutex);
-    ABTI_mutex_unlock(p_mutex);
+    ABTI_mutex_unlock(p_local, p_mutex);
     return ABT_SUCCESS;
 }
 
diff --git a/src/rwlock.c b/src/rwlock.c
index 6f818c4..e606748 100644
--- a/src/rwlock.c
+++ b/src/rwlock.c
@@ -97,7 +97,7 @@ int ABT_rwlock_rdlock(ABT_rwlock rwlock)
     if (abt_errno == ABT_SUCCESS) {
         p_rwlock->reader_count++;
     }
-    ABTI_mutex_unlock(&p_rwlock->mutex);
+    ABTI_mutex_unlock(p_local, &p_rwlock->mutex);
     ABTI_CHECK_ERROR(abt_errno);
     return ABT_SUCCESS;
 }
@@ -131,7 +131,7 @@ int ABT_rwlock_wrlock(ABT_rwlock rwlock)
     if (abt_errno == ABT_SUCCESS) {
         p_rwlock->write_flag = 1;
     }
-    ABTI_mutex_unlock(&p_rwlock->mutex);
+    ABTI_mutex_unlock(p_local, &p_rwlock->mutex);
     ABTI_CHECK_ERROR(abt_errno);
     return ABT_SUCCESS;
 }
@@ -162,6 +162,6 @@ int ABT_rwlock_unlock(ABT_rwlock rwlock)
         p_rwlock->reader_count--;
     }
     ABTI_cond_broadcast(p_local, &p_rwlock->cond);
-    ABTI_mutex_unlock(&p_rwlock->mutex);
+    ABTI_mutex_unlock(p_local, &p_rwlock->mutex);
     return ABT_SUCCESS;
 }
-- 
2.21.0 (Apple Git-122.2)


From b7d30fbc18c04d87377a7f0777d9ea1766c08325 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Wed, 2 Dec 2020 13:16:05 -0600
Subject: [PATCH 26/40] info: return information even if Argobots is not
 initialized

ABT_info_query_config(), ABT_info_print_config(), and
ABT_info_print_all_xstreams() are functions that return the system information.
Such information can be returned even without initialization of Argobots.  This
patch changes these functions so that they can return some information without
throwing an error if possible when Argobots is not initialized.

This is useful to know, for example, configuration-time parameters such as
support of some Argobots features before instantiating Argobots.
---
 src/info.c | 31 +++++++++++++++++++++----------
 1 file changed, 21 insertions(+), 10 deletions(-)

diff --git a/src/info.c b/src/info.c
index 9112216..420a0cf 100644
--- a/src/info.c
+++ b/src/info.c
@@ -115,10 +115,9 @@ static void info_trigger_print_all_thread_stacks(
  */
 int ABT_info_query_config(ABT_info_query_kind query_kind, void *val)
 {
-    ABTI_SETUP_WITH_INIT_CHECK();
-
     switch (query_kind) {
         case ABT_INFO_QUERY_KIND_ENABLED_DEBUG:
+            ABTI_SETUP_WITH_INIT_CHECK();
             *((ABT_bool *)val) = gp_ABTI_global->use_debug;
             break;
         case ABT_INFO_QUERY_KIND_ENABLED_PRINT_ERRNO:
@@ -129,6 +128,7 @@ int ABT_info_query_config(ABT_info_query_kind query_kind, void *val)
 #endif
             break;
         case ABT_INFO_QUERY_KIND_ENABLED_LOG:
+            ABTI_SETUP_WITH_INIT_CHECK();
             *((ABT_bool *)val) = gp_ABTI_global->use_logging;
             break;
         case ABT_INFO_QUERY_KIND_ENABLED_VALGRIND:
@@ -197,24 +197,31 @@ int ABT_info_query_config(ABT_info_query_kind query_kind, void *val)
 #endif
             break;
         case ABT_INFO_QUERY_KIND_ENABLED_PRINT_CONFIG:
+            ABTI_SETUP_WITH_INIT_CHECK();
             *((ABT_bool *)val) = gp_ABTI_global->print_config;
             break;
         case ABT_INFO_QUERY_KIND_ENABLED_AFFINITY:
+            ABTI_SETUP_WITH_INIT_CHECK();
             *((ABT_bool *)val) = gp_ABTI_global->set_affinity;
             break;
         case ABT_INFO_QUERY_KIND_MAX_NUM_XSTREAMS:
+            ABTI_SETUP_WITH_INIT_CHECK();
             *((unsigned int *)val) = gp_ABTI_global->max_xstreams;
             break;
         case ABT_INFO_QUERY_KIND_DEFAULT_THREAD_STACKSIZE:
+            ABTI_SETUP_WITH_INIT_CHECK();
             *((size_t *)val) = gp_ABTI_global->thread_stacksize;
             break;
         case ABT_INFO_QUERY_KIND_DEFAULT_SCHED_STACKSIZE:
+            ABTI_SETUP_WITH_INIT_CHECK();
             *((size_t *)val) = gp_ABTI_global->sched_stacksize;
             break;
         case ABT_INFO_QUERY_KIND_DEFAULT_SCHED_EVENT_FREQ:
+            ABTI_SETUP_WITH_INIT_CHECK();
             *((uint64_t *)val) = gp_ABTI_global->sched_event_freq;
             break;
         case ABT_INFO_QUERY_KIND_DEFAULT_SCHED_SLEEP_NSEC:
+            ABTI_SETUP_WITH_INIT_CHECK();
             *((uint64_t *)val) = gp_ABTI_global->sched_sleep_nsec;
             break;
         case ABT_INFO_QUERY_KIND_ENABLED_TOOL:
@@ -240,13 +247,15 @@ int ABT_info_query_config(ABT_info_query_kind query_kind, void *val)
  *
  * @param[in] fp  output stream
  * @return Error code
- * @retval ABT_SUCCESS            on success
- * @retval ABT_ERR_UNINITIALIZED  Argobots has not been initialized
+ * @retval ABT_SUCCESS  on success
  */
 int ABT_info_print_config(FILE *fp)
 {
-    ABTI_SETUP_WITH_INIT_CHECK();
-
+    if (!gp_ABTI_global) {
+        fprintf(fp, "Argobots is not initialized.\n");
+        fflush(fp);
+        return ABT_SUCCESS;
+    }
     ABTI_info_print_config(fp);
     return ABT_SUCCESS;
 }
@@ -260,13 +269,15 @@ int ABT_info_print_config(FILE *fp)
  *
  * @param[in] fp  output stream
  * @return Error code
- * @retval ABT_SUCCESS            on success
- * @retval ABT_ERR_UNINITIALIZED  Argobots has not been initialized
+ * @retval ABT_SUCCESS  on success
  */
 int ABT_info_print_all_xstreams(FILE *fp)
 {
-    ABTI_SETUP_WITH_INIT_CHECK();
-
+    if (!gp_ABTI_global) {
+        fprintf(fp, "Argobots is not initialized.\n");
+        fflush(fp);
+        return ABT_SUCCESS;
+    }
     ABTI_global *p_global = gp_ABTI_global;
 
     ABTI_spinlock_acquire(&p_global->xstream_list_lock);
-- 
2.21.0 (Apple Git-122.2)


From a8f8c310cdf28fef7257a0018205623b6cfaa673 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Wed, 2 Dec 2020 13:24:34 -0600
Subject: [PATCH 27/40] info: print information when a handle is NULL

Previously a error code is returned if NULL handles are passed, but printing
NULL handles as "NULL" is often meaningful.  This patch changes the behavior of
ABT_info_xxx() functions to show "NULL" in such a case.
---
 src/info.c    | 36 +++++++++++++++++++-----------------
 src/ythread.c |  2 ++
 2 files changed, 21 insertions(+), 17 deletions(-)

diff --git a/src/info.c b/src/info.c
index 420a0cf..691eb68 100644
--- a/src/info.c
+++ b/src/info.c
@@ -311,8 +311,6 @@ int ABT_info_print_all_xstreams(FILE *fp)
 int ABT_info_print_xstream(FILE *fp, ABT_xstream xstream)
 {
     ABTI_xstream *p_xstream = ABTI_xstream_get_ptr(xstream);
-    ABTI_CHECK_NULL_XSTREAM_PTR(p_xstream);
-
     ABTI_xstream_print(p_xstream, fp, 0, ABT_FALSE);
     return ABT_SUCCESS;
 }
@@ -332,8 +330,6 @@ int ABT_info_print_xstream(FILE *fp, ABT_xstream xstream)
 int ABT_info_print_sched(FILE *fp, ABT_sched sched)
 {
     ABTI_sched *p_sched = ABTI_sched_get_ptr(sched);
-    ABTI_CHECK_NULL_SCHED_PTR(p_sched);
-
     ABTI_sched_print(p_sched, fp, 0, ABT_TRUE);
     return ABT_SUCCESS;
 }
@@ -353,8 +349,6 @@ int ABT_info_print_sched(FILE *fp, ABT_sched sched)
 int ABT_info_print_pool(FILE *fp, ABT_pool pool)
 {
     ABTI_pool *p_pool = ABTI_pool_get_ptr(pool);
-    ABTI_CHECK_NULL_POOL_PTR(p_pool);
-
     ABTI_pool_print(p_pool, fp, 0);
     return ABT_SUCCESS;
 }
@@ -374,8 +368,6 @@ int ABT_info_print_pool(FILE *fp, ABT_pool pool)
 int ABT_info_print_thread(FILE *fp, ABT_thread thread)
 {
     ABTI_thread *p_thread = ABTI_thread_get_ptr(thread);
-    ABTI_CHECK_NULL_THREAD_PTR(p_thread);
-
     ABTI_thread_print(p_thread, fp, 0);
     return ABT_SUCCESS;
 }
@@ -396,8 +388,6 @@ int ABT_info_print_thread(FILE *fp, ABT_thread thread)
 int ABT_info_print_thread_attr(FILE *fp, ABT_thread_attr attr)
 {
     ABTI_thread_attr *p_attr = ABTI_thread_attr_get_ptr(attr);
-    ABTI_CHECK_NULL_THREAD_ATTR_PTR(p_attr);
-
     ABTI_thread_attr_print(p_attr, fp, 0);
     return ABT_SUCCESS;
 }
@@ -433,11 +423,19 @@ int ABT_info_print_task(FILE *fp, ABT_task task);
 int ABT_info_print_thread_stack(FILE *fp, ABT_thread thread)
 {
     ABTI_thread *p_thread = ABTI_thread_get_ptr(thread);
-    ABTI_CHECK_NULL_THREAD_PTR(p_thread);
-    ABTI_ythread *p_ythread;
-    ABTI_CHECK_YIELDABLE(p_thread, &p_ythread, ABT_ERR_INV_THREAD);
-
-    ABTI_ythread_print_stack(p_ythread, fp);
+    if (!p_thread) {
+        fprintf(fp, "no stack\n");
+        fflush(0);
+    } else {
+        ABTI_ythread *p_ythread;
+        if (p_thread->type & ABTI_THREAD_TYPE_YIELDABLE) {
+            p_ythread = ABTI_thread_get_ythread(p_thread);
+            ABTI_ythread_print_stack(p_ythread, fp);
+        } else {
+            fprintf(fp, "no stack\n");
+            fflush(0);
+        }
+    }
     return ABT_SUCCESS;
 }
 
@@ -457,8 +455,6 @@ int ABT_info_print_thread_stack(FILE *fp, ABT_thread thread)
 int ABT_info_print_thread_stacks_in_pool(FILE *fp, ABT_pool pool)
 {
     ABTI_pool *p_pool = ABTI_pool_get_ptr(pool);
-    ABTI_CHECK_NULL_POOL_PTR(p_pool);
-
     int abt_errno = info_print_thread_stacks_in_pool(fp, p_pool);
     ABTI_CHECK_ERROR(abt_errno);
     return ABT_SUCCESS;
@@ -712,6 +708,12 @@ static void info_print_unit(void *arg, ABT_unit unit)
 ABTU_ret_err static int info_print_thread_stacks_in_pool(FILE *fp,
                                                          ABTI_pool *p_pool)
 {
+    if (p_pool == NULL) {
+        fprintf(fp, "== NULL pool ==\n");
+        fflush(fp);
+        return ABT_SUCCESS;
+    }
+
     ABT_pool pool = ABTI_pool_get_handle(p_pool);
 
     if (!p_pool->p_print_all) {
diff --git a/src/ythread.c b/src/ythread.c
index 02b2c7f..741dcd1 100644
--- a/src/ythread.c
+++ b/src/ythread.c
@@ -89,6 +89,8 @@ ABTU_no_sanitize_address void ABTI_ythread_print_stack(ABTI_ythread *p_ythread,
     size_t i, j, stacksize = p_ythread->stacksize;
     if (stacksize == 0 || p_stack == NULL) {
         /* Some threads do not have p_stack (e.g., the main thread) */
+        fprintf(p_os, "no stack\n");
+        fflush(0);
         return;
     }
 
-- 
2.21.0 (Apple Git-122.2)


From 47d1c54b5ebf5384093833e6e2d5e1c17853b7f9 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Wed, 2 Dec 2020 13:49:47 -0600
Subject: [PATCH 28/40] info: fix ABT_INFO_QUERY_KIND_ENABLED_PRESERVE_FPU

FPU is not preserved only when 1. fcontext is used and 2. FPU preservation is
disabled.  This patch fixes the condition.
---
 src/info.c | 7 ++++---
 1 file changed, 4 insertions(+), 3 deletions(-)

diff --git a/src/info.c b/src/info.c
index 691eb68..b52ca59 100644
--- a/src/info.c
+++ b/src/info.c
@@ -152,10 +152,11 @@ int ABT_info_query_config(ABT_info_query_kind query_kind, void *val)
             *((ABT_bool *)val) = ABT_FALSE;
             break;
         case ABT_INFO_QUERY_KIND_ENABLED_PRESERVE_FPU:
-#ifdef ABTD_FCONTEXT_PRESERVE_FPU
-            *((ABT_bool *)val) = ABT_TRUE;
-#else
+#if !defined(ABTD_FCONTEXT_PRESERVE_FPU) && defined(ABT_CONFIG_USE_FCONTEXT)
             *((ABT_bool *)val) = ABT_FALSE;
+#else
+            /* If ucontext is used, FPU is preserved. */
+            *((ABT_bool *)val) = ABT_TRUE;
 #endif
             break;
         case ABT_INFO_QUERY_KIND_ENABLED_THREAD_CANCEL:
-- 
2.21.0 (Apple Git-122.2)


From 2cd62d1156ebbd6ae6a54c0e67b3b630f54e14bd Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Wed, 2 Dec 2020 13:59:20 -0600
Subject: [PATCH 29/40] info: add ABT_INFO_QUERY_KIND_FCONTEXT and
 _DYNAMIC_PROMOTION

The user can know the underlying context-switching implementation via
ABT_info_query_config().  This is useful to understand the performance at
runtime to some extent.
---
 src/include/abt.h.in |  4 ++++
 src/info.c           | 20 ++++++++++++++++++++
 2 files changed, 24 insertions(+)

diff --git a/src/include/abt.h.in b/src/include/abt.h.in
index 198f5dd..d4385fc 100644
--- a/src/include/abt.h.in
+++ b/src/include/abt.h.in
@@ -222,6 +222,10 @@ enum ABT_info_query_kind {
     ABT_INFO_QUERY_KIND_DEFAULT_SCHED_SLEEP_NSEC,
     /* Whether the tool interface is enabled or not */
     ABT_INFO_QUERY_KIND_ENABLED_TOOL,
+    /* Whether fcontext is used for context switch or not */
+    ABT_INFO_QUERY_KIND_FCONTEXT,
+    /* Whether dynamic promotion is used for context switch or not */
+    ABT_INFO_QUERY_KIND_DYNAMIC_PROMOTION,
 };
 
 enum ABT_tool_query_kind {
diff --git a/src/info.c b/src/info.c
index b52ca59..614babc 100644
--- a/src/info.c
+++ b/src/info.c
@@ -105,6 +105,12 @@ static void info_trigger_print_all_thread_stacks(
  * - ABT_INFO_QUERY_KIND_ENABLED_TOOL
  *   \c val must be a pointer to a variable of the type ABT_bool.  ABT_TRUE is
  *   set to \c *val if the tool is enabled.  Otherwise, ABT_FALSE is set.
+ * - ABT_INFO_QUERY_KIND_FCONTEXT
+ *   \c val must be a pointer to a variable of the type ABT_bool.  ABT_TRUE is
+ *   set to \c *val if fcontext is used.  Otherwise, ABT_FALSE is set.
+ * - ABT_INFO_QUERY_KIND_DYNAMIC_PROMOTION
+ *   \c val must be a pointer to a variable of the type ABT_bool.  ABT_TRUE is
+ *   set to \c *val if dynamic promotion is used.  Otherwise, ABT_FALSE is set.
  *
  * @param[in]  query_kind  query kind
  * @param[out] val         a pointer to a result
@@ -230,6 +236,20 @@ int ABT_info_query_config(ABT_info_query_kind query_kind, void *val)
             *((ABT_bool *)val) = ABT_TRUE;
 #else
             *((ABT_bool *)val) = ABT_FALSE;
+#endif
+            break;
+        case ABT_INFO_QUERY_KIND_FCONTEXT:
+#ifdef ABT_CONFIG_USE_FCONTEXT
+            *((ABT_bool *)val) = ABT_TRUE;
+#else
+            *((ABT_bool *)val) = ABT_FALSE;
+#endif
+            break;
+        case ABT_INFO_QUERY_KIND_DYNAMIC_PROMOTION:
+#if ABT_CONFIG_THREAD_TYPE == ABT_THREAD_TYPE_DYNAMIC_PROMOTION
+            *((ABT_bool *)val) = ABT_TRUE;
+#else
+            *((ABT_bool *)val) = ABT_FALSE;
 #endif
             break;
         default:
-- 
2.21.0 (Apple Git-122.2)


From 7e17ba3deff9942a1724fd96506a5c0b060da26a Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Wed, 2 Dec 2020 13:30:08 -0600
Subject: [PATCH 30/40] info: add missing fflush

---
 src/info.c    | 2 ++
 src/ythread.c | 1 +
 2 files changed, 3 insertions(+)

diff --git a/src/info.c b/src/info.c
index 614babc..b1a462b 100644
--- a/src/info.c
+++ b/src/info.c
@@ -593,6 +593,7 @@ void ABTI_info_check_print_all_thread_stacks(void)
         ABTI_spinlock_release(&gp_ABTI_global->xstream_list_lock);
         if (print_cb_func)
             print_cb_func(force_print, print_arg);
+        fflush(print_stack_fp);
         /* Update print_stack_flag to 3. */
         ABTD_atomic_release_store_int(&print_stack_flag,
                                       PRINT_STACK_FLAG_FINALIZE);
@@ -745,6 +746,7 @@ ABTU_ret_err static int info_print_thread_stacks_in_pool(FILE *fp,
     arg.fp = fp;
     arg.pool = pool;
     p_pool->p_print_all(pool, &arg, info_print_unit);
+    fflush(fp);
     return ABT_SUCCESS;
 }
 
diff --git a/src/ythread.c b/src/ythread.c
index 741dcd1..8528583 100644
--- a/src/ythread.c
+++ b/src/ythread.c
@@ -133,4 +133,5 @@ ABTU_no_sanitize_address void ABTI_ythread_print_stack(ABTI_ythread *p_ythread,
                 fprintf(p_os, "\n");
         }
     }
+    fflush(p_os);
 }
-- 
2.21.0 (Apple Git-122.2)


From 9f0136c46478c0078acc1fb0b1d16b7b5d715402 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Wed, 2 Dec 2020 14:09:01 -0600
Subject: [PATCH 31/40] info: update information printed by ABT_info_print
 functions

Some ABT_info_print functions do not print the latest information added
recently.  This patch updates the contents printed by these functions.
---
 src/arch/abtd_stream.c | 26 ++++++++++++
 src/include/abtd.h     |  2 +
 src/info.c             | 96 +++++++++++++++++++++++++++++++++++++++---
 src/sched/sched.c      |  5 ++-
 src/stream.c           | 16 +++++--
 src/thread.c           | 56 ++++++++++++++++++------
 6 files changed, 179 insertions(+), 22 deletions(-)

diff --git a/src/arch/abtd_stream.c b/src/arch/abtd_stream.c
index d9ba075..0818028 100644
--- a/src/arch/abtd_stream.c
+++ b/src/arch/abtd_stream.c
@@ -108,3 +108,29 @@ void ABTD_xstream_context_set_self(ABTD_xstream_context *p_ctx)
 {
     p_ctx->native_thread = pthread_self();
 }
+
+void ABTD_xstream_context_print(ABTD_xstream_context *p_ctx, FILE *p_os,
+                                int indent)
+{
+    if (p_ctx == NULL) {
+        fprintf(p_os, "%*s== NULL XSTREAM CONTEXT ==\n", indent, "");
+    } else {
+        const char *state;
+        if (p_ctx->state == ABTD_XSTREAM_CONTEXT_STATE_RUNNING) {
+            state = "RUNNING";
+        } else if (p_ctx->state == ABTD_XSTREAM_CONTEXT_STATE_WAITING) {
+            state = "WAITING";
+        } else if (p_ctx->state == ABTD_XSTREAM_CONTEXT_STATE_REQ_JOIN) {
+            state = "REQ_JOIN";
+        } else if (p_ctx->state == ABTD_XSTREAM_CONTEXT_STATE_REQ_TERMINATE) {
+            state = "REQ_TERMINATE";
+        } else {
+            state = "UNKNOWN";
+        }
+        fprintf(p_os,
+                "%*s== XSTREAM CONTEXT (%p) ==\n"
+                "%*sstate : %s\n",
+                indent, "", (void *)p_ctx, indent, "", state);
+    }
+    fflush(p_os);
+}
diff --git a/src/include/abtd.h b/src/include/abtd.h
index 677ddc1..76af062 100644
--- a/src/include/abtd.h
+++ b/src/include/abtd.h
@@ -51,6 +51,8 @@ void ABTD_xstream_context_free(ABTD_xstream_context *p_ctx);
 void ABTD_xstream_context_join(ABTD_xstream_context *p_ctx);
 void ABTD_xstream_context_revive(ABTD_xstream_context *p_ctx);
 void ABTD_xstream_context_set_self(ABTD_xstream_context *p_ctx);
+void ABTD_xstream_context_print(ABTD_xstream_context *p_ctx, FILE *p_os,
+                                int indent);
 
 /* ES Affinity */
 void ABTD_affinity_init(const char *affinity_str);
diff --git a/src/info.c b/src/info.c
index b1a462b..7dea04e 100644
--- a/src/info.c
+++ b/src/info.c
@@ -620,9 +620,10 @@ void ABTI_info_print_config(FILE *fp)
     ABTI_global *p_global = gp_ABTI_global;
 
     fprintf(fp, "Argobots Configuration:\n");
+    fprintf(fp, " - version: " ABT_VERSION "\n");
     fprintf(fp, " - # of cores: %d\n", p_global->num_cores);
-    fprintf(fp, " - cache line size: %u\n", ABT_CONFIG_STATIC_CACHELINE_SIZE);
-    fprintf(fp, " - huge page size: %zu\n", p_global->huge_page_size);
+    fprintf(fp, " - cache line size: %u B\n", ABT_CONFIG_STATIC_CACHELINE_SIZE);
+    fprintf(fp, " - huge page size: %zu B\n", p_global->huge_page_size);
     fprintf(fp, " - max. # of ESs: %d\n", p_global->max_xstreams);
     fprintf(fp, " - cur. # of ESs: %d\n", p_global->num_xstreams);
     fprintf(fp, " - ES affinity: %s\n",
@@ -631,14 +632,98 @@ void ABTI_info_print_config(FILE *fp)
             (p_global->use_logging == ABT_TRUE) ? "on" : "off");
     fprintf(fp, " - debug output: %s\n",
             (p_global->use_debug == ABT_TRUE) ? "on" : "off");
+    fprintf(fp, " - print errno: "
+#ifdef ABT_CONFIG_PRINT_ABT_ERRNO
+                "on"
+#else
+                "off"
+#endif
+                "\n");
+    fprintf(fp, " - valgrind support: "
+#ifdef HAVE_VALGRIND_SUPPORT
+                "yes"
+#else
+                "no"
+#endif
+                "\n");
+    fprintf(fp, " - thread cancellation: "
+#ifndef ABT_CONFIG_DISABLE_THREAD_CANCEL
+                "enabled"
+#else
+                "disabled"
+#endif
+                "\n");
+    fprintf(fp, " - task cancellation: "
+#ifndef ABT_CONFIG_DISABLE_TASK_CANCEL
+                "enabled"
+#else
+                "disabled"
+#endif
+                "\n");
+    fprintf(fp, " - thread migration: "
+#ifndef ABT_CONFIG_DISABLE_MIGRATION
+                "enabled"
+#else
+                "disabled"
+#endif
+                "\n");
+    fprintf(fp, " - external thread: "
+#ifndef ABT_CONFIG_DISABLE_EXT_THREAD
+                "enabled"
+#else
+                "disabled"
+#endif
+                "\n");
+    fprintf(fp, " - error check: "
+#ifndef ABT_CONFIG_DISABLE_ERROR_CHECK
+                "enabled"
+#else
+                "disable"
+#endif
+                "\n");
+    fprintf(fp, " - tool interface: "
+#ifndef ABT_CONFIG_DISABLE_TOOL_INTERFACE
+                "yes"
+#else
+                "no"
+#endif
+                "\n");
+    fprintf(fp, " - context-switch: "
+#ifdef ABT_CONFIG_USE_FCONTEXT
+                "fcontext"
+#if ABT_CONFIG_THREAD_TYPE == ABT_THREAD_TYPE_DYNAMIC_PROMOTION &&             \
+    defined(ABTD_FCONTEXT_PRESERVE_FPU)
+                " (dynamic-promotion)"
+#elif ABT_CONFIG_THREAD_TYPE == ABT_THREAD_TYPE_DYNAMIC_PROMOTION &&           \
+    !defined(ABTD_FCONTEXT_PRESERVE_FPU)
+                " (dynamic-promotion, no FPU save)"
+#elif ABT_CONFIG_THREAD_TYPE != ABT_THREAD_TYPE_DYNAMIC_PROMOTION &&           \
+    !defined(ABTD_FCONTEXT_PRESERVE_FPU)
+                " (no FPU save)"
+#endif /* ABT_CONFIG_THREAD_TYPE, ABTD_FCONTEXT_PRESERVE_FPU */
+
+#else  /* ABT_CONFIG_USE_FCONTEXT */
+                "ucontext"
+#endif /* !ABT_CONFIG_USE_FCONTEXT */
+                "\n");
+
     fprintf(fp, " - key table entries: %" PRIu32 "\n",
             p_global->key_table_size);
-    fprintf(fp, " - ULT stack size: %zu KB\n",
+    fprintf(fp, " - default ULT stack size: %zu KB\n",
             p_global->thread_stacksize / 1024);
-    fprintf(fp, " - scheduler stack size: %zu KB\n",
+    fprintf(fp, " - default scheduler stack size: %zu KB\n",
             p_global->sched_stacksize / 1024);
-    fprintf(fp, " - scheduler event check frequency: %u\n",
+    fprintf(fp, " - default scheduler event check frequency: %u\n",
             p_global->sched_event_freq);
+    fprintf(fp, " - default scheduler sleep: "
+#ifdef ABT_CONFIG_USE_SCHED_SLEEP
+                "on"
+#else
+                "off"
+#endif
+                "\n");
+    fprintf(fp, " - default scheduler sleep duration : %" PRIu64 " [ns]\n",
+            p_global->sched_sleep_nsec);
 
     fprintf(fp, " - timer function: "
 #if defined(ABT_CONFIG_USE_CLOCK_GETTIME)
@@ -656,6 +741,7 @@ void ABTI_info_print_config(FILE *fp)
             p_global->mem_page_size / 1024);
     fprintf(fp, " - stack page size: %zu KB\n", p_global->mem_sp_size / 1024);
     fprintf(fp, " - max. # of stacks per ES: %u\n", p_global->mem_max_stacks);
+    fprintf(fp, " - max. # of descs per ES: %u\n", p_global->mem_max_descs);
     switch (p_global->mem_lp_alloc) {
         case ABTI_MEM_LP_MALLOC:
             fprintf(fp, " - large page allocation: malloc\n");
diff --git a/src/sched/sched.c b/src/sched/sched.c
index 2ad7007..5686cb7 100644
--- a/src/sched/sched.c
+++ b/src/sched/sched.c
@@ -647,6 +647,8 @@ void ABTI_sched_print(ABTI_sched *p_sched, FILE *p_os, int indent,
             kind_str = "BASIC_WAIT";
         } else if (kind == sched_get_kind(ABTI_sched_get_prio_def())) {
             kind_str = "PRIO";
+        } else if (kind == sched_get_kind(ABTI_sched_get_randws_def())) {
+            kind_str = "RANDWS";
         } else {
             kind_str = "USER";
         }
@@ -690,6 +692,7 @@ void ABTI_sched_print(ABTI_sched *p_sched, FILE *p_os, int indent,
                 "%*snum_pools: %zu\n"
                 "%*ssize     : %zu\n"
                 "%*stot_size : %zu\n"
+                "%*sthread   : %p\n"
                 "%*sdata     : %p\n",
                 indent, "", (void *)p_sched,
 #ifdef ABT_CONFIG_USE_DEBUG_LOG
@@ -701,7 +704,7 @@ void ABTI_sched_print(ABTI_sched *p_sched, FILE *p_os, int indent,
                 ABTD_atomic_acquire_load_uint32(&p_sched->request), indent, "",
                 p_sched->num_pools, indent, "", ABTI_sched_get_size(p_sched),
                 indent, "", ABTI_sched_get_total_size(p_sched), indent, "",
-                p_sched->data);
+                (void *)p_sched->p_ythread, indent, "", p_sched->data);
         if (print_sub == ABT_TRUE) {
             size_t i;
             for (i = 0; i < p_sched->num_pools; i++) {
diff --git a/src/stream.c b/src/stream.c
index 8a87b37..9968fb4 100644
--- a/src/stream.c
+++ b/src/stream.c
@@ -1003,18 +1003,26 @@ void ABTI_xstream_print(ABTI_xstream *p_xstream, FILE *p_os, int indent,
 
         fprintf(p_os,
                 "%*s== ES (%p) ==\n"
-                "%*srank      : %d\n"
-                "%*stype      : %s\n"
-                "%*sstate     : %s\n"
-                "%*smain_sched: %p\n",
+                "%*srank         : %d\n"
+                "%*stype         : %s\n"
+                "%*sstate        : %s\n"
+                "%*sroot_ythread : %p\n"
+                "%*sroot_pool    : %p\n"
+                "%*sthread       : %p\n"
+                "%*smain_sched   : %p\n",
                 indent, "", (void *)p_xstream, indent, "", p_xstream->rank,
                 indent, "", type, indent, "", state, indent, "",
+                (void *)p_xstream->p_root_ythread, indent, "",
+                (void *)p_xstream->p_root_pool, indent, "",
+                (void *)p_xstream->p_thread, indent, "",
                 (void *)p_xstream->p_main_sched);
 
         if (print_sub == ABT_TRUE) {
             ABTI_sched_print(p_xstream->p_main_sched, p_os,
                              indent + ABTI_INDENT, ABT_TRUE);
         }
+        fprintf(p_os, "%*sctx          :\n", indent, "");
+        ABTD_xstream_context_print(&p_xstream->ctx, p_os, indent + ABTI_INDENT);
     }
     fflush(p_os);
 }
diff --git a/src/thread.c b/src/thread.c
index e60a044..69a98b9 100644
--- a/src/thread.c
+++ b/src/thread.c
@@ -1536,12 +1536,14 @@ void ABTI_thread_print(ABTI_thread *p_thread, FILE *p_os, int indent)
     } else {
         ABTI_xstream *p_xstream = p_thread->p_last_xstream;
         int xstream_rank = p_xstream ? p_xstream->rank : 0;
-        const char *type, *yieldable, *state;
+        const char *type, *yieldable, *state, *named, *migratable;
 
         if (p_thread->type & ABTI_THREAD_TYPE_MAIN) {
             type = "MAIN";
         } else if (p_thread->type & ABTI_THREAD_TYPE_MAIN_SCHED) {
             type = "MAIN_SCHED";
+        } else if (p_thread->type & ABTI_THREAD_TYPE_ROOT) {
+            type = "ROOT";
         } else {
             type = "USER";
         }
@@ -1550,6 +1552,16 @@ void ABTI_thread_print(ABTI_thread *p_thread, FILE *p_os, int indent)
         } else {
             yieldable = "no";
         }
+        if (p_thread->type & ABTI_THREAD_TYPE_NAMED) {
+            named = "yes";
+        } else {
+            named = "no";
+        }
+        if (p_thread->type & ABTI_THREAD_TYPE_MIGRATABLE) {
+            migratable = "yes";
+        } else {
+            migratable = "no";
+        }
         switch (ABTD_atomic_acquire_load_int(&p_thread->state)) {
             case ABT_THREAD_STATE_READY:
                 state = "READY";
@@ -1567,25 +1579,45 @@ void ABTI_thread_print(ABTI_thread *p_thread, FILE *p_os, int indent)
                 state = "UNKNOWN";
                 break;
         }
+        ABTI_thread_mig_data *p_mig_data =
+            (ABTI_thread_mig_data *)ABTI_ktable_get(&p_thread->p_keytable,
+                                                    &g_thread_mig_data_key);
+        void *p_migration_cb_arg =
+            p_mig_data ? p_mig_data->p_migration_cb_arg : NULL;
 
         fprintf(p_os,
                 "%*s== Thread (%p) ==\n"
-                "%*sid        : %" PRIu64 "\n"
-                "%*stype      : %s\n"
-                "%*syieldable : %s\n"
-                "%*sstate     : %s\n"
-                "%*slast_ES   : %p (%d)\n"
-                "%*sp_arg     : %p\n"
-                "%*spool      : %p\n"
-                "%*srequest   : 0x%x\n"
-                "%*skeytable  : %p\n",
+                "%*sid         : %" PRIu64 "\n"
+                "%*stype       : %s\n"
+                "%*syieldable  : %s\n"
+                "%*sstate      : %s\n"
+                "%*slast_ES    : %p (%d)\n"
+                "%*sparent     : %p\n"
+                "%*sp_arg      : %p\n"
+                "%*spool       : %p\n"
+                "%*snamed      : %s\n"
+                "%*smigratable : %s\n"
+                "%*srequest    : 0x%x\n"
+                "%*smig_cb_arg : %p\n"
+                "%*skeytable   : %p\n",
                 indent, "", (void *)p_thread, indent, "",
                 ABTI_thread_get_id(p_thread), indent, "", type, indent, "",
                 yieldable, indent, "", state, indent, "", (void *)p_xstream,
-                xstream_rank, indent, "", p_thread->p_arg, indent, "",
-                (void *)p_thread->p_pool, indent, "",
+                xstream_rank, indent, "", (void *)p_thread->p_parent, indent,
+                "", p_thread->p_arg, indent, "", (void *)p_thread->p_pool,
+                indent, "", named, indent, "", migratable, indent, "",
                 ABTD_atomic_acquire_load_uint32(&p_thread->request), indent, "",
+                p_migration_cb_arg, indent, "",
                 ABTD_atomic_acquire_load_ptr(&p_thread->p_keytable));
+
+        if (p_thread->type & ABTI_THREAD_TYPE_YIELDABLE) {
+            ABTI_ythread *p_ythread = ABTI_thread_get_ythread(p_thread);
+            fprintf(p_os,
+                    "%*sstack      : %p\n"
+                    "%*sstacksize  : %zu\n",
+                    indent, "", p_ythread->p_stack, indent, "",
+                    p_ythread->stacksize);
+        }
     }
     fflush(p_os);
 }
-- 
2.21.0 (Apple Git-122.2)


From 8b32bbb64d61d299010d7f421bf468d89d057433 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Thu, 3 Dec 2020 16:22:30 -0600
Subject: [PATCH 32/40] stream_barrier: add a fallback implementation of
 ABT_stream_barrier

ABT_stream_barrier was unavailable if pthread_barrier is not supported.
Although such a case should be extremely rare, we should provide the same
functionality if it should happen.  This patch implements a simple sense-based
barrier implementation (though it uses uint64-type tag instead of bool-type
sense).
---
 src/include/abti.h                |  6 +++++
 src/include/abti_stream_barrier.h |  2 --
 src/stream_barrier.c              | 44 ++++++++++++++++++++++---------
 3 files changed, 38 insertions(+), 14 deletions(-)

diff --git a/src/include/abti.h b/src/include/abti.h
index e6a9156..04a0e51 100644
--- a/src/include/abti.h
+++ b/src/include/abti.h
@@ -415,7 +415,13 @@ struct ABTI_barrier {
 
 struct ABTI_xstream_barrier {
     uint32_t num_waiters;
+#ifdef HAVE_PTHREAD_BARRIER_INIT
     ABTD_xstream_barrier bar;
+#else
+    ABTI_spinlock lock;
+    uint32_t counter;
+    ABTD_atomic_uint64 tag;
+#endif
 };
 
 struct ABTI_timer {
diff --git a/src/include/abti_stream_barrier.h b/src/include/abti_stream_barrier.h
index 510786f..c792e59 100644
--- a/src/include/abti_stream_barrier.h
+++ b/src/include/abti_stream_barrier.h
@@ -6,7 +6,6 @@
 #ifndef ABTI_XSTREAM_BARRIER_H_INCLUDED
 #define ABTI_XSTREAM_BARRIER_H_INCLUDED
 
-#ifdef HAVE_PTHREAD_BARRIER_INIT
 static inline ABTI_xstream_barrier *
 ABTI_xstream_barrier_get_ptr(ABT_xstream_barrier barrier)
 {
@@ -38,6 +37,5 @@ ABTI_xstream_barrier_get_handle(ABTI_xstream_barrier *p_barrier)
     return (ABT_xstream_barrier)p_barrier;
 #endif
 }
-#endif
 
 #endif /* ABTI_XSTREAM_BARRIER_H_INCLUDED */
diff --git a/src/stream_barrier.c b/src/stream_barrier.c
index bc35a47..051e2ca 100644
--- a/src/stream_barrier.c
+++ b/src/stream_barrier.c
@@ -26,7 +26,6 @@
 int ABT_xstream_barrier_create(uint32_t num_waiters,
                                ABT_xstream_barrier *newbarrier)
 {
-#ifdef HAVE_PTHREAD_BARRIER_INIT
     int abt_errno;
     ABTI_xstream_barrier *p_newbarrier;
 
@@ -35,18 +34,21 @@ int ABT_xstream_barrier_create(uint32_t num_waiters,
     ABTI_CHECK_ERROR(abt_errno);
 
     p_newbarrier->num_waiters = num_waiters;
+#ifdef HAVE_PTHREAD_BARRIER_INIT
     abt_errno = ABTD_xstream_barrier_init(num_waiters, &p_newbarrier->bar);
     if (ABTI_IS_ERROR_CHECK_ENABLED && abt_errno != ABT_SUCCESS) {
         ABTU_free(p_newbarrier);
         ABTI_HANDLE_ERROR(abt_errno);
     }
+#else
+    ABTI_spinlock_clear(&p_newbarrier->lock);
+    p_newbarrier->counter = 0;
+    ABTD_atomic_relaxed_store_uint64(&p_newbarrier->tag, 0);
+#endif
 
     /* Return value */
     *newbarrier = ABTI_xstream_barrier_get_handle(p_newbarrier);
     return ABT_SUCCESS;
-#else
-    ABTI_HANDLE_ERROR(ABT_ERR_FEATURE_NA);
-#endif
 }
 
 /**
@@ -63,20 +65,18 @@ int ABT_xstream_barrier_create(uint32_t num_waiters,
  */
 int ABT_xstream_barrier_free(ABT_xstream_barrier *barrier)
 {
-#ifdef HAVE_PTHREAD_BARRIER_INIT
     ABT_xstream_barrier h_barrier = *barrier;
     ABTI_xstream_barrier *p_barrier = ABTI_xstream_barrier_get_ptr(h_barrier);
     ABTI_CHECK_NULL_XSTREAM_BARRIER_PTR(p_barrier);
 
+#ifdef HAVE_PTHREAD_BARRIER_INIT
     ABTD_xstream_barrier_destroy(&p_barrier->bar);
+#endif
     ABTU_free(p_barrier);
 
     /* Return value */
     *barrier = ABT_XSTREAM_BARRIER_NULL;
     return ABT_SUCCESS;
-#else
-    ABTI_HANDLE_ERROR(ABT_ERR_FEATURE_NA);
-#endif
 }
 
 /**
@@ -92,15 +92,35 @@ int ABT_xstream_barrier_free(ABT_xstream_barrier *barrier)
  */
 int ABT_xstream_barrier_wait(ABT_xstream_barrier barrier)
 {
-#ifdef HAVE_PTHREAD_BARRIER_INIT
     ABTI_xstream_barrier *p_barrier = ABTI_xstream_barrier_get_ptr(barrier);
     ABTI_CHECK_NULL_XSTREAM_BARRIER_PTR(p_barrier);
 
     if (p_barrier->num_waiters > 1) {
+#ifdef HAVE_PTHREAD_BARRIER_INIT
         ABTD_xstream_barrier_wait(&p_barrier->bar);
-    }
-    return ABT_SUCCESS;
 #else
-    ABTI_HANDLE_ERROR(ABT_ERR_FEATURE_NA);
+        /* The following implementation is a simple sense-reversal barrier
+         * implementation while it uses uint64_t instead of boolean to prevent
+         * a sense variable from wrapping around. */
+        ABTI_spinlock_acquire(&p_barrier->lock);
+        p_barrier->counter++;
+        if (p_barrier->counter == p_barrier->num_waiters) {
+            /* Wake up the other waiters. */
+            p_barrier->counter = 0;
+            /* Updating tag wakes up other waiters.  Note that this tag is
+             * sufficiently large, so it will not wrap around. */
+            uint64_t cur_tag = ABTD_atomic_relaxed_load_uint64(&p_barrier->tag);
+            uint64_t new_tag = (cur_tag + 1) & (UINT64_MAX >> 1);
+            ABTD_atomic_release_store_uint64(&p_barrier->tag, new_tag);
+            ABTI_spinlock_release(&p_barrier->lock);
+        } else {
+            /* Wait until the tag is updated by the last waiter */
+            uint64_t cur_tag = ABTD_atomic_relaxed_load_uint64(&p_barrier->tag);
+            ABTI_spinlock_release(&p_barrier->lock);
+            while (cur_tag == ABTD_atomic_acquire_load_uint64(&p_barrier->tag))
+                ABTD_atomic_pause();
+        }
 #endif
+    }
+    return ABT_SUCCESS;
 }
-- 
2.21.0 (Apple Git-122.2)


From 55ca5c7ad6c9d1092cefce6f31d871776c60ed4b Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Mon, 7 Dec 2020 15:03:13 -0600
Subject: [PATCH 33/40] configure: accept libunwind/stack-unwind settings

This patch implements configuration options that enable the stack unwinding
feature, which is implemented in the next commit.  This feature requires
libunwind, so --with-libunwind is also added.
---
 configure.ac         | 27 +++++++++++++++++++++++++++
 src/include/abt.h.in |  2 ++
 src/info.c           | 11 +++++++++++
 3 files changed, 40 insertions(+)

diff --git a/configure.ac b/configure.ac
index ab324aa..6252c5c 100644
--- a/configure.ac
+++ b/configure.ac
@@ -222,6 +222,16 @@ AC_ARG_WITH([hugetlbfs],
     AS_HELP_STRING([--with-hugetlbfs=PATH],
         [specify path where hugetlbfs include directory and lib directory can be found]))
 
+# --with-libunwind
+AC_ARG_WITH([libunwind],
+    AS_HELP_STRING([--with-libunwind=PATH],
+        [specify path where libunwind include directory and lib directory can be found]))
+
+# --enable-stack-unwind
+AC_ARG_ENABLE([stack-unwind],
+    AS_HELP_STRING([--enable-stack-unwind],
+                   [enable stack unwinding, which is disabled by default.]))
+
 # --with-papi
 AC_ARG_WITH([papi],
     AS_HELP_STRING([--with-papi=PATH],
@@ -730,6 +740,23 @@ if test "x$with_hugetlbfs" != "x"; then
     AC_CHECK_LIB(hugetlbfs, get_huge_pages)
 fi
 
+# --enable-stack-unwind
+if test "x$enable_stack_unwind" = "xyes"; then
+    # --with-libunwind
+    if test "x$with_libunwind" != "x"; then
+        PAC_PREPEND_FLAG([-I${with_libunwind}/include], [CFLAGS])
+        PAC_PREPEND_FLAG([-Wl,-rpath,${with_libunwind}/lib -L${with_libunwind}/lib], [LDFLAGS])
+    fi
+    AC_CHECK_HEADERS(libunwind.h)
+    AC_CHECK_LIB(unwind, unw_backtrace)
+    if test x"$ac_cv_header_libunwind_h" = x"yes" -a x"$ac_cv_lib_unwind_unw_backtrace" = x"yes" ; then
+        AC_DEFINE(ABT_CONFIG_ENABLE_STACK_UNWIND, 1, [Define to use the stack unwinding feature.])
+        PAC_PREPEND_FLAG([-lunwind], [LDFLAGS])
+    else
+        AC_MSG_ERROR([libunwind is not found.  Either remove --enable-stack-unwind or \
+set --with-libunwind=LIBUNWIND_PREFIX_PATH.])
+    fi
+fi
 
 # --with-papi
 PAPI_CFLAGS=""
diff --git a/src/include/abt.h.in b/src/include/abt.h.in
index d4385fc..02910cb 100644
--- a/src/include/abt.h.in
+++ b/src/include/abt.h.in
@@ -226,6 +226,8 @@ enum ABT_info_query_kind {
     ABT_INFO_QUERY_KIND_FCONTEXT,
     /* Whether dynamic promotion is used for context switch or not */
     ABT_INFO_QUERY_KIND_DYNAMIC_PROMOTION,
+    /* Whether the stack unwinding feature is enabled or not */
+    ABT_INFO_QUERY_KIND_ENABLED_STACK_UNWIND,
 };
 
 enum ABT_tool_query_kind {
diff --git a/src/info.c b/src/info.c
index 7dea04e..46fa8e0 100644
--- a/src/info.c
+++ b/src/info.c
@@ -111,6 +111,10 @@ static void info_trigger_print_all_thread_stacks(
  * - ABT_INFO_QUERY_KIND_DYNAMIC_PROMOTION
  *   \c val must be a pointer to a variable of the type ABT_bool.  ABT_TRUE is
  *   set to \c *val if dynamic promotion is used.  Otherwise, ABT_FALSE is set.
+ * - ABT_INFO_QUERY_KIND_ENABLED_STACK_UNWIND
+ *   \c val must be a pointer to a variable of the type ABT_bool.  ABT_TRUE is
+ *   set to \c *val if the stack unwinding feature is enabled.  Otherwise,
+ *   ABT_FALSE is set.
  *
  * @param[in]  query_kind  query kind
  * @param[out] val         a pointer to a result
@@ -250,6 +254,13 @@ int ABT_info_query_config(ABT_info_query_kind query_kind, void *val)
             *((ABT_bool *)val) = ABT_TRUE;
 #else
             *((ABT_bool *)val) = ABT_FALSE;
+#endif
+            break;
+        case ABT_INFO_QUERY_KIND_ENABLED_STACK_UNWIND:
+#ifdef ABT_CONFIG_ENABLE_STACK_UNWIND
+            *((ABT_bool *)val) = ABT_TRUE;
+#else
+            *((ABT_bool *)val) = ABT_FALSE;
 #endif
             break;
         default:
-- 
2.21.0 (Apple Git-122.2)


From e9c1abe7d4bfa8ef9f82d95090c345d85e04b51e Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Mon, 7 Dec 2020 15:03:42 -0600
Subject: [PATCH 34/40] thread: implement a stack unwinding feature

This patch implements a stack unwinding feature, which should be useful for
debugging.  When the stack unwinding feature is enabled,
ABT_info_print_thread_stack() and ABT_info_trigger_print_all_thread_stacks()
print call stacks of ready threads as well as raw stacks.

This stack unwinding feature is specially optimized for x86/64 + fcontext.  On
the other architectures / contexts, enabling this option (disabled by default)
slightly increases the threading overheads.  The optimized version will be
implemented in the future.
---
 src/arch/fcontext/jump_x86_64_sysv_elf_gas.S | 20 +++++
 src/include/abtd_context.h                   | 21 ++---
 src/include/abtd_fcontext.h                  | 87 ++++++++++++++++++++
 src/include/abtd_ucontext.h                  | 58 +++++++++++++
 src/include/abti_ythread.h                   | 15 ++++
 src/info.c                                   |  5 --
 src/ythread.c                                | 78 ++++++++++++++++++
 7 files changed, 269 insertions(+), 15 deletions(-)

diff --git a/src/arch/fcontext/jump_x86_64_sysv_elf_gas.S b/src/arch/fcontext/jump_x86_64_sysv_elf_gas.S
index 3c8a2ac..e12b702 100644
--- a/src/arch/fcontext/jump_x86_64_sysv_elf_gas.S
+++ b/src/arch/fcontext/jump_x86_64_sysv_elf_gas.S
@@ -133,6 +133,26 @@ init_and_call_fcontext:
 .size init_and_call_fcontext,.-init_and_call_fcontext
 #endif
 
+.text
+.globl peek_fcontext
+.type peek_fcontext,@function
+.align 16
+peek_fcontext:
+    /* temporarily move RSP (pointing to context-data) to R12 (callee-saved) */
+    pushq  %r12
+    movq   %rsp, %r12
+    /* restore RSP (pointing to context-data) from RDI */
+    movq   %rdi, %rsp
+    /* RSP is already 16-byte aligned, so we can call a peek funciton here
+     * rsi(rdx) => second_arg(third_arg) */
+    movq   %rdx, %rdi
+    callq *%rsi
+    /* restore callee-saved registers. */
+    movq   %r12, %rsp
+    popq   %r12
+    ret
+.size peek_fcontext,.-peek_fcontext
+
 /* Mark that we don't need executable stack.  */
 #ifndef __SUNPRO_C
 .section .note.GNU-stack,"",%progbits
diff --git a/src/include/abtd_context.h b/src/include/abtd_context.h
index 32a3b38..f598c8f 100644
--- a/src/include/abtd_context.h
+++ b/src/include/abtd_context.h
@@ -15,6 +15,11 @@
 #include <ucontext.h>
 #endif
 
+#ifdef ABT_CONFIG_ENABLE_STACK_UNWIND
+/* Peek context is needed only for stack unwinding. */
+#define ABT_CONFIG_ENABLE_PEEK_CONTEXT
+#endif
+
 typedef struct ABTD_ythread_context ABTD_ythread_context;
 
 typedef struct ABTD_ythread_context_atomic_ptr {
@@ -47,16 +52,7 @@ static inline void ABTD_atomic_release_store_ythread_context_ptr(
     ABTD_atomic_release_store_ptr(&ptr->val, (void *)p_ctx);
 }
 
-struct ABTD_ythread_context {
-    void *p_ctx;                            /* actual context of fcontext, or a
-                                             * pointer to uctx */
-    ABTD_ythread_context_atomic_ptr p_link; /* pointer to scheduler context */
-#ifndef ABT_CONFIG_USE_FCONTEXT
-    ucontext_t uctx;               /* ucontext entity pointed by p_ctx */
-    void (*f_uctx_thread)(void *); /* root function called by ucontext */
-    void *p_uctx_arg;              /* argument for root function */
-#endif
-};
+struct ABTD_ythread_context;
 
 static void ABTD_ythread_context_make(ABTD_ythread_context *p_ctx, void *sp,
                                       size_t size, void (*thread_func)(void *));
@@ -71,6 +67,11 @@ static void ABTD_ythread_context_init_and_call(ABTD_ythread_context *p_ctx,
                                                void (*thread_func)(void *),
                                                void *arg);
 #endif
+#ifdef ABT_CONFIG_ENABLE_PEEK_CONTEXT
+static inline void ABTD_ythread_context_peek(ABTD_ythread_context *p_ctx,
+                                             void (*peek_func)(void *),
+                                             void *arg);
+#endif
 
 void ABTD_ythread_print_context(ABTI_ythread *p_ythread, FILE *p_os,
                                 int indent);
diff --git a/src/include/abtd_fcontext.h b/src/include/abtd_fcontext.h
index ba48a89..3787620 100644
--- a/src/include/abtd_fcontext.h
+++ b/src/include/abtd_fcontext.h
@@ -23,25 +23,89 @@ void init_and_call_fcontext(void *p_arg, void (*f_thread)(void *),
                             void *p_stacktop, fcontext_t *old);
 #endif
 
+#if defined(ABT_CONFIG_ENABLE_PEEK_CONTEXT) && defined(__x86_64__)
+/* We implement peek_fcontext only for x86-64. */
+void peek_fcontext(fcontext_t new, void (*peek_func)(void *),
+                   void *arg) ABT_API_PRIVATE;
+#define ABTD_SUPPORT_PEEK_FCONTEXT 1
+#endif /* defined(ABT_CONFIG_ENABLE_PEEK_CONTEXT) && defined(__x86_64__) */
+
+struct ABTD_ythread_context {
+    void *p_ctx;                            /* actual context of fcontext, or a
+                                             * pointer to uctx */
+    ABTD_ythread_context_atomic_ptr p_link; /* pointer to scheduler context */
+#if defined(ABT_CONFIG_ENABLE_PEEK_CONTEXT) &&                                 \
+    !defined(ABTD_CONTEXT_SUPPORT_PEEK_FCONTEXT)
+    void (*thread_func)(void *);
+    void *arg;
+    void (*peek_func)(void *);
+    void *peek_arg;
+    void *p_peek_ctx;
+    ABT_bool is_peeked;
+#endif
+};
+
+#if defined(ABT_CONFIG_ENABLE_PEEK_CONTEXT) &&                                 \
+    !defined(ABTD_CONTEXT_SUPPORT_PEEK_FCONTEXT)
+static inline void ABTDI_fcontext_check_peeked(ABTD_ythread_context *p_self)
+{
+    /* Check if this thread is called only for peeked */
+    while (ABTU_unlikely(p_self->is_peeked)) {
+        p_self->peek_func(p_self->peek_arg);
+        /* Reset the flag. */
+        p_self->is_peeked = ABT_FALSE;
+        jump_fcontext(&p_self->p_ctx, p_self->p_peek_ctx, NULL);
+    }
+}
+
+static inline void ABTDI_fcontext_wrapper(void *arg)
+{
+    ABTD_ythread_context *p_self = (ABTD_ythread_context *)arg;
+    ABTDI_fcontext_check_peeked(p_self);
+    p_self->thread_func(p_self->arg);
+}
+#endif
+
 static inline void ABTD_ythread_context_make(ABTD_ythread_context *p_ctx,
                                              void *sp, size_t size,
                                              void (*thread_func)(void *))
 {
+#if defined(ABT_CONFIG_ENABLE_PEEK_CONTEXT) &&                                 \
+    !defined(ABTD_CONTEXT_SUPPORT_PEEK_FCONTEXT)
+    p_ctx->thread_func = thread_func;
+    p_ctx->is_peeked = ABT_FALSE;
+    p_ctx->p_ctx = make_fcontext(sp, size, ABTDI_fcontext_wrapper);
+#else
     p_ctx->p_ctx = make_fcontext(sp, size, thread_func);
+#endif
 }
 
 static inline void ABTD_ythread_context_jump(ABTD_ythread_context *p_old,
                                              ABTD_ythread_context *p_new,
                                              void *arg)
 {
+#if defined(ABT_CONFIG_ENABLE_PEEK_CONTEXT) &&                                 \
+    !defined(ABTD_CONTEXT_SUPPORT_PEEK_FCONTEXT)
+    p_new->arg = arg;
+    p_old->is_peeked = ABT_FALSE;
+    jump_fcontext(&p_old->p_ctx, p_new->p_ctx, p_new);
+    ABTDI_fcontext_check_peeked(p_old);
+#else
     jump_fcontext(&p_old->p_ctx, p_new->p_ctx, arg);
+#endif
 }
 
 ABTU_noreturn static inline void
 ABTD_ythread_context_take(ABTD_ythread_context *p_old,
                           ABTD_ythread_context *p_new, void *arg)
 {
+#if defined(ABT_CONFIG_ENABLE_PEEK_CONTEXT) &&                                 \
+    !defined(ABTD_CONTEXT_SUPPORT_PEEK_FCONTEXT)
+    p_new->arg = arg;
+    take_fcontext(&p_old->p_ctx, p_new->p_ctx, p_new);
+#else
     take_fcontext(&p_old->p_ctx, p_new->p_ctx, arg);
+#endif
     ABTU_unreachable();
 }
 
@@ -50,8 +114,31 @@ static inline void
 ABTD_ythread_context_init_and_call(ABTD_ythread_context *p_ctx, void *sp,
                                    void (*thread_func)(void *), void *arg)
 {
+#if defined(ABT_CONFIG_ENABLE_PEEK_CONTEXT) &&                                 \
+    !defined(ABTD_CONTEXT_SUPPORT_PEEK_FCONTEXT)
+    p_ctx->is_peeked = ABT_FALSE;
     init_and_call_fcontext(arg, thread_func, sp, &p_ctx->p_ctx);
+    ABTDI_fcontext_check_peeked(p_ctx);
+#else
+    init_and_call_fcontext(arg, thread_func, sp, &p_ctx->p_ctx);
+#endif
 }
 #endif
 
+#ifdef ABT_CONFIG_ENABLE_PEEK_CONTEXT
+static inline void ABTD_ythread_context_peek(ABTD_ythread_context *p_ctx,
+                                             void (*peek_func)(void *),
+                                             void *arg)
+{
+#ifdef ABTD_CONTEXT_SUPPORT_PEEK_FCONTEXT
+    peek_fcontext(p_ctx->p_ctx, peek_func, *arg);
+#else
+    p_ctx->peek_arg = arg;
+    p_ctx->peek_func = peek_func;
+    p_ctx->is_peeked = ABT_TRUE;
+    jump_fcontext(&p_ctx->p_peek_ctx, p_ctx->p_ctx, p_ctx);
+#endif
+}
+#endif /*!ABT_CONFIG_ENABLE_PEEK_CONTEXT */
+
 #endif /* ABTD_FCONTEXT_H_INCLUDED */
diff --git a/src/include/abtd_ucontext.h b/src/include/abtd_ucontext.h
index 4e1646d..e36edc4 100644
--- a/src/include/abtd_ucontext.h
+++ b/src/include/abtd_ucontext.h
@@ -6,6 +6,35 @@
 #ifndef ABTD_UCONTEXT_H_INCLUDED
 #define ABTD_UCONTEXT_H_INCLUDED
 
+struct ABTD_ythread_context {
+    void *p_ctx;                            /* actual context of fcontext, or a
+                                             * pointer to uctx */
+    ABTD_ythread_context_atomic_ptr p_link; /* pointer to scheduler context */
+    ucontext_t uctx;               /* ucontext entity pointed by p_ctx */
+    void (*f_uctx_thread)(void *); /* root function called by ucontext */
+    void *p_uctx_arg;              /* argument for root function */
+#ifdef ABT_CONFIG_ENABLE_PEEK_CONTEXT
+    void (*peek_func)(void *);
+    void *peek_arg;
+    ucontext_t *p_peek_uctx;
+    ABT_bool is_peeked;
+#endif
+};
+
+#ifdef ABT_CONFIG_ENABLE_PEEK_CONTEXT
+static inline void ABTDI_ucontext_check_peeked(ABTD_ythread_context *p_self)
+{
+    /* Check if this thread is called only for peeked */
+    while (ABTU_unlikely(p_self->is_peeked)) {
+        p_self->peek_func(p_self->peek_arg);
+        /* Reset the flag. */
+        p_self->is_peeked = ABT_FALSE;
+        int ret = swapcontext(&p_self->uctx, p_self->p_peek_uctx);
+        ABTI_ASSERT(ret == 0); /* Fatal. */
+    }
+}
+#endif
+
 static void ABTD_ucontext_wrapper(int arg1, int arg2)
 {
     ABTD_ythread_context *p_self;
@@ -17,6 +46,11 @@ static void ABTD_ucontext_wrapper(int arg1, int arg2)
 #else
 #error "Unknown pointer size."
 #endif
+
+#ifdef ABT_CONFIG_ENABLE_PEEK_CONTEXT
+    ABTDI_ucontext_check_peeked(p_self);
+#endif
+
     p_self->f_uctx_thread(p_self->p_uctx_arg);
     /* ABTD_ythread_context_jump or take must be called at the end of
      * f_uctx_thread, */
@@ -49,16 +83,25 @@ static inline void ABTD_ythread_context_make(ABTD_ythread_context *p_ctx,
 #else
 #error "Unknown pointer size."
 #endif
+#ifdef ABT_CONFIG_ENABLE_PEEK_CONTEXT
+    p_ctx->is_peeked = ABT_FALSE;
+#endif
 }
 
 static inline void ABTD_ythread_context_jump(ABTD_ythread_context *p_old,
                                              ABTD_ythread_context *p_new,
                                              void *arg)
 {
+#ifdef ABT_CONFIG_ENABLE_PEEK_CONTEXT
+    p_old->is_peeked = ABT_FALSE;
+#endif
     p_new->p_uctx_arg = arg;
     int ret = swapcontext(&p_old->uctx, &p_new->uctx);
     /* Fatal.  This out-of-stack error is not recoverable. */
     ABTI_ASSERT(ret == 0);
+#ifdef ABT_CONFIG_ENABLE_PEEK_CONTEXT
+    ABTDI_ucontext_check_peeked(p_old);
+#endif
 }
 
 ABTU_noreturn static inline void
@@ -71,6 +114,21 @@ ABTD_ythread_context_take(ABTD_ythread_context *p_old,
     ABTU_unreachable();
 }
 
+#ifdef ABT_CONFIG_ENABLE_PEEK_CONTEXT
+static inline void ABTD_ythread_context_peek(ABTD_ythread_context *p_ctx,
+                                             void (*peek_func)(void *),
+                                             void *arg)
+{
+    ucontext_t self_uctx;
+    p_ctx->peek_arg = arg;
+    p_ctx->peek_func = peek_func;
+    p_ctx->p_peek_uctx = &self_uctx;
+    p_ctx->is_peeked = ABT_TRUE;
+    int ret = swapcontext(&self_uctx, &p_ctx->uctx);
+    ABTI_ASSERT(ret == 0);
+}
+#endif
+
 #if ABT_CONFIG_THREAD_TYPE == ABT_THREAD_TYPE_DYNAMIC_PROMOTION
 #error "ABTD_ythread_context_make_and_call is not implemented."
 #endif
diff --git a/src/include/abti_ythread.h b/src/include/abti_ythread.h
index d366992..a0b32cd 100644
--- a/src/include/abti_ythread.h
+++ b/src/include/abti_ythread.h
@@ -299,6 +299,21 @@ static inline ABTI_ythread *ABTI_ythread_context_switch_to_child_internal(
     }
 }
 
+#ifdef ABT_CONFIG_ENABLE_PEEK_CONTEXT
+static inline void ABTI_ythread_context_peek(ABTI_ythread *p_ythread,
+                                             void (*peek_func)(void *),
+                                             void *arg)
+{
+#if ABT_CONFIG_THREAD_TYPE == ABT_THREAD_TYPE_DYNAMIC_PROMOTION
+    if (!ABTI_ythread_is_dynamic_promoted(p_ythread)) {
+        ABTD_ythread_context_arm_ythread(p_ythread->stacksize,
+                                         p_ythread->p_stack, &p_ythread->ctx);
+    }
+#endif
+    ABTD_ythread_context_peek(&p_ythread->ctx, peek_func, arg);
+}
+#endif
+
 /* Return the previous thread. */
 static inline ABTI_ythread *
 ABTI_ythread_context_switch_to_sibling(ABTI_xstream **pp_local_xstream,
diff --git a/src/info.c b/src/info.c
index 46fa8e0..090525c 100644
--- a/src/info.c
+++ b/src/info.c
@@ -811,11 +811,6 @@ static void info_print_unit(void *arg, ABT_unit unit)
                 "id        : %" PRIu64 "\n"
                 "ctx       : %p\n",
                 (uint64_t)thread_id, (void *)&p_ythread->ctx);
-        ABTD_ythread_print_context(p_ythread, fp, 2);
-        fprintf(fp,
-                "stack     : %p\n"
-                "stacksize : %" PRIu64 "\n",
-                p_ythread->p_stack, (uint64_t)p_ythread->stacksize);
         ABTI_ythread_print_stack(p_ythread, fp);
     } else if (type == ABT_UNIT_TYPE_TASK) {
         fprintf(fp, "=== tasklet (%p) ===\n", (void *)unit);
diff --git a/src/ythread.c b/src/ythread.c
index 8528583..6aebbea 100644
--- a/src/ythread.c
+++ b/src/ythread.c
@@ -5,6 +5,21 @@
 
 #include "abti.h"
 
+#ifdef ABT_CONFIG_ENABLE_STACK_UNWIND
+
+#ifndef ABT_CONFIG_ENABLE_PEEK_CONTEXT
+#error "ABT_CONFIG_ENABLE_PEEK_CONTEXT must be enabled"
+#endif
+
+#define UNW_LOCAL_ONLY
+#include <libunwind.h>
+struct unwind_stack_t {
+    FILE *fp;
+};
+static void ythread_unwind_stack(void *arg);
+
+#endif
+
 void ABTI_ythread_set_blocked(ABTI_ythread *p_ythread)
 {
     /* The root thread cannot be blocked */
@@ -85,6 +100,18 @@ void ABTI_ythread_set_ready(ABTI_local *p_local, ABTI_ythread *p_ythread)
 ABTU_no_sanitize_address void ABTI_ythread_print_stack(ABTI_ythread *p_ythread,
                                                        FILE *p_os)
 {
+    ABTD_ythread_print_context(p_ythread, p_os, 0);
+    fprintf(p_os,
+            "stack     : %p\n"
+            "stacksize : %" PRIu64 "\n",
+            p_ythread->p_stack, (uint64_t)p_ythread->stacksize);
+
+#ifdef ABT_CONFIG_ENABLE_STACK_UNWIND
+    struct unwind_stack_t arg;
+    arg.fp = p_os;
+    ABTI_ythread_context_peek(p_ythread, ythread_unwind_stack, &arg);
+#endif
+
     void *p_stack = p_ythread->p_stack;
     size_t i, j, stacksize = p_ythread->stacksize;
     if (stacksize == 0 || p_stack == NULL) {
@@ -135,3 +162,54 @@ ABTU_no_sanitize_address void ABTI_ythread_print_stack(ABTI_ythread *p_ythread,
     }
     fflush(p_os);
 }
+
+#ifdef ABT_CONFIG_ENABLE_STACK_UNWIND
+ABTU_no_sanitize_address static int ythread_unwind_stack_impl(FILE *fp)
+{
+    unw_cursor_t cursor;
+    unw_context_t uc;
+    unw_word_t ip, sp;
+    int ret, level = -1;
+
+    ret = unw_getcontext(&uc);
+    if (ret != 0)
+        return ABT_ERR_OTHER;
+
+    ret = unw_init_local(&cursor, &uc);
+    if (ret != 0)
+        return ABT_ERR_OTHER;
+
+    while (unw_step(&cursor) > 0 && level < 50) {
+        level++;
+
+        ret = unw_get_reg(&cursor, UNW_REG_IP, &ip);
+        if (ret != 0)
+            return ABT_ERR_OTHER;
+
+        ret = unw_get_reg(&cursor, UNW_REG_SP, &sp);
+        if (ret != 0)
+            return ABT_ERR_OTHER;
+
+        char proc_name[256];
+        unw_word_t offset;
+        ret = unw_get_proc_name(&cursor, proc_name, 256, &offset);
+        if (ret != 0)
+            return ABT_ERR_OTHER;
+
+        /* Print function stack. */
+        fprintf(fp, "#%d %p in %s () <+%d> (%s = %p)\n", level,
+                (void *)((uintptr_t)ip), proc_name, (int)offset,
+                unw_regname(UNW_REG_SP), (void *)((uintptr_t)sp));
+    }
+    return ABT_SUCCESS;
+}
+
+static void ythread_unwind_stack(void *arg)
+{
+    struct unwind_stack_t *p_arg = (struct unwind_stack_t *)arg;
+    if (ythread_unwind_stack_impl(p_arg->fp) != ABT_SUCCESS) {
+        fprintf(p_arg->fp, "libunwind error\n");
+    }
+}
+
+#endif /* ABT_CONFIG_ENABLE_STACK_UNWIND */
-- 
2.21.0 (Apple Git-122.2)


From 3e7882d31f09ef06777997452bff0fb1af60157a Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Mon, 7 Dec 2020 15:04:03 -0600
Subject: [PATCH 35/40] test/basic: add a new test, info_print_stack

info_print_stack checks ABT_info_print_thread_stack().
---
 test/.gitignore               |   1 +
 test/basic/Makefile.am        |   3 +
 test/basic/info_print_stack.c | 178 ++++++++++++++++++++++++++++++++++
 3 files changed, 182 insertions(+)
 create mode 100644 test/basic/info_print_stack.c

diff --git a/test/.gitignore b/test/.gitignore
index 94f74b3..f7b4523 100644
--- a/test/.gitignore
+++ b/test/.gitignore
@@ -57,6 +57,7 @@ basic/ext_thread
 basic/ext_thread2
 basic/timer
 basic/info_print
+basic/info_print_stack
 basic/info_stackdump
 basic/info_stackdump2
 basic/error
diff --git a/test/basic/Makefile.am b/test/basic/Makefile.am
index 5500424..7ecc49b 100644
--- a/test/basic/Makefile.am
+++ b/test/basic/Makefile.am
@@ -62,6 +62,7 @@ TESTS = \
 	ext_thread2 \
 	timer \
 	info_print \
+	info_print_stack \
 	info_stackdump \
 	info_stackdump2 \
 	error
@@ -137,6 +138,7 @@ ext_thread_SOURCES = ext_thread.c
 ext_thread2_SOURCES = ext_thread2.c
 timer_SOURCES = timer.c
 info_print_SOURCES = info_print.c
+info_print_stack_SOURCES = info_print_stack.c
 info_stackdump_SOURCES = info_stackdump.c
 info_stackdump2_SOURCES = info_stackdump2.c
 error_SOURCES = error.c
@@ -200,6 +202,7 @@ testing:
 	./ext_thread2
 	./timer
 	./info_print
+	./info_print_stack
 	./info_stackdump
 	./info_stackdump2
 	./error
diff --git a/test/basic/info_print_stack.c b/test/basic/info_print_stack.c
new file mode 100644
index 0000000..6b5b5ea
--- /dev/null
+++ b/test/basic/info_print_stack.c
@@ -0,0 +1,178 @@
+/* -*- Mode: C; c-basic-offset:4 ; indent-tabs-mode:nil ; -*- */
+/*
+ * See COPYRIGHT in top-level directory.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <signal.h>
+#include "abt.h"
+#include "abttest.h"
+
+#define DEFAULT_NUM_THREADS 10
+
+volatile int g_go = 0;
+
+typedef struct thread_arg {
+    int id;
+    int level;
+    void *stack;
+} thread_arg_t;
+
+void user_thread_func_lv4(int level)
+{
+    while (g_go == 0) {
+        int ret = ABT_thread_yield();
+        ATS_ERROR(ret, "ABT_thread_yield");
+    }
+}
+
+void user_thread_func_lv3(int level)
+{
+    if (level == 0) {
+        while (g_go == 0) {
+            int ret = ABT_thread_yield();
+            ATS_ERROR(ret, "ABT_thread_yield");
+        }
+    } else {
+        user_thread_func_lv4(level - 1);
+    }
+    user_thread_func_lv4(level - 1);
+}
+
+void user_thread_func_lv2(int level)
+{
+    if (level == 0) {
+        while (g_go == 0) {
+            int ret = ABT_thread_yield();
+            ATS_ERROR(ret, "ABT_thread_yield");
+        }
+    } else {
+        user_thread_func_lv3(level - 1);
+    }
+    user_thread_func_lv3(level - 1);
+}
+
+void user_thread_func(void *arg)
+{
+    thread_arg_t *t_arg = (thread_arg_t *)arg;
+    int level = t_arg->level;
+    if (level == 0) {
+        while (g_go == 0) {
+            int ret = ABT_thread_yield();
+            ATS_ERROR(ret, "ABT_thread_yield");
+        }
+    } else {
+        user_thread_func_lv2(level - 1);
+    }
+    user_thread_func_lv2(level - 1);
+}
+
+static inline void create_thread(ABT_pool pool, ABT_thread *threads,
+                                 thread_arg_t *args, int i)
+{
+    int ret;
+    args[i].id = i;
+    args[i].level = i % 4;
+    args[i].stack = NULL;
+    if (i % 3 == 0) {
+        ret = ABT_thread_create(pool, user_thread_func, (void *)&args[i],
+                                ABT_THREAD_ATTR_NULL, &threads[i]);
+        ATS_ERROR(ret, "ABT_thread_create");
+    } else if (i % 3 == 1) {
+        ABT_thread_attr attr;
+        ret = ABT_thread_attr_create(&attr);
+        ATS_ERROR(ret, "ABT_thread_attr_create");
+        ret = ABT_thread_attr_set_stacksize(attr, 32768);
+        ATS_ERROR(ret, "ABT_thread_attr_set_stacksize");
+        ret = ABT_thread_create(pool, user_thread_func, (void *)&args[i], attr,
+                                &threads[i]);
+        ATS_ERROR(ret, "ABT_thread_create");
+        ret = ABT_thread_attr_free(&attr);
+        ATS_ERROR(ret, "ABT_thread_attr_free");
+    } else {
+        const size_t stacksize = 32768;
+        args[i].stack = malloc(stacksize);
+        ABT_thread_attr attr;
+        ret = ABT_thread_attr_create(&attr);
+        ATS_ERROR(ret, "ABT_thread_attr_create");
+        ret = ABT_thread_attr_set_stack(attr, args[i].stack, stacksize);
+        ATS_ERROR(ret, "ABT_thread_attr_set_stack");
+        ret = ABT_thread_create(pool, user_thread_func, (void *)&args[i], attr,
+                                &threads[i]);
+        ATS_ERROR(ret, "ABT_thread_create");
+        ret = ABT_thread_attr_free(&attr);
+        ATS_ERROR(ret, "ABT_thread_attr_free");
+    }
+}
+
+int main(int argc, char *argv[])
+{
+    int i;
+    int ret;
+    int num_threads = DEFAULT_NUM_THREADS;
+
+    /* Initialize */
+    ATS_read_args(argc, argv);
+    if (argc >= 2) {
+        num_threads = ATS_get_arg_val(ATS_ARG_N_ULT);
+    }
+    ATS_init(argc, argv, 1);
+
+    ATS_printf(2, "# of ESs : 1\n");
+    ATS_printf(1, "# of ULTs: %d\n", num_threads);
+
+    ABT_xstream xstream;
+    ABT_thread *threads =
+        (ABT_thread *)malloc(sizeof(ABT_thread) * num_threads);
+    thread_arg_t *args =
+        (thread_arg_t *)malloc(sizeof(thread_arg_t) * num_threads);
+
+    /* Create execution streams */
+    ret = ABT_xstream_self(&xstream);
+    ATS_ERROR(ret, "ABT_xstream_self");
+
+    /* Get the pools attached to an execution stream */
+    ABT_pool pool;
+    ret = ABT_xstream_get_main_pools(xstream, 1, &pool);
+    ATS_ERROR(ret, "ABT_xstream_get_main_pools");
+
+    /* Create the first (num_threads - 4) threads, which will be executed. */
+    for (i = 0; i < num_threads - 4; i++)
+        create_thread(pool, threads, args, i);
+
+    /* Execute some of the threads. */
+    ret = ABT_thread_yield();
+    ATS_ERROR(ret, "ABT_thread_yield");
+
+    /* Create the last four threads, which are not executed. */
+    for (i = num_threads - 4; i < num_threads; i++)
+        create_thread(pool, threads, args, i);
+
+    /* Print unwinded stacks. */
+    for (i = 0; i < num_threads; i++) {
+        printf("threads[%d]:\n", i);
+        ret = ABT_info_print_thread_stack(stdout, threads[i]);
+        ATS_ERROR(ret, "ABT_info_print_thread_stack");
+        printf("\n");
+    }
+    g_go = 1;
+
+    /* Join and free ULTs */
+    for (i = 0; i < num_threads; i++) {
+        ret = ABT_thread_free(&threads[i]);
+        ATS_ERROR(ret, "ABT_thread_free");
+    }
+
+    /* Finalize */
+    ret = ATS_finalize(0);
+
+    for (i = 0; i < num_threads; i++) {
+        if (args[i].stack)
+            free(args[i].stack);
+    }
+    free(threads);
+    free(args);
+
+    return ret;
+}
-- 
2.21.0 (Apple Git-122.2)


From 8ef8c5dce8b090ca7194cf14bdaba9e908dbc8d0 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Mon, 7 Dec 2020 15:04:46 -0600
Subject: [PATCH 36/40] ythread: check if a target ULT is running in
 ABTI_ythread_print_stack

When the stack unwinding feature is enabled, calling ABTI_ythread_print_stack()
against a running ULT causes a catastrophic error.  Although this check is
incomplete, this patch adds a quick flag check to avoid such a case.
---
 src/ythread.c | 15 ++++++++++++---
 1 file changed, 12 insertions(+), 3 deletions(-)

diff --git a/src/ythread.c b/src/ythread.c
index 6aebbea..9fdba7d 100644
--- a/src/ythread.c
+++ b/src/ythread.c
@@ -107,9 +107,18 @@ ABTU_no_sanitize_address void ABTI_ythread_print_stack(ABTI_ythread *p_ythread,
             p_ythread->p_stack, (uint64_t)p_ythread->stacksize);
 
 #ifdef ABT_CONFIG_ENABLE_STACK_UNWIND
-    struct unwind_stack_t arg;
-    arg.fp = p_os;
-    ABTI_ythread_context_peek(p_ythread, ythread_unwind_stack, &arg);
+    {
+        /* Peeking a running context is specially forbidden.  Though it is
+         * incomplete, let's quickly check if a thread is running. */
+        ABT_thread_state state = (ABT_thread_state)ABTD_atomic_acquire_load_int(
+            &p_ythread->thread.state);
+        if (state == ABT_THREAD_STATE_READY ||
+            state == ABT_THREAD_STATE_BLOCKED) {
+            struct unwind_stack_t arg;
+            arg.fp = p_os;
+            ABTI_ythread_context_peek(p_ythread, ythread_unwind_stack, &arg);
+        }
+    }
 #endif
 
     void *p_stack = p_ythread->p_stack;
-- 
2.21.0 (Apple Git-122.2)


From 1362d92be612bbf54d57f0c849e074a435e9f97e Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Mon, 7 Dec 2020 15:07:44 -0600
Subject: [PATCH 37/40] info: fix the place of fflush to ensure all messages
 are printed

fflush() should be called before calling the call-back function.
---
 src/info.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/src/info.c b/src/info.c
index 090525c..a83099e 100644
--- a/src/info.c
+++ b/src/info.c
@@ -600,11 +600,11 @@ void ABTI_info_check_print_all_thread_stacks(void)
             fprintf(print_stack_fp, "ABT_info_trigger_print_all_thread_stacks: "
                                     "failed because of an internal error.\n");
         }
+        fflush(print_stack_fp);
         /* Release the lock that protects ES data. */
         ABTI_spinlock_release(&gp_ABTI_global->xstream_list_lock);
         if (print_cb_func)
             print_cb_func(force_print, print_arg);
-        fflush(print_stack_fp);
         /* Update print_stack_flag to 3. */
         ABTD_atomic_release_store_int(&print_stack_flag,
                                       PRINT_STACK_FLAG_FINALIZE);
-- 
2.21.0 (Apple Git-122.2)


From 6ca23e95264c8ccb7b22d4c63985f7b78192500c Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Tue, 8 Dec 2020 09:50:00 -0600
Subject: [PATCH 38/40] future: call a callback function before making a future
 ready

ABT_future_test() could succeed before calling a callback function.  This patch
guarantees that a callback function is called before a future gets ready.
---
 src/futures.c | 12 ++++++++----
 1 file changed, 8 insertions(+), 4 deletions(-)

diff --git a/src/futures.c b/src/futures.c
index bebe657..d408b06 100644
--- a/src/futures.c
+++ b/src/futures.c
@@ -189,19 +189,23 @@ int ABT_future_set(ABT_future future, void *value)
     ABTI_spinlock_acquire(&p_future->lock);
 
     size_t counter = ABTD_atomic_relaxed_load_size(&p_future->counter);
+    size_t compartments = p_future->compartments;
 #ifndef ABT_CONFIG_DISABLE_ERROR_CHECK
-    if (counter >= p_future->compartments) {
+    if (counter >= compartments) {
         ABTI_spinlock_release(&p_future->lock);
         ABTI_HANDLE_ERROR(ABT_ERR_FUTURE);
     }
 #endif
     p_future->array[counter] = value;
     counter++;
+    /* Call a callback function before setting the counter. */
+    if (counter == compartments && p_future->p_callback != NULL) {
+        (*p_future->p_callback)(p_future->array);
+    }
+
     ABTD_atomic_release_store_size(&p_future->counter, counter);
 
-    if (counter == p_future->compartments) {
-        if (p_future->p_callback != NULL)
-            (*p_future->p_callback)(p_future->array);
+    if (counter == compartments) {
         ABTI_waitlist_broadcast(p_local, &p_future->waitlist);
     }
 
-- 
2.21.0 (Apple Git-122.2)


From 4896142fef9d2a1602eb4c34be55f024f65647ea Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Tue, 8 Dec 2020 11:03:14 -0600
Subject: [PATCH 39/40] thread_attr: fix ABT_thread_attr_set_stacksize

ABT_thread_attr_set_stacksize() set a wrong thread_type, so all ULTs used a
predefined stacksize regardless of stacksize.  This patch fixes it by
implementing thread_attr_set_stack() and isolating complicated thread_type
management.
---
 src/thread_attr.c | 75 +++++++++++++++++++++++++++--------------------
 1 file changed, 43 insertions(+), 32 deletions(-)

diff --git a/src/thread_attr.c b/src/thread_attr.c
index cf2d7d0..6320864 100644
--- a/src/thread_attr.c
+++ b/src/thread_attr.c
@@ -5,6 +5,9 @@
 
 #include "abti.h"
 
+static void thread_attr_set_stack(ABTI_thread_attr *p_attr, void *stackaddr,
+                                  size_t stacksize);
+
 /** @defgroup ULT_ATTR ULT Attributes
  * Attributes are used to specify ULT behavior that is different from the
  * default. When a ULT is created with \c ABT_thread_create(), attributes
@@ -86,26 +89,10 @@ int ABT_thread_attr_set_stack(ABT_thread_attr attr, void *stackaddr,
 {
     ABTI_thread_attr *p_attr = ABTI_thread_attr_get_ptr(attr);
     ABTI_CHECK_NULL_THREAD_ATTR_PTR(p_attr);
-
-    ABTI_thread_type new_thread_type;
-    if (stackaddr != NULL) {
-        if (((uintptr_t)stackaddr & 0x7) != 0) {
-            ABTI_HANDLE_ERROR(ABT_ERR_OTHER);
-        }
-        new_thread_type = ABTI_THREAD_TYPE_MEM_MEMPOOL_DESC;
-    } else {
-        if (stacksize == gp_ABTI_global->thread_stacksize) {
-            new_thread_type = ABTI_THREAD_TYPE_MEM_MEMPOOL_DESC_STACK;
-        } else {
-            new_thread_type = ABTI_THREAD_TYPE_MEM_MALLOC_DESC_STACK;
-        }
-    }
-    /* Unset the stack type and set new_thread_type. */
-    p_attr->thread_type &= ~ABTI_THREAD_TYPES_MEM;
-    p_attr->thread_type |= new_thread_type;
-
-    p_attr->p_stack = stackaddr;
-    p_attr->stacksize = stacksize;
+    /* If stackaddr is not NULL, it must be aligned by 8 bytes. */
+    ABTI_CHECK_TRUE(stackaddr == NULL || ((uintptr_t)stackaddr & 0x7) == 0,
+                    ABT_ERR_OTHER);
+    thread_attr_set_stack(p_attr, stackaddr, stacksize);
     return ABT_SUCCESS;
 }
 
@@ -152,18 +139,7 @@ int ABT_thread_attr_set_stacksize(ABT_thread_attr attr, size_t stacksize)
 {
     ABTI_thread_attr *p_attr = ABTI_thread_attr_get_ptr(attr);
     ABTI_CHECK_NULL_THREAD_ATTR_PTR(p_attr);
-
-    /* Set the value */
-    p_attr->stacksize = stacksize;
-    ABTI_thread_type new_thread_type;
-    if (stacksize == gp_ABTI_global->thread_stacksize) {
-        new_thread_type = ABTI_THREAD_TYPE_MEM_MEMPOOL_DESC_STACK;
-    } else {
-        new_thread_type = ABTI_THREAD_TYPE_MEM_MEMPOOL_DESC_STACK;
-    }
-    /* Unset the stack type and set new_thread_type. */
-    p_attr->thread_type &= ~ABTI_THREAD_TYPES_MEM;
-    p_attr->thread_type |= new_thread_type;
+    thread_attr_set_stack(p_attr, p_attr->p_stack, stacksize);
     return ABT_SUCCESS;
 }
 
@@ -308,3 +284,38 @@ ABTU_ret_err int ABTI_thread_attr_dup(const ABTI_thread_attr *p_attr,
     *pp_dup_attr = p_dup_attr;
     return ABT_SUCCESS;
 }
+
+/*****************************************************************************/
+/* Internal static functions                                                 */
+/*****************************************************************************/
+
+static void thread_attr_set_stack(ABTI_thread_attr *p_attr, void *stackaddr,
+                                  size_t stacksize)
+{
+    /* Get the best thread type. */
+    ABTI_thread_type new_thread_type;
+    if (stackaddr != NULL) {
+        /* This check must be done by the caller. */
+        ABTI_ASSERT(((uintptr_t)stackaddr & 0x7) == 0);
+        /* Only a descriptor will be allocated from a memory pool.  A stack
+         * is given by the user. */
+        new_thread_type = ABTI_THREAD_TYPE_MEM_MEMPOOL_DESC;
+    } else {
+        if (stacksize == gp_ABTI_global->thread_stacksize) {
+            /* Both a stack and a descriptor will be allocated from a memory
+             * pool. */
+            new_thread_type = ABTI_THREAD_TYPE_MEM_MEMPOOL_DESC_STACK;
+        } else {
+            /* The stack must be allocated by malloc().  Let's allocate both
+             * a stack and a descriptor together by a single malloc(). */
+            new_thread_type = ABTI_THREAD_TYPE_MEM_MALLOC_DESC_STACK;
+        }
+    }
+
+    /* Unset the stack type and set new_thread_type. */
+    p_attr->thread_type &= ~ABTI_THREAD_TYPES_MEM;
+    p_attr->thread_type |= new_thread_type;
+
+    p_attr->p_stack = stackaddr;
+    p_attr->stacksize = stacksize;
+}
-- 
2.21.0 (Apple Git-122.2)


From 3a6abbc9bb88d4aa13b5f839d08689ef31e9a2f0 Mon Sep 17 00:00:00 2001
From: Shintaro Iwasaki <siwasaki@anl.gov>
Date: Tue, 8 Dec 2020 11:53:12 -0600
Subject: [PATCH 40/40] test/basic: add thread_attr2 to check if stack is
 correctly created

thread_attr2 checks if a created ULT has a stack specified by ABT_thread_attr.
---
 test/.gitignore           |   1 +
 test/basic/Makefile.am    |   3 +
 test/basic/thread_attr2.c | 205 ++++++++++++++++++++++++++++++++++++++
 3 files changed, 209 insertions(+)
 create mode 100644 test/basic/thread_attr2.c

diff --git a/test/.gitignore b/test/.gitignore
index f7b4523..d0d831c 100644
--- a/test/.gitignore
+++ b/test/.gitignore
@@ -10,6 +10,7 @@ basic/thread_create2
 basic/thread_create_on_xstream
 basic/thread_revive
 basic/thread_attr
+basic/thread_attr2
 basic/thread_yield
 basic/thread_yield_to
 basic/thread_self_suspend_resume
diff --git a/test/basic/Makefile.am b/test/basic/Makefile.am
index 7ecc49b..56d6918 100644
--- a/test/basic/Makefile.am
+++ b/test/basic/Makefile.am
@@ -15,6 +15,7 @@ TESTS = \
 	thread_create_on_xstream \
 	thread_revive \
 	thread_attr \
+	thread_attr2 \
 	thread_yield \
 	thread_yield_to \
 	thread_self_suspend_resume \
@@ -91,6 +92,7 @@ thread_create2_SOURCES = thread_create2.c
 thread_create_on_xstream_SOURCES = thread_create_on_xstream.c
 thread_revive_SOURCES = thread_revive.c
 thread_attr_SOURCES = thread_attr.c
+thread_attr2_SOURCES = thread_attr2.c
 thread_yield_SOURCES = thread_yield.c
 thread_yield_to_SOURCES = thread_yield_to.c
 thread_self_suspend_resume_SOURCES = thread_self_suspend_resume.c
@@ -155,6 +157,7 @@ testing:
 	./thread_create_on_xstream
 	./thread_revive
 	./thread_attr
+	./thread_attr2
 	./thread_yield
 	./thread_yield_to
 	./thread_self_suspend_resume
diff --git a/test/basic/thread_attr2.c b/test/basic/thread_attr2.c
new file mode 100644
index 0000000..e8eaa14
--- /dev/null
+++ b/test/basic/thread_attr2.c
@@ -0,0 +1,205 @@
+/* -*- Mode: C; c-basic-offset:4 ; indent-tabs-mode:nil ; -*- */
+/*
+ * See COPYRIGHT in top-level directory.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include "abt.h"
+#include "abttest.h"
+
+#define DEFAULT_NUM_XSTREAMS 4
+#define DEFAULT_NUM_THREADS 4
+
+#define DUMMY_SIZE ((int)(1024 / sizeof(double)))
+void set_random_dummy(volatile double *dummy)
+{
+    int i;
+    double base_value = ABT_get_wtime();
+    for (i = 0; i < DUMMY_SIZE; i++)
+        dummy[i] = base_value + i;
+}
+
+void update_random_dummy(volatile double *dummy)
+{
+    int i;
+    double base_value = ABT_get_wtime();
+    for (i = 0; i < DUMMY_SIZE; i++) {
+        if (dummy[i] == base_value + i)
+            dummy[i] *= 1.5;
+    }
+}
+
+void dummy_rec(const volatile double *top_dummy, volatile double *prev_dummy,
+               size_t stacksize)
+{
+    int i;
+    volatile double dummy[DUMMY_SIZE];
+    set_random_dummy(dummy);
+
+    uintptr_t dummy_ptr = (uintptr_t)dummy;
+    uintptr_t top_dummy_ptr = (uintptr_t)top_dummy;
+    if (top_dummy_ptr > dummy_ptr) {
+        if ((size_t)(top_dummy_ptr - dummy_ptr) > stacksize / 2)
+            /* Consumed enough stack. */
+            return;
+    } else {
+        if ((size_t)(dummy_ptr - top_dummy_ptr) > stacksize / 2)
+            /* Consumed enough stack. */
+            return;
+    }
+    /* Recursive call. */
+    dummy_rec(top_dummy, dummy, stacksize);
+    /* We need to avoid tail recursion elimination, so let's do something. */
+    update_random_dummy(dummy);
+    for (i = 0; i < DUMMY_SIZE; i++)
+        prev_dummy[i] += dummy[i];
+}
+
+void thread_func(void *arg)
+{
+    size_t stacksize = *((size_t *)arg), stacksize2;
+    ABT_thread thread;
+    ABT_thread_attr attr;
+    int ret, i;
+
+    ret = ABT_thread_self(&thread);
+    ATS_ERROR(ret, "ABT_thread_self");
+    ret = ABT_thread_get_attr(thread, &attr);
+    ATS_ERROR(ret, "ABT_thread_get_attr");
+
+    ret = ABT_thread_attr_get_stacksize(attr, &stacksize2);
+    ATS_ERROR(ret, "ABT_thread_attr_get_stacksize");
+    /* This must be the same. */
+    assert(stacksize == stacksize2);
+
+    /*
+     * Checking a real stack size is tricky.  Let's consume stack by recursion.
+     * - Each dummy_rec() consumes at least "DUMMY_SIZE * sizeof(double)" bytes.
+     * - Call dummy_rec() recursively until the total stack consumption gets
+     *   more than half of stacksize.  We need a margin for safety since we
+     *   cannot control the exact size of each function stack.
+     * Note that we use neither alloca() nor variable-length array since they
+     * are not portable.
+     */
+    volatile double dummy[DUMMY_SIZE];
+    set_random_dummy(dummy);
+    dummy_rec(dummy, dummy, stacksize);
+
+    update_random_dummy(dummy);
+    /* Use values of dummy to avoid possible compiler optimization */
+    for (i = 0; i < DUMMY_SIZE; i++) {
+        if (0.00001 < dummy[i] && dummy[i] < 0.00002)
+            printf("%d %f", i, dummy[i]);
+    }
+
+    ret = ABT_thread_attr_free(&attr);
+    ATS_ERROR(ret, "ABT_thread_attr_free");
+}
+
+int main(int argc, char *argv[])
+{
+    int ret, i;
+
+    ABT_thread_attr attr;
+    ABT_xstream xstream;
+    ABT_pool pool;
+    ABT_thread thread;
+
+    /* Initialize */
+    ATS_read_args(argc, argv);
+    ATS_init(argc, argv, 1);
+
+    /* Get a main pool. */
+    ret = ABT_xstream_self(&xstream);
+    ATS_ERROR(ret, "ABT_xstream_self");
+    ret = ABT_xstream_get_main_pools(xstream, 1, &pool);
+    ATS_ERROR(ret, "ABT_xstream_get_main_pools");
+
+    /* Get the default stack size. */
+    size_t default_stacksize;
+    ret = ABT_info_query_config(ABT_INFO_QUERY_KIND_DEFAULT_THREAD_STACKSIZE,
+                                &default_stacksize);
+    ATS_ERROR(ret, "ABT_info_query_config");
+
+    /* Loop over different stack sizes. */
+    size_t stacksizes[] = { default_stacksize, 1024 * 64, 1024 * 1024 };
+    int num_stacksizes = sizeof(stacksizes) / sizeof(stacksizes[0]);
+    for (i = 0; i < num_stacksizes; i++) {
+        size_t stacksize = stacksizes[i];
+
+        ret = ABT_thread_attr_create(&attr);
+        ATS_ERROR(ret, "ABT_thread_attr_create");
+
+        /* Case 1: set it via ABT_thread_attr_set_stacksize() */
+        ret = ABT_thread_attr_set_stacksize(attr, stacksize);
+        ATS_ERROR(ret, "ABT_thread_attr_set_stacksize");
+        ret = ABT_thread_create(pool, thread_func, (void *)&stacksize, attr,
+                                &thread);
+        ATS_ERROR(ret, "ABT_thread_create");
+        ret = ABT_thread_free(&thread);
+        ATS_ERROR(ret, "ABT_thread_free");
+
+        /* Case 2: set it via ABT_thread_attr_set_stack() (stack: NULL) */
+        ret = ABT_thread_attr_set_stack(attr, NULL, stacksize);
+        ATS_ERROR(ret, "ABT_thread_attr_set_stack");
+        ret = ABT_thread_create(pool, thread_func, (void *)&stacksize, attr,
+                                &thread);
+        ATS_ERROR(ret, "ABT_thread_create");
+        ret = ABT_thread_free(&thread);
+        ATS_ERROR(ret, "ABT_thread_free");
+
+        /* Case 3: set a different value once. */
+        ret =
+            ABT_thread_attr_set_stacksize(attr,
+                                          stacksizes[(i + 1) % num_stacksizes]);
+        ATS_ERROR(ret, "ABT_thread_attr_set_stack_size");
+        ret = ABT_thread_attr_set_stacksize(attr, stacksize);
+        ATS_ERROR(ret, "ABT_thread_attr_set_stack_size");
+        ret = ABT_thread_create(pool, thread_func, (void *)&stacksize, attr,
+                                &thread);
+        ATS_ERROR(ret, "ABT_thread_create");
+        ret = ABT_thread_free(&thread);
+        ATS_ERROR(ret, "ABT_thread_free");
+
+        /* Case 4: use ABT_thread_attr_set_stack() with stack. */
+        void *p_stack1 = (void *)malloc(stacksize);
+        ret = ABT_thread_attr_set_stack(attr, p_stack1, stacksize);
+        ATS_ERROR(ret, "ABT_thread_attr_set_stack");
+        ret = ABT_thread_create(pool, thread_func, (void *)&stacksize, attr,
+                                &thread);
+        ATS_ERROR(ret, "ABT_thread_create");
+        ret = ABT_thread_free(&thread);
+        ATS_ERROR(ret, "ABT_thread_free");
+        free(p_stack1);
+
+        /* Case 5: set a different value once. */
+        void *p_stack2 = (void *)malloc(stacksize);
+        ret = ABT_thread_attr_set_stack(attr, p_stack2,
+                                        stacksizes[(i + 1) % num_stacksizes]);
+        ATS_ERROR(ret, "ABT_thread_attr_set_stack");
+        ret = ABT_thread_attr_set_stacksize(attr, stacksize);
+        ATS_ERROR(ret, "ABT_thread_attr_set_stack_size");
+        ret = ABT_thread_create(pool, thread_func, (void *)&stacksize, attr,
+                                &thread);
+        ATS_ERROR(ret, "ABT_thread_create");
+        ret = ABT_thread_free(&thread);
+        ATS_ERROR(ret, "ABT_thread_free");
+        free(p_stack2);
+
+        ret = ABT_thread_attr_free(&attr);
+        ATS_ERROR(ret, "ABT_thread_attr_free");
+    }
+
+    /* Case 6: default attribute. */
+    ret = ABT_thread_create(pool, thread_func, (void *)&default_stacksize,
+                            ABT_THREAD_ATTR_NULL, &thread);
+    ATS_ERROR(ret, "ABT_thread_create");
+    ret = ABT_thread_free(&thread);
+    ATS_ERROR(ret, "ABT_thread_free");
+
+    /* Finalize */
+    ret = ATS_finalize(0);
+
+    return ret;
+}
-- 
2.21.0 (Apple Git-122.2)

